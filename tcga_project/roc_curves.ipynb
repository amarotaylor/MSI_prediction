{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import torch\n",
    "import psutil\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, set_image_backend\n",
    "\n",
    "import data_utils\n",
    "import train_utils\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "set_image_backend('accimage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = 0\n",
    "dataset = 'Val'\n",
    "root_dir = '/n/mounted-data-drive/COAD/'\n",
    "transform = train_utils.transform_validation\n",
    "batch_size = 256\n",
    "n_workers = 12\n",
    "output_shape = 1\n",
    "criterion = nn.BCEWithLogitsLoss(reduction = 'none')\n",
    "device = torch.device('cuda', 0)\n",
    "magnification = '5.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(e, dataset, encoding, valid_loader, resnet, criterion):\n",
    "    total_loss = 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    all_loss = []\n",
    "    all_probs = []\n",
    "\n",
    "    for idx,(batch,labels) in enumerate(valid_loader):\n",
    "        batch, labels = batch.cuda(device=device), encoding[labels.cuda(device=device)]\n",
    "        output = resnet(batch)\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        total_loss += torch.sum(loss.detach().mean(dim=1)).cpu().numpy()\n",
    "        all_labels.extend(torch.sum(labels, dim=1).float().cpu().numpy())\n",
    "        all_preds.extend(torch.sum(torch.sigmoid(output) > 0.5, dim=1).float().detach().cpu().numpy())\n",
    "        all_loss.extend(loss.detach().mean(dim=1).cpu().numpy())\n",
    "        all_probs.extend(torch.mean(torch.sigmoid(output), dim=1).float().detach().cpu().numpy())\n",
    "\n",
    "        if idx % 100 == 0:\n",
    "            print('Epoch: {0}, Batch: {1}, {3} NLL: {2:0.4f}'.format(e, idx, torch.sum(loss.detach())/batch.shape[0], dataset))\n",
    "\n",
    "    return idx, total_loss, all_labels, all_preds, all_loss, all_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(e, idx, dataset, batch_size, total_loss, all_labels, all_preds, all_loss, jpg_to_sample, encoding):\n",
    "    acc = np.mean(np.array(all_labels) == np.array(all_preds))\n",
    "\n",
    "    d = {'label': all_labels, 'pred': all_preds, 'sample': jpg_to_sample}\n",
    "    df = pd.DataFrame(data = d)\n",
    "    df['correct_tile'] = df['label'] == df['pred']\n",
    "    df.groupby(['label'])['correct_tile'].mean()\n",
    "    tile_acc_by_label = ', '.join([str(i) + ': ' + str(float(df.groupby(['label'])['correct_tile'].mean()[i]))[:6] for i in range(encoding.shape[0])])\n",
    "\n",
    "    df2 = df.groupby(['sample'])['label','pred'].mean().round()\n",
    "    df2['correct_sample'] = df2['label'] == df2['pred']\n",
    "    mean_pool_acc = df2['correct_sample'].mean()\n",
    "\n",
    "    df3 = df.groupby(['sample'])['label','pred'].max()\n",
    "    df3['correct_sample'] = df3['label'] == df3['pred']\n",
    "    max_pool_acc = df3['correct_sample'].mean()\n",
    "\n",
    "    slide_acc_by_label = ', '.join([str(i) + ': ' + str(float(df2.groupby(['label'])['correct_sample'].mean()[i]))[:6] for i in range(encoding.shape[0])])\n",
    "\n",
    "    print('Epoch: {0}, Avg {3} NLL: {1:0.4f}, Median {3} NLL: {2:0.4f}'.format(e, total_loss/(float(idx+1) * batch_size), \n",
    "                                                                               np.median(all_loss), dataset))\n",
    "    print('------ {2} Tile-Level Acc: {0:0.4f}; By Label: {1}'.format(acc, tile_acc_by_label, dataset))\n",
    "    print('------ {2} Slide-Level Acc: Mean-Pooling: {0:0.4f}, Max-Pooling: {1:0.4f}'.format(mean_pool_acc, max_pool_acc, \n",
    "                                                                                             dataset))\n",
    "    print('------ {1} Slide-Level Acc (Mean-Pooling) By Label: {0}'.format(slide_acc_by_label, dataset))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_roc_curves(task, level, labels=None, probs=None, df=None):\n",
    "    if level == 'Slide':\n",
    "        slide_df = df.groupby(['sample'])['label','pred'].mean()\n",
    "        labels = slide_df['label']\n",
    "        probs = slide_df['pred']\n",
    "        \n",
    "    fpr, tpr, thresholds = metrics.roc_curve(np.array(labels), np.array(probs))\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(level + '-level receiver operating characteristic (' + task + ')')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_and_curves(e, dataset, task, pickle_file, state_dict_file, root_dir, transform, \n",
    "                           batch_size, n_workers, output_shape, criterion, device, magnification):\n",
    "    with open(pickle_file, 'rb') as f: \n",
    "        train_val, sa_val = pickle.load(f)    \n",
    "    val_set = data_utils.TCGADataset_tiles(sa_val, root_dir, transform=transform, magnification=magnification)\n",
    "    jpg_to_sample = val_set.jpg_to_sample\n",
    "    valid_loader = DataLoader(val_set, batch_size=batch_size, pin_memory=True, num_workers=n_workers)\n",
    "\n",
    "    resnet = models.resnet18(pretrained=True)\n",
    "    resnet.fc = nn.Linear(2048, output_shape, bias=True)\n",
    "    saved_state = torch.load(state_dict_file, map_location=lambda storage, loc: storage)\n",
    "    resnet.load_state_dict(saved_state)\n",
    "    resnet.cuda(device=device)\n",
    "    resnet.eval()\n",
    "\n",
    "    for param in resnet.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    if task == 'MSI':\n",
    "        encoding = torch.tensor([[0,0],[1,0],[1,1]], device=device).float()\n",
    "    elif task == 'WGD' or task == 'MSI-SINGLE_LABEL':\n",
    "        encoding = torch.tensor([[0],[1]], device=device).float()\n",
    "        \n",
    "    idx, total_loss, all_labels, all_preds, all_loss, all_probs = forward_pass(e, dataset, encoding, valid_loader, resnet, criterion)\n",
    "    df = print_results(e, idx, dataset, batch_size, total_loss, all_labels, all_preds, all_loss, jpg_to_sample, encoding)\n",
    "    print_roc_curves(task, 'Tile', labels=all_labels, probs=all_probs)\n",
    "    print_roc_curves(task, 'Slide', df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'WGD'\n",
    "pickle_file = '/n/tcga_models/resnet18_WGD_v04_sa.pkl'\n",
    "state_dict_file = '/n/tcga_models/resnet18_WGD_v04.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_results_and_curves(e, dataset, task, pickle_file, state_dict_file, root_dir, transform, \n",
    "                       batch_size, n_workers, output_shape, criterion, device, magnification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'MSI-SINGLE_LABEL'\n",
    "pickle_file = '/n/tcga_models/resnet18_MSI_singlelabel_v02_sa.pkl'\n",
    "state_dict_file = '/n/tcga_models/resnet18_MSI_singlelabel_v02.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_results_and_curves(e, dataset, task, pickle_file, state_dict_file, root_dir, transform, \n",
    "                       batch_size, n_workers, output_shape, criterion, device, magnification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

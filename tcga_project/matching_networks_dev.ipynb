{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import torch\n",
    "import psutil\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, set_image_backend\n",
    "\n",
    "import data_utils\n",
    "import train_utils\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "set_image_backend('accimage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define global variables\n",
    "classification = 'WGD'\n",
    "magnification = '10.0'\n",
    "output_shape = 1\n",
    "device = torch.device('cuda', 0)\n",
    "root_dir = '/n/mounted-data-drive/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep Images - DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get image file paths\n",
    "batch_one = ['COAD', 'BRCA', 'UCEC']\n",
    "batch_two_orig = ['BLCA', 'KIRC', 'READ', 'HNSC', 'LUSC', 'LIHC', 'LUAD', 'STAD']\n",
    "if magnification == '10.0':\n",
    "    batch_two = [b + '_10x' for b in batch_two_orig]\n",
    "elif magnification == '5.0':\n",
    "    batch_two = [b + '_5x' for b in batch_two_orig]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# get sample annotations\n",
    "# NOTE: ONLY FOR WGD\n",
    "wgd_path = 'ALL_WGD_TABLE.xlsx'\n",
    "wgd_raw = pd.read_excel(wgd_path)\n",
    "#wgd_raw.head(3)\n",
    "\n",
    "batch_all_orig = batch_one + batch_two_orig\n",
    "wgd_filtered = wgd_raw.loc[wgd_raw['Type'].isin(batch_all_orig)]\n",
    "#wgd_filtered.head(3)\n",
    "\n",
    "wgd_filtered.loc[wgd_filtered['Genome_doublings'].values == 2, 'Genome_doublings'] = 1\n",
    "\n",
    "wgd_filtered.set_index('Sample', inplace=True)\n",
    "#wgd_filtered.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Samples with Images and Labels:\n",
      "COAD      Num Images:   433  Num Labels:   433  Overlap:   406\n",
      "BRCA      Num Images: 1,054  Num Labels: 1,048  Overlap:   998\n",
      "UCEC      Num Images:   505  Num Labels:   517  Overlap:   477\n",
      "BLCA_10x  Num Images:   387  Num Labels:   402  Overlap:   377\n",
      "KIRC_10x  Num Images:   508  Num Labels:   483  Overlap:   459\n",
      "READ_10x  Num Images:   157  Num Labels:   155  Overlap:   143\n",
      "HNSC_10x  Num Images:   365  Num Labels:   512  Overlap:   351\n",
      "LUSC_10x  Num Images:   479  Num Labels:   482  Overlap:   460\n",
      "LIHC_10x  Num Images:   365  Num Labels:   362  Overlap:   351\n",
      "LUAD_10x  Num Images:   466  Num Labels:   503  Overlap:   448\n",
      "STAD_10x  Num Images:   373  Num Labels:   427  Overlap:   358\n"
     ]
    }
   ],
   "source": [
    "# get sample annotations for all cancer types\n",
    "# split samples into two sets of train/val\n",
    "sa_trains1 = []\n",
    "sa_vals1 = []\n",
    "sa_trains2 = []\n",
    "sa_vals2 = []\n",
    "batch_all = batch_one + batch_two\n",
    "\n",
    "print('Num Samples with Images and Labels:')\n",
    "for cancer in batch_all:\n",
    "    sa_train1, sa_val1, sa_train2, sa_val2 = data_utils.process_WGD_data(root_dir='/n/mounted-data-drive/', \n",
    "                                                                         cancer_type=cancer, \n",
    "                                                                         wgd_path=None, \n",
    "                                                                         split_in_two=True, \n",
    "                                                                         print_overlap=True, \n",
    "                                                                         wgd_raw=wgd_filtered)\n",
    "    sa_trains1.append(sa_train1)\n",
    "    sa_vals1.append(sa_val1)\n",
    "    sa_trains2.append(sa_train2)\n",
    "    sa_vals2.append(sa_val2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save sample annotations in a pickle\n",
    "pickle_file = '/home/sxchao/MSI_prediction/tcga_project/tcga_wgd_sa_all.pkl'\n",
    "with open(pickle_file, 'wb') as f: \n",
    "    pickle.dump([batch_all, sa_trains1, sa_vals1, sa_trains2, sa_vals2], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sample annotations pickle\n",
    "pickle_file = '/home/sxchao/MSI_prediction/tcga_project/tcga_wgd_sa_all.pkl'\n",
    "batch_all, _, _, sa_trains, sa_vals = data_utils.load_COAD_train_val_sa_pickle(pickle_file=pickle_file, \n",
    "                                                                               return_all_cancers=True, \n",
    "                                                                               split_in_two=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize Datasets\n",
    "train_sets = []\n",
    "val_sets = []\n",
    "\n",
    "#train_transform = train_utils.transform_train\n",
    "val_transform = train_utils.transform_validation\n",
    "\n",
    "train_cancers = ['COAD', 'BRCA', 'READ_10x', 'LUSC_10x', 'BLCA_10x', 'LUAD_10x', 'STAD_10x', 'HNSC_10x']\n",
    "val_cancers = ['UCEC', 'LIHC_10x', 'KIRC_10x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COAD BRCA READ_10x LUSC_10x BLCA_10x LUAD_10x STAD_10x HNSC_10x "
     ]
    }
   ],
   "source": [
    "for i in range(len(train_cancers)):\n",
    "    print(train_cancers[i], end=' ')\n",
    "    train_set = data_utils.TCGADataset_tiles(sa_vals[batch_all.index(train_cancers[i])], \n",
    "                                             root_dir + train_cancers[i] + '/', \n",
    "                                             transform=val_transform, \n",
    "                                             magnification=magnification, \n",
    "                                             batch_type='tile')\n",
    "    train_sets.append(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCEC LIHC_10x KIRC_10x "
     ]
    }
   ],
   "source": [
    "for j in range(len(val_cancers)):\n",
    "    print(val_cancers[j], end=' ')\n",
    "    val_set = data_utils.TCGADataset_tiles(sa_vals[batch_all.index(val_cancers[j])], \n",
    "                                           root_dir + val_cancers[j] + '/', \n",
    "                                           transform=val_transform, \n",
    "                                           magnification=magnification, \n",
    "                                           batch_type='tile')\n",
    "    val_sets.append(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Num Tiles:')\n",
    "for cancer, tset, vset in zip(batch_all, train_sets, val_sets):\n",
    "    print('{0:<8}  Train: {1:>10,d}              Val: {2:>8,d}'.format(cancer, tset.__len__(), vset.__len__()))\n",
    "    print('          Train: (0) {0:0.4f}, (1) {1:0.4f}  Val: (0) {2:0.4f} (1) {3:0.4f}'.format(np.mean(np.array(tset.all_labels) == 0),\n",
    "                                                                                              np.mean(np.array(tset.all_labels) == 1),\n",
    "                                                                                              np.mean(np.array(vset.all_labels) == 0),\n",
    "                                                                                              np.mean(np.array(vset.all_labels) == 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model file paths\n",
    "if classification == 'WGD':\n",
    "    if magnification == '10.0':\n",
    "        #sa_file = '/n/tcga_models/resnet18_WGD_10x_sa.pkl'\n",
    "        #state_dict_file = '/n/tcga_models/resnet18_WGD_10x.pt'\n",
    "        sa_file = '/home/sxchao/MSI_prediction/tcga_project/tcga_wgd_sa_all.pkl'\n",
    "        state_dict_file = '/n/tcga_models/resnet18_WGD_all_10x.pt'\n",
    "    elif magnification == '5.0':\n",
    "        #sa_file = '/n/tcga_models/resnet18_WGD_v04_sa.pkl'\n",
    "        state_dict_file = '/n/tcga_models/resnet18_WGD_v04.pt'\n",
    "elif classification == 'MSI':\n",
    "    if magnification == '10.0':\n",
    "        #sa_file = '/n/tcga_models/resnet18_MSI_singlelabel_10x_sa.pkl'\n",
    "        state_dict_file = '/n/tcga_models/resnet18_MSI_singlelabel_10x.pt'\n",
    "    elif magnification == '5.0':\n",
    "        #sa_file = '/n/tcga_models/resnet18_MSI_singlelabel_v02_sa.pkl'\n",
    "        state_dict_file = '/n/tcga_models/resnet18_MSI_singlelabel_v02.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=2048, out_features=2048, bias=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load embedding network and freeze layers\n",
    "resnet = models.resnet18(pretrained=False)\n",
    "resnet.fc = nn.Linear(2048, output_shape, bias=True)\n",
    "saved_state = torch.load(state_dict_file, map_location=lambda storage, loc: storage)\n",
    "resnet.load_state_dict(saved_state)\n",
    "resnet.fc = Identity()\n",
    "#resnet.fc = nn.Linear(2048, 2048, bias=False)\n",
    "#resnet.fc.weight.data=torch.eye(2048)\n",
    "resnet.cuda(device=device)\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "#resnet.fc.weight.parameters.requires_grad = True\n",
    "#resnet.fc.bias.parameters.requires_grad = True\n",
    "\n",
    "# initialize fully-connected final layer \n",
    "final_embed_layer = nn.Linear(2048, 2048)\n",
    "final_embed_layer.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConcatDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, *datasets):\n",
    "        self.datasets = datasets\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return torch.stack([d[i][0] for d in self.datasets]), torch.cat([torch.tensor(d[i][1]).view(-1) for d in self.datasets])\n",
    "\n",
    "    def __len__(self):\n",
    "        return min(len(d) for d in self.datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "support_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(ConcatDataset(*train_sets), \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True, \n",
    "                                           num_workers=24, \n",
    "                                           pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-5\n",
    "lsm = nn.LogSoftmax(dim=1)\n",
    "criterion = nn.BCELoss()\n",
    "#optimizer = torch.optim.Adam(resnet.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(final_embed_layer.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step, (tiles, labels) in enumerate(train_loader):  \n",
    "    labels = labels.cuda().float().transpose(0,1)    \n",
    "    # flatten batch_size x num_cancer_types \n",
    "    batch = tiles.cuda().transpose(0,1).reshape(batch_size * len(train_cancers), 3, 256, 256)    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 500, Train NLL: 13.2893\n",
      "Epoch: 510, Train NLL: 13.2892\n",
      "Epoch: 520, Train NLL: 13.2890\n",
      "Epoch: 530, Train NLL: 13.2888\n",
      "Epoch: 540, Train NLL: 13.2887\n",
      "Epoch: 550, Train NLL: 13.2885\n",
      "Epoch: 560, Train NLL: 13.2884\n",
      "Epoch: 570, Train NLL: 13.2882\n",
      "Epoch: 580, Train NLL: 13.2880\n",
      "Epoch: 590, Train NLL: 13.2878\n",
      "Epoch: 600, Train NLL: 13.2876\n",
      "Epoch: 610, Train NLL: 13.2875\n",
      "Epoch: 620, Train NLL: 13.2873\n",
      "Epoch: 630, Train NLL: 13.2871\n",
      "Epoch: 640, Train NLL: 13.2869\n",
      "Epoch: 650, Train NLL: 13.2867\n",
      "Epoch: 660, Train NLL: 13.2865\n",
      "Epoch: 670, Train NLL: 13.2863\n",
      "Epoch: 680, Train NLL: 13.2861\n",
      "Epoch: 690, Train NLL: 13.2859\n",
      "Epoch: 700, Train NLL: 13.2857\n",
      "Epoch: 710, Train NLL: 13.2855\n",
      "Epoch: 720, Train NLL: 13.2853\n",
      "Epoch: 730, Train NLL: 13.2851\n",
      "Epoch: 740, Train NLL: 13.2848\n",
      "Epoch: 750, Train NLL: 13.2846\n",
      "Epoch: 760, Train NLL: 13.2844\n",
      "Epoch: 770, Train NLL: 13.2842\n",
      "Epoch: 780, Train NLL: 13.2839\n",
      "Epoch: 790, Train NLL: 13.2837\n",
      "Epoch: 800, Train NLL: 13.2835\n",
      "Epoch: 810, Train NLL: 13.2832\n",
      "Epoch: 820, Train NLL: 13.2830\n",
      "Epoch: 830, Train NLL: 13.2828\n",
      "Epoch: 840, Train NLL: 13.2825\n",
      "Epoch: 850, Train NLL: 13.2823\n",
      "Epoch: 860, Train NLL: 13.2820\n",
      "Epoch: 870, Train NLL: 13.2818\n",
      "Epoch: 880, Train NLL: 13.2815\n",
      "Epoch: 890, Train NLL: 13.2813\n",
      "Epoch: 900, Train NLL: 13.2810\n",
      "Epoch: 910, Train NLL: 13.2808\n",
      "Epoch: 920, Train NLL: 13.2805\n",
      "Epoch: 930, Train NLL: 13.2803\n",
      "Epoch: 940, Train NLL: 13.2800\n",
      "Epoch: 950, Train NLL: 13.2797\n",
      "Epoch: 960, Train NLL: 13.2795\n",
      "Epoch: 970, Train NLL: 13.2792\n",
      "Epoch: 980, Train NLL: 13.2789\n",
      "Epoch: 990, Train NLL: 13.2786\n",
      "Epoch: 1000, Train NLL: 13.2783\n",
      "Epoch: 1010, Train NLL: 13.2781\n",
      "Epoch: 1020, Train NLL: 13.2778\n",
      "Epoch: 1030, Train NLL: 13.2775\n",
      "Epoch: 1040, Train NLL: 13.2772\n",
      "Epoch: 1050, Train NLL: 13.2769\n",
      "Epoch: 1060, Train NLL: 13.2766\n",
      "Epoch: 1070, Train NLL: 13.2763\n",
      "Epoch: 1080, Train NLL: 13.2760\n",
      "Epoch: 1090, Train NLL: 13.2757\n",
      "Epoch: 1100, Train NLL: 13.2754\n",
      "Epoch: 1110, Train NLL: 13.2751\n",
      "Epoch: 1120, Train NLL: 13.2748\n",
      "Epoch: 1130, Train NLL: 13.2745\n",
      "Epoch: 1140, Train NLL: 13.2742\n",
      "Epoch: 1150, Train NLL: 13.2739\n",
      "Epoch: 1160, Train NLL: 13.2735\n",
      "Epoch: 1170, Train NLL: 13.2732\n",
      "Epoch: 1180, Train NLL: 13.2729\n",
      "Epoch: 1190, Train NLL: 13.2726\n",
      "Epoch: 1200, Train NLL: 13.2722\n",
      "Epoch: 1210, Train NLL: 13.2719\n",
      "Epoch: 1220, Train NLL: 13.2716\n",
      "Epoch: 1230, Train NLL: 13.2712\n",
      "Epoch: 1240, Train NLL: 13.2709\n",
      "Epoch: 1250, Train NLL: 13.2705\n",
      "Epoch: 1260, Train NLL: 13.2702\n",
      "Epoch: 1270, Train NLL: 13.2698\n",
      "Epoch: 1280, Train NLL: 13.2695\n",
      "Epoch: 1290, Train NLL: 13.2691\n",
      "Epoch: 1300, Train NLL: 13.2688\n",
      "Epoch: 1310, Train NLL: 13.2684\n",
      "Epoch: 1320, Train NLL: 13.2681\n",
      "Epoch: 1330, Train NLL: 13.2677\n",
      "Epoch: 1340, Train NLL: 13.2673\n",
      "Epoch: 1350, Train NLL: 13.2669\n",
      "Epoch: 1360, Train NLL: 13.2665\n",
      "Epoch: 1370, Train NLL: 13.2662\n",
      "Epoch: 1380, Train NLL: 13.2658\n",
      "Epoch: 1390, Train NLL: 13.2654\n",
      "Epoch: 1400, Train NLL: 13.2650\n",
      "Epoch: 1410, Train NLL: 13.2647\n",
      "Epoch: 1420, Train NLL: 13.2643\n",
      "Epoch: 1430, Train NLL: 13.2639\n",
      "Epoch: 1440, Train NLL: 13.2635\n",
      "Epoch: 1450, Train NLL: 13.2631\n",
      "Epoch: 1460, Train NLL: 13.2627\n",
      "Epoch: 1470, Train NLL: 13.2623\n",
      "Epoch: 1480, Train NLL: 13.2619\n",
      "Epoch: 1490, Train NLL: 13.2614\n"
     ]
    }
   ],
   "source": [
    "for e in range(2000):    \n",
    "    # forward pass\n",
    "    output = resnet(batch)\n",
    "    \n",
    "    # un-flatten num_cancer_types x batch_size\n",
    "    cancers_by_feats = torch.stack(torch.chunk(output, len(train_cancers)))    \n",
    "        \n",
    "    # split feats, labels into support, query sets\n",
    "    feats_support = cancers_by_feats[:, :support_size, :]\n",
    "    feats_support = feats_support.reshape(support_size * len(train_cancers), 2048)\n",
    "    feats_support = final_embed_layer(feats_support)\n",
    "    feats_support = torch.stack(torch.chunk(feats_support, len(train_cancers)))\n",
    "    \n",
    "    feats_query = cancers_by_feats[:, support_size:, :]\n",
    "    labels_support = labels[:,:support_size]\n",
    "    labels_query = labels[:,support_size:]\n",
    "    \n",
    "    # get preds    \n",
    "    scores = lsm(torch.bmm(feats_support, feats_query.transpose(1,2))).exp()\n",
    "    preds = torch.bmm(labels_support.unsqueeze(1), scores).squeeze(1)\n",
    "    clamped_preds = torch.clamp(preds, 0, 1)\n",
    "    \n",
    "    # calc loss, backprop, step    \n",
    "    loss = criterion(clamped_preds, labels_query)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #if step % 5 == 0:\n",
    "    #    print('Epoch: {0}, Step: {1}, Train NLL: {2:0.4f}'.format(e, step, loss.detach().cpu().numpy()))\n",
    "    if e % 100 == 0:\n",
    "        print('Epoch: {0}, Train NLL: {1:0.4f}'.format(e, loss.detach().cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

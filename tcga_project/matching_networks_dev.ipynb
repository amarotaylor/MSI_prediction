{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import torch\n",
    "import psutil\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, set_image_backend\n",
    "\n",
    "import data_utils\n",
    "import train_utils\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "set_image_backend('accimage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define global vars\n",
    "classification = 'WGD'\n",
    "magnification = '10.0'\n",
    "output_size = 1\n",
    "device = torch.device('cuda', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model file paths\n",
    "if classification == 'WGD':\n",
    "    if magnification == '10.0':\n",
    "        #sa_file = '/n/tcga_models/resnet18_WGD_10x_sa.pkl'\n",
    "        state_dict_file = '/n/tcga_models/resnet18_WGD_10x.pt'\n",
    "    elif magnification == '5.0':\n",
    "        #sa_file = '/n/tcga_models/resnet18_WGD_v04_sa.pkl'\n",
    "        state_dict_file = '/n/tcga_models/resnet18_WGD_v04.pt'\n",
    "elif classification == 'MSI':\n",
    "    if magnification == '10.0':\n",
    "        #sa_file = '/n/tcga_models/resnet18_MSI_singlelabel_10x_sa.pkl'\n",
    "        state_dict_file = '/n/tcga_models/resnet18_MSI_singlelabel_10x.pt'\n",
    "    elif magnification == '5.0':\n",
    "        #sa_file = '/n/tcga_models/resnet18_MSI_singlelabel_v02_sa.pkl'\n",
    "        state_dict_file = '/n/tcga_models/resnet18_MSI_singlelabel_v02.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load embedding network and freeze layers\n",
    "resnet = models.resnet18(pretrained=False)\n",
    "resnet.fc = nn.Linear(2048, output_shape, bias=True)\n",
    "saved_state = torch.load(state_dict_file, map_location=lambda storage, loc: storage)\n",
    "resnet.load_state_dict(saved_state)\n",
    "resnet.fc = nn.Linear(2048, 2048, bias=False)\n",
    "resnet.fc.weight.data=torch.eye(2048)\n",
    "resnet.cuda(device=device)\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize fully-connected final layer \n",
    "final_embed_layer = nn.Linear(2048, 2048)\n",
    "final_embed_layer.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get image file paths\n",
    "root_dir = '/n/mounted-data-drive/'\n",
    "batch_one = ['COAD', 'BRCA', 'UCEC']\n",
    "batch_two_orig = ['BLCA', 'KIRC', 'READ', 'HNSC', 'LUSC', 'LIHC', 'LUAD', 'STAD']\n",
    "if magnification == '10.0':\n",
    "    batch_two = [b + '_10x' for b in batch_two_orig]\n",
    "elif magnification == '5.0':\n",
    "    batch_two = [b + '_5x' for b in batch_two_orig]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sample annotations\n",
    "# NOTE: ONLY FOR WGD\n",
    "wgd_path = 'ALL_WGD_TABLE.xlsx'\n",
    "wgd_raw = pd.read_excel(wgd_path)\n",
    "#wgd_raw.head(3)\n",
    "\n",
    "batch_all = batch_one + batch_two_orig\n",
    "wgd_filtered = wgd_raw.loc[wgd_raw['Type'].isin(batch_all)]\n",
    "#wgd_filtered.head(3)\n",
    "\n",
    "wgd_filtered.loc[wgd_filtered['Genome_doublings'].values == 2, 'Genome_doublings'] = 1\n",
    "\n",
    "wgd_filtered.set_index('Sample', inplace=True)\n",
    "#wgd_filtered.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sample annotations for all cancer types\n",
    "sa_trains = []\n",
    "sa_vals = []\n",
    "batch_all = batch_one + batch_two\n",
    "\n",
    "for cancer in batch_all:\n",
    "    sa_train, sa_val = data_utils.process_WGD_data(root_dir='/n/mounted-data-drive/', cancer_type=cancer, \n",
    "                                                   wgd_path=None, wgd_raw = wgd_filtered)\n",
    "    sa_trains.append(sa_train)\n",
    "    sa_vals.append(sa_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save sample annotations in a pickle\n",
    "pickle_file = 'tcga_wgd_sa_all.pkl'\n",
    "with open(pickle_file, 'wb') as f: \n",
    "        pickle.dump([batch_all, sa_trains, sa_vals], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sample annotations pickle\n",
    "batch_all, sa_trains, sa_vals = data_utils.load_COAD_train_val_sa_pickle(pickle_file=pickle_file, \n",
    "                                                                         return_all_cancers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/n/mounted-data-drive/UCEC/TCGA-D1-A0ZS-01Z-00-DX1.8021A060-3CA2-418E-AE16-C48E911F5C25.svs/TCGA-D1-A0ZS-01Z-00-DX1.8021A060-3CA2-418E-AE16-C48E911F5C25_files/10.0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-1c29091243cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     train_set = data_utils.TCGADataset_tiles(sa_trains[i], root_dir + batch_all[i] + '/', transform=train_transform, \n\u001b[0;32m---> 11\u001b[0;31m                                              magnification=magnification, batch_type='tile')\n\u001b[0m\u001b[1;32m     12\u001b[0m     val_set = data_utils.TCGADataset_tiles(sa_vals[i], root_dir + batch_all[i] + '/', transform=val_transform, \n\u001b[1;32m     13\u001b[0m                                            magnification=magnification, batch_type='tile')\n",
      "\u001b[0;32m~/MSI_prediction/tcga_project/data_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sample_annotations, root_dir, transform, loader, magnification, batch_type, tile_batch_size)\u001b[0m\n\u001b[1;32m    114\u001b[0m         self.img_dirs = [self.root_dir + sample_name + '.svs/' \\\n\u001b[1;32m    115\u001b[0m                          + sample_name + '_files/' + self.magnification for sample_name in self.sample_names]\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjpegs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg_dir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_dirs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_jpegs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MSI_prediction/tcga_project/data_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    114\u001b[0m         self.img_dirs = [self.root_dir + sample_name + '.svs/' \\\n\u001b[1;32m    115\u001b[0m                          + sample_name + '_files/' + self.magnification for sample_name in self.sample_names]\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjpegs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg_dir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_dirs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_jpegs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/n/mounted-data-drive/UCEC/TCGA-D1-A0ZS-01Z-00-DX1.8021A060-3CA2-418E-AE16-C48E911F5C25.svs/TCGA-D1-A0ZS-01Z-00-DX1.8021A060-3CA2-418E-AE16-C48E911F5C25_files/10.0'"
     ]
    }
   ],
   "source": [
    "# initialize Datasets\n",
    "train_sets = []\n",
    "val_sets = []\n",
    "batch_all = batch_one + batch_two_orig\n",
    "\n",
    "train_transform = train_utils.transform_train\n",
    "val_transform = train_utils.transform_validation\n",
    "\n",
    "for i in range(len(batch_all)):\n",
    "    train_set = data_utils.TCGADataset_tiles(sa_trains[i], root_dir + batch_all[i] + '/', transform=train_transform, \n",
    "                                             magnification=magnification, batch_type='tile')\n",
    "    val_set = data_utils.TCGADataset_tiles(sa_vals[i], root_dir + batch_all[i] + '/', transform=val_transform, \n",
    "                                           magnification=magnification, batch_type='tile')\n",
    "    train_sets.append(train_set)\n",
    "    val_sets.append(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tset, vset in zip(train_sets, val_sets):\n",
    "    print(tset.__len__(), vset.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define few-shot learning params\n",
    "n_support = 5 # number of training examples in the support set\n",
    "n_query = 20 # number of training examples in the query set\n",
    "n_task = 4 # number of 'tasks' to sample from each cancer type"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import torch\n",
    "import psutil\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, set_image_backend\n",
    "\n",
    "import data_utils\n",
    "import train_utils\n",
    "import model_utils\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "set_image_backend('accimage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sample annotations pickle\n",
    "pickle_file = '/home/sxchao/MSI_prediction/tcga_project/tcga_wgd_sa_all.pkl'\n",
    "batch_all, _, _, sa_trains, sa_vals = data_utils.load_COAD_train_val_sa_pickle(pickle_file=pickle_file, \n",
    "                                                                               return_all_cancers=True, \n",
    "                                                                               split_in_two=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize Datasets\n",
    "train_sets = []\n",
    "val_sets = []\n",
    "\n",
    "magnification = '10.0'\n",
    "root_dir = '/n/mounted-data-drive/'\n",
    "train_transform = train_utils.transform_train\n",
    "val_transform = train_utils.transform_validation\n",
    "\n",
    "train_cancers = ['COAD', 'BRCA', 'READ_10x', 'LUSC_10x', 'BLCA_10x', 'LUAD_10x', 'STAD_10x', 'HNSC_10x']\n",
    "val_cancers = ['UCEC', 'LIHC_10x', 'KIRC_10x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COAD BRCA READ_10x LUSC_10x BLCA_10x LUAD_10x STAD_10x HNSC_10x "
     ]
    }
   ],
   "source": [
    "for i in range(len(train_cancers)):\n",
    "    print(train_cancers[i], end=' ')\n",
    "    train_set = data_utils.TCGADataset_tiles(sa_trains[batch_all.index(train_cancers[i])], \n",
    "                                             root_dir + train_cancers[i] + '/', \n",
    "                                             transform=train_transform, \n",
    "                                             magnification=magnification, \n",
    "                                             batch_type='tile')\n",
    "    train_sets.append(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCEC LIHC_10x KIRC_10x "
     ]
    }
   ],
   "source": [
    "for j in range(len(val_cancers)):\n",
    "    print(val_cancers[j], end=' ')\n",
    "    val_set = data_utils.TCGADataset_tiles(sa_vals[batch_all.index(val_cancers[j])], \n",
    "                                           root_dir + val_cancers[j] + '/', \n",
    "                                           transform=val_transform, \n",
    "                                           magnification=magnification, \n",
    "                                           batch_type='tile',\n",
    "                                           return_jpg_to_sample=True)\n",
    "    val_sets.append(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 100\n",
    "train_loader = torch.utils.data.DataLoader(data_utils.ConcatDataset(*train_sets), \n",
    "                                           batch_size=batch_size_train, \n",
    "                                           shuffle=True, \n",
    "                                           num_workers=20, \n",
    "                                           pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_val = 100\n",
    "#val_loader = torch.utils.data.DataLoader(data_utils.ConcatDataset(*val_sets, return_jpg_to_sample=True), \n",
    "#                                        batch_size=batch_size_val, \n",
    "#                                        shuffle=True, \n",
    "#                                        num_workers=20, \n",
    "#                                        pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loaders = [torch.utils.data.DataLoader(val_set, \n",
    "                                            batch_size=batch_size_val, \n",
    "                                            shuffle=True, \n",
    "                                            num_workers=20, \n",
    "                                            pin_memory=True) for val_set in val_sets]\n",
    "len(val_loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1411, 1199)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model args\n",
    "state_dict_file = '/n/tcga_models/resnet18_WGD_all_10x.pt'\n",
    "device = torch.device('cuda', 0)\n",
    "input_size = 2048\n",
    "hidden_size = 512\n",
    "output_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize trained resnet\n",
    "resnet = models.resnet18(pretrained=False)\n",
    "resnet.fc = nn.Linear(2048, output_size, bias=True)\n",
    "saved_state = torch.load(state_dict_file, map_location=lambda storage, loc: storage)\n",
    "resnet.load_state_dict(saved_state)\n",
    "\n",
    "# freeze layers\n",
    "resnet.fc = model_utils.Identity()\n",
    "resnet.cuda(device=device)\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize theta_global\n",
    "model_global = model_utils.FeedForward(input_size, hidden_size, output_size).cuda()\n",
    "theta_global = []\n",
    "for p in model_global.parameters():\n",
    "    theta_global.append(torch.randn(list(p.shape)).cuda())\n",
    "    \n",
    "model_global.linear1.weight = torch.nn.Parameter(theta_global[0])\n",
    "model_global.linear1.bias = torch.nn.Parameter(theta_global[1])\n",
    "model_global.linear2.weight = torch.nn.Parameter(theta_global[2])\n",
    "model_global.linear2.bias = torch.nn.Parameter(theta_global[3])\n",
    "\n",
    "# initialize local models, set theta_local = theta_global    \n",
    "local_models = []\n",
    "for i in range(len(train_cancers)):\n",
    "    local_models.append(model_utils.FeedForward(input_size, hidden_size, output_size, theta_global).cuda()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train params\n",
    "num_epochs = 1000\n",
    "alpha = 0.1\n",
    "eta = 0.1\n",
    "patience = 1\n",
    "factor = 0.1\n",
    "patience_count = 0\n",
    "previous_loss = 1e8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, Val NLL: 212.1946, Acc: 0.4300, By Label: 0: 0.45, 1: 0.35\n",
      "Step: 100, Val NLL: 191.5525, Acc: 0.4800, By Label: 0: 0.4729, 1: 0.5\n",
      "Step: 200, Val NLL: 208.2188, Acc: 0.4400, By Label: 0: 0.4096, 1: 0.5882\n",
      "Step: 300, Val NLL: 219.0420, Acc: 0.4200, By Label: 0: 0.4197, 1: 0.4210\n",
      "Step: 400, Val NLL: 219.8965, Acc: 0.3900, By Label: 0: 0.3513, 1: 0.5\n",
      "Step: 500, Val NLL: 222.8416, Acc: 0.4400, By Label: 0: 0.4675, 1: 0.3478\n",
      "Step: 600, Val NLL: 182.6078, Acc: 0.4800, By Label: 0: 0.4324, 1: 0.6153\n",
      "Step: 700, Val NLL: 217.5059, Acc: 0.4000, By Label: 0: 0.3783, 1: 0.4615\n",
      "Step: 800, Val NLL: 185.4231, Acc: 0.4200, By Label: 0: 0.4166, 1: 0.4285\n",
      "Step: 900, Val NLL: 219.0046, Acc: 0.4900, By Label: 0: 0.4729, 1: 0.5384\n",
      "Step: 1000, Val NLL: 198.4301, Acc: 0.4200, By Label: 0: 0.3918, 1: 0.5\n",
      "Step: 1100, Val NLL: 198.5161, Acc: 0.4300, By Label: 0: 0.4342, 1: 0.4166\n",
      "Step: 1200, Val NLL: 198.9433, Acc: 0.4900, By Label: 0: 0.4125, 1: 0.8\n",
      "Step: 1300, Val NLL: 187.8407, Acc: 0.4500, By Label: 0: 0.4084, 1: 0.5517\n",
      "Step: 1400, Val NLL: 211.7233, Acc: 0.4200, By Label: 0: 0.4125, 1: 0.45\n",
      "Step: 1500, Val NLL: 191.0856, Acc: 0.4900, By Label: 0: 0.4583, 1: 0.5714\n",
      "Step: 1600, Val NLL: 203.0397, Acc: 0.4400, By Label: 0: 0.4096, 1: 0.5882\n",
      "Step: 1700, Val NLL: 216.6092, Acc: 0.4400, By Label: 0: 0.4375, 1: 0.45\n",
      "Step: 1800, Val NLL: 207.5115, Acc: 0.4600, By Label: 0: 0.4594, 1: 0.4615\n",
      "Step: 1900, Val NLL: 233.9815, Acc: 0.3900, By Label: 0: 0.3717, 1: 0.4545\n",
      "Step: 2000, Val NLL: 252.8537, Acc: 0.4900, By Label: 0: 0.4878, 1: 0.5\n",
      "Step: 0, Val NLL: 290.6121, Acc: 0.4200, By Label: 0: 0.3958, 1: 0.4423\n",
      "Step: 100, Val NLL: 355.2213, Acc: 0.3200, By Label: 0: 0.2931, 1: 0.3571\n",
      "Step: 200, Val NLL: 296.5076, Acc: 0.4000, By Label: 0: 0.2888, 1: 0.4909\n",
      "Step: 300, Val NLL: 219.9468, Acc: 0.4500, By Label: 0: 0.36, 1: 0.54\n",
      "Step: 400, Val NLL: 288.8413, Acc: 0.4700, By Label: 0: 0.4583, 1: 0.4807\n",
      "Step: 500, Val NLL: 280.1645, Acc: 0.4200, By Label: 0: 0.4385, 1: 0.3953\n",
      "Step: 600, Val NLL: 250.8349, Acc: 0.4500, By Label: 0: 0.4181, 1: 0.4888\n",
      "Step: 700, Val NLL: 293.8246, Acc: 0.5000, By Label: 0: 0.4482, 1: 0.5714\n",
      "Step: 800, Val NLL: 259.7611, Acc: 0.4700, By Label: 0: 0.4883, 1: 0.4561\n",
      "Step: 900, Val NLL: 309.1606, Acc: 0.4300, By Label: 0: 0.3703, 1: 0.5\n",
      "Step: 1000, Val NLL: 252.4454, Acc: 0.4500, By Label: 0: 0.4716, 1: 0.4255\n",
      "Step: 1100, Val NLL: 266.5021, Acc: 0.4200, By Label: 0: 0.3695, 1: 0.4629\n",
      "Step: 0, Val NLL: 406.7936, Acc: 0.3000, By Label: 0: 0.2777, 1: 0.5\n",
      "Step: 100, Val NLL: 292.3515, Acc: 0.3900, By Label: 0: 0.3604, 1: 0.5714\n",
      "Step: 200, Val NLL: 380.2633, Acc: 0.2500, By Label: 0: 0.2068, 1: 0.5384\n",
      "Step: 300, Val NLL: 392.3091, Acc: 0.3200, By Label: 0: 0.2727, 1: 0.6666\n",
      "Step: 400, Val NLL: 399.7958, Acc: 0.3000, By Label: 0: 0.2386, 1: 0.75\n",
      "Step: 500, Val NLL: 367.3756, Acc: 0.3600, By Label: 0: 0.2926, 1: 0.6666\n",
      "Step: 600, Val NLL: 366.9332, Acc: 0.2900, By Label: 0: 0.2405, 1: 0.4761\n",
      "Step: 700, Val NLL: 343.8350, Acc: 0.3500, By Label: 0: 0.3170, 1: 0.5\n",
      "Step: 800, Val NLL: 287.1539, Acc: 0.3800, By Label: 0: 0.3707, 1: 0.4545\n",
      "Step: 900, Val NLL: 343.9374, Acc: 0.3300, By Label: 0: 0.2619, 1: 0.6875\n",
      "Step: 1000, Val NLL: 428.2990, Acc: 0.3900, By Label: 0: 0.3164, 1: 0.6666\n",
      "Step: 1100, Val NLL: 396.2593, Acc: 0.3300, By Label: 0: 0.2823, 1: 0.6\n",
      "Step: 1200, Val NLL: 367.0958, Acc: 0.3300, By Label: 0: 0.3111, 1: 0.5\n",
      "Step: 1300, Val NLL: 332.8911, Acc: 0.3600, By Label: 0: 0.3181, 1: 0.6666\n",
      "Step: 1400, Val NLL: 378.5279, Acc: 0.2900, By Label: 0: 0.2068, 1: 0.8461\n",
      "Step: 1500, Val NLL: 403.0594, Acc: 0.3000, By Label: 0: 0.2765, 1: 0.6666\n",
      "Epoch: 0, Val NLL: 349.1061, Tile-Level Acc: 0.4078, By Label: 0: 0.3604, 1: 0.5346\n",
      "------ Slide-Level Acc (Mean-Pooling): 0.3358, By Label: 0: 0.2244, 1: 0.6388\n",
      "------ Slide-Level Acc (Max-Pooling): 0.2687, By Label: 0: 0.0, 1: 1.0\n"
     ]
    }
   ],
   "source": [
    "e = 0\n",
    "val_loss, tile_acc, slide_acc = train_utils.maml_validate_all(e, resnet, model_global, val_loaders, criterion=nn.BCEWithLogitsLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, Train NLL: 566.9117, Acc: 0.3200, By Label: 0: 0.0, 1: 1.0\n",
      "Step: 50, Train NLL: 0.7116, Acc: 0.6800, By Label: 0: 1.0, 1: 0.0588\n",
      "Step: 100, Train NLL: 0.6816, Acc: 0.7400, By Label: 0: 1.0, 1: 0.0\n",
      "Step: 150, Train NLL: 0.7392, Acc: 0.7200, By Label: 0: 1.0, 1: 0.0\n",
      "Step: 200, Train NLL: 0.7264, Acc: 0.7400, By Label: 0: 1.0, 1: 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-64d855c32029>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--- LR DECAY --- Alpha: {0:0.8f}, Eta: {1:0.8f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mtiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMP_STATUS_CHECK_INTERVAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/anaconda3/lib/python3.6/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train meta-learner\n",
    "for e in range(num_epochs):\n",
    "    # reduce LR on plateau\n",
    "    if patience_count > patience:\n",
    "        alpha = factor * alpha\n",
    "        eta = factor * eta\n",
    "        patience_count = 0\n",
    "        print('--- LR DECAY --- Alpha: {0:0.8f}, Eta: {1:0.8f}'.format(alpha, eta))\n",
    "    \n",
    "    for step, (tiles, labels) in enumerate(train_loader):  \n",
    "        tiles, labels = tiles.cuda(), labels.cuda().float()           \n",
    "        grads, local_models = train_utils.maml_train_local(step, tiles, labels, resnet, local_models, alpha = alpha)\n",
    "        theta_global, model_global = train_utils.maml_train_global(theta_global, model_global, grads, eta = eta)\n",
    "        for i in range(len(local_models)):\n",
    "            local_models[i].update_params(theta_global)\n",
    "            \n",
    "    loss, acc, mean_pool_acc = train_utils.maml_validate(e, resnet, model_global, val_loader)\n",
    "    \n",
    "    if loss > previous_loss:\n",
    "        patience_count += 1\n",
    "    else:\n",
    "        patience_count = 0\n",
    "        \n",
    "    previous_loss = loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, Val NLL: 0.7332, Acc: 0.7100, By Label: 0: 0.9330, 1: 0.0526\n",
      "Step: 50, Val NLL: 0.7045, Acc: 0.7067, By Label: 0: 0.9398, 1: 0.1071\n",
      "Step: 100, Val NLL: 0.6924, Acc: 0.7100, By Label: 0: 0.9571, 1: 0.1333\n",
      "Step: 150, Val NLL: 0.7229, Acc: 0.7167, By Label: 0: 0.9452, 1: 0.0987\n",
      "Step: 200, Val NLL: 0.7237, Acc: 0.6800, By Label: 0: 0.9377, 1: 0.0879\n",
      "Step: 250, Val NLL: 0.7034, Acc: 0.7033, By Label: 0: 0.9369, 1: 0.0384\n",
      "Step: 300, Val NLL: 0.6934, Acc: 0.6867, By Label: 0: 0.9336, 1: 0.1011\n",
      "Step: 350, Val NLL: 0.7325, Acc: 0.6833, By Label: 0: 0.9436, 1: 0.0459\n",
      "Step: 400, Val NLL: 0.7169, Acc: 0.6967, By Label: 0: 0.9248, 1: 0.1379\n",
      "Step: 450, Val NLL: 0.7155, Acc: 0.7533, By Label: 0: 0.9511, 1: 0.16\n",
      "Step: 500, Val NLL: 0.7533, Acc: 0.7233, By Label: 0: 0.9372, 1: 0.1038\n",
      "Step: 550, Val NLL: 0.7105, Acc: 0.7033, By Label: 0: 0.9209, 1: 0.1529\n",
      "Step: 600, Val NLL: 0.7235, Acc: 0.6867, By Label: 0: 0.9086, 1: 0.0864\n",
      "Step: 650, Val NLL: 0.6936, Acc: 0.7033, By Label: 0: 0.9311, 1: 0.0975\n",
      "Step: 700, Val NLL: 0.7152, Acc: 0.6933, By Label: 0: 0.9386, 1: 0.1022\n",
      "Step: 750, Val NLL: 0.7106, Acc: 0.7300, By Label: 0: 0.9638, 1: 0.0759\n",
      "Step: 800, Val NLL: 0.7160, Acc: 0.7633, By Label: 0: 0.9778, 1: 0.1081\n",
      "Step: 850, Val NLL: 0.6996, Acc: 0.7300, By Label: 0: 0.9549, 1: 0.0897\n",
      "Step: 900, Val NLL: 0.7380, Acc: 0.7200, By Label: 0: 0.9330, 1: 0.0921\n",
      "Step: 950, Val NLL: 0.6976, Acc: 0.7233, By Label: 0: 0.9459, 1: 0.0897\n",
      "Step: 1000, Val NLL: 0.6922, Acc: 0.7133, By Label: 0: 0.9541, 1: 0.0731\n",
      "Step: 1050, Val NLL: 0.7157, Acc: 0.7267, By Label: 0: 0.9633, 1: 0.0975\n",
      "Step: 1100, Val NLL: 0.7010, Acc: 0.7233, By Label: 0: 0.9414, 1: 0.1025\n",
      "Step: 1150, Val NLL: 0.7446, Acc: 0.7200, By Label: 0: 0.9333, 1: 0.08\n",
      "Epoch: 0, Val NLL: 0.7478, Acc: 0.7135, By Label: 0: 0.9420, 1: 0.0894\n"
     ]
    }
   ],
   "source": [
    "loss, acc = run_validation(e, resnet, model_global, val_loader) # batch size = 200, lr = 0.1, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, Val NLL: 0.9906, Acc: 0.6233, By Label: 0: 0.7336, 1: 0.2676\n",
      "Step: 50, Val NLL: 1.1043, Acc: 0.6100, By Label: 0: 0.7370, 1: 0.2988\n",
      "Step: 100, Val NLL: 0.9727, Acc: 0.6633, By Label: 0: 0.7782, 1: 0.3417\n",
      "Step: 150, Val NLL: 1.1521, Acc: 0.6033, By Label: 0: 0.7162, 1: 0.3176\n",
      "Step: 200, Val NLL: 1.2545, Acc: 0.5800, By Label: 0: 0.7017, 1: 0.1944\n",
      "Step: 250, Val NLL: 1.2396, Acc: 0.6133, By Label: 0: 0.7534, 1: 0.2345\n",
      "Step: 300, Val NLL: 1.3489, Acc: 0.5767, By Label: 0: 0.7242, 1: 0.2093\n",
      "Step: 350, Val NLL: 0.8989, Acc: 0.6733, By Label: 0: 0.7973, 1: 0.2876\n",
      "Step: 400, Val NLL: 1.1073, Acc: 0.5800, By Label: 0: 0.6950, 1: 0.2467\n",
      "Step: 450, Val NLL: 1.1416, Acc: 0.5933, By Label: 0: 0.7104, 1: 0.2658\n",
      "Step: 500, Val NLL: 1.1372, Acc: 0.6200, By Label: 0: 0.7268, 1: 0.3452\n",
      "Step: 550, Val NLL: 1.0899, Acc: 0.6467, By Label: 0: 0.7899, 1: 0.2592\n",
      "Step: 600, Val NLL: 1.0686, Acc: 0.6200, By Label: 0: 0.7314, 1: 0.3333\n",
      "Step: 650, Val NLL: 1.2468, Acc: 0.6033, By Label: 0: 0.7053, 1: 0.3026\n",
      "Step: 700, Val NLL: 1.2153, Acc: 0.5933, By Label: 0: 0.7351, 1: 0.2098\n",
      "Step: 750, Val NLL: 1.2087, Acc: 0.5700, By Label: 0: 0.6985, 1: 0.2747\n",
      "Step: 800, Val NLL: 1.0931, Acc: 0.5933, By Label: 0: 0.7320, 1: 0.2747\n",
      "Step: 850, Val NLL: 1.0909, Acc: 0.6133, By Label: 0: 0.7731, 1: 0.2023\n",
      "Step: 900, Val NLL: 0.9876, Acc: 0.6767, By Label: 0: 0.8380, 1: 0.3\n",
      "Step: 950, Val NLL: 1.0360, Acc: 0.6333, By Label: 0: 0.7467, 1: 0.2388\n",
      "Step: 1000, Val NLL: 1.2623, Acc: 0.6033, By Label: 0: 0.7649, 1: 0.1807\n",
      "Step: 1050, Val NLL: 0.9999, Acc: 0.6400, By Label: 0: 0.7692, 1: 0.2784\n",
      "Step: 1100, Val NLL: 1.0177, Acc: 0.5900, By Label: 0: 0.7318, 1: 0.2\n",
      "Step: 1150, Val NLL: 1.2845, Acc: 0.6233, By Label: 0: 0.7942, 1: 0.2307\n",
      "Epoch: 0, Val NLL: 0.9291, Acc: 0.6147, By Label: 0: 0.7436, 1: 0.2626\n"
     ]
    }
   ],
   "source": [
    "loss, acc = run_validation(e, resnet, model_global, val_loader) # batch_size = 100, lr = 0.01, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, Val NLL: 67.1556, Acc: 0.5233, By Label: 0: 0.5450, 1: 0.4615\n",
      "Step: 50, Val NLL: 71.8051, Acc: 0.5000, By Label: 0: 0.4932, 1: 0.5189\n",
      "Step: 100, Val NLL: 65.5996, Acc: 0.5000, By Label: 0: 0.4892, 1: 0.5373\n",
      "Step: 150, Val NLL: 81.1949, Acc: 0.4800, By Label: 0: 0.4545, 1: 0.55\n",
      "Step: 200, Val NLL: 70.8121, Acc: 0.5000, By Label: 0: 0.5090, 1: 0.4743\n",
      "Step: 250, Val NLL: 62.1865, Acc: 0.6067, By Label: 0: 0.5844, 1: 0.6666\n",
      "Step: 300, Val NLL: 67.4404, Acc: 0.4633, By Label: 0: 0.4511, 1: 0.4941\n",
      "Step: 350, Val NLL: 65.1226, Acc: 0.4867, By Label: 0: 0.4841, 1: 0.4936\n",
      "Step: 400, Val NLL: 72.8518, Acc: 0.4867, By Label: 0: 0.4633, 1: 0.5487\n",
      "Step: 450, Val NLL: 66.6190, Acc: 0.5267, By Label: 0: 0.4837, 1: 0.6352\n",
      "Step: 500, Val NLL: 71.3242, Acc: 0.4967, By Label: 0: 0.5142, 1: 0.4555\n",
      "Step: 550, Val NLL: 76.1082, Acc: 0.4967, By Label: 0: 0.5022, 1: 0.48\n",
      "Step: 600, Val NLL: 71.5169, Acc: 0.4967, By Label: 0: 0.4882, 1: 0.5172\n",
      "Step: 650, Val NLL: 63.6326, Acc: 0.5133, By Label: 0: 0.5, 1: 0.5487\n",
      "Step: 700, Val NLL: 66.5611, Acc: 0.5133, By Label: 0: 0.5116, 1: 0.5176\n",
      "Step: 750, Val NLL: 63.7524, Acc: 0.5167, By Label: 0: 0.4809, 1: 0.6\n",
      "Step: 800, Val NLL: 70.6765, Acc: 0.5000, By Label: 0: 0.5164, 1: 0.4597\n",
      "Step: 850, Val NLL: 65.9089, Acc: 0.5000, By Label: 0: 0.5069, 1: 0.4819\n",
      "Step: 900, Val NLL: 63.2968, Acc: 0.4833, By Label: 0: 0.4533, 1: 0.5733\n",
      "Step: 950, Val NLL: 66.1024, Acc: 0.5133, By Label: 0: 0.5267, 1: 0.4736\n",
      "Step: 1000, Val NLL: 73.2435, Acc: 0.4800, By Label: 0: 0.4423, 1: 0.5783\n",
      "Step: 1050, Val NLL: 82.5915, Acc: 0.4700, By Label: 0: 0.4788, 1: 0.4482\n",
      "Step: 1100, Val NLL: 71.3002, Acc: 0.4567, By Label: 0: 0.4117, 1: 0.5822\n",
      "Step: 1150, Val NLL: 66.1497, Acc: 0.4533, By Label: 0: 0.4150, 1: 0.5454\n",
      "Epoch: 0, Val NLL: 77.5103, Tile-Level Acc: 0.4919, By Label: 0: 0.4874, 1: 0.5040\n",
      "------ Slide-Level Acc (Mean-Pooling): 0.4519, By Label: 0: 0.3947, 1: 0.6071\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-a47f59f5d180>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_global\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# batch_size = 100, lr = 1e-4, SGD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "loss, acc, mean_pool_acc = run_validation(e, resnet, model_global, val_loader) # batch_size = 100, lr = 1e-4, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

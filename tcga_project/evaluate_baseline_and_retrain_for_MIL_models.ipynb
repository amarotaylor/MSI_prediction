{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import psutil\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, set_image_backend\n",
    "\n",
    "import data_utils\n",
    "import train_utils\n",
    "import model_utils\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "set_image_backend('accimage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = 1\n",
    "state_dict_file = '/n/tcga_models/resnet18_WGD_10x.pt'\n",
    "resnet = models.resnet18(pretrained=False)\n",
    "resnet.fc = nn.Linear(2048, output_size)\n",
    "saved_state = torch.load(state_dict_file, map_location=lambda storage, loc: storage)\n",
    "resnet.load_state_dict(saved_state)\n",
    "for p in resnet.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = '/n/data_labeled_histopathology_images/COAD/train.pkl'\n",
    "with open(pickle_file, 'rb') as f: \n",
    "    train_embeddings,train_labels,train_jpgs_to_slide = pickle.load(f)\n",
    "    \n",
    "pickle_file = '/n/data_labeled_histopathology_images/COAD/val.pkl'\n",
    "with open(pickle_file, 'rb') as f: \n",
    "    val_embeddings,val_labels,val_jpgs_to_slide = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_fc = resnet.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = train_jpgs_to_slide.max()+1\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "logits_vec = torch.zeros((n_samples,1)).cuda()\n",
    "labels_vec = torch.zeros_like(logits_vec).cuda()\n",
    "train_embeddings = train_embeddings.cuda()\n",
    "resnet_fc.cuda()\n",
    "\n",
    "for idx in range(n_samples):\n",
    "    with torch.no_grad():\n",
    "        slide = train_embeddings[train_jpgs_to_slide==idx]\n",
    "        labels_vec[idx] = train_labels[train_jpgs_to_slide==idx].unique().float().cuda()\n",
    "        logits_vec[idx] = torch.mean(resnet_fc(slide))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.808641975308642"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(labels_vec.cpu().numpy() == (logits_vec>0.5).float().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = val_jpgs_to_slide.max()+1\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "logits_vec = torch.zeros((n_samples,1)).cuda()\n",
    "labels_vec = torch.zeros_like(logits_vec).cuda()\n",
    "val_embeddings = val_embeddings.cuda()\n",
    "resnet_fc.cuda()\n",
    "\n",
    "for idx in range(n_samples):\n",
    "    with torch.no_grad():\n",
    "        slide = val_embeddings[val_jpgs_to_slide==idx]\n",
    "        labels_vec[idx] = val_labels[val_jpgs_to_slide==idx].unique().float().cuda()\n",
    "        logits_vec[idx] = torch.mean(resnet_fc(slide))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6097560975609756"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(labels_vec.cpu().numpy() == (logits_vec>0.5).float().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9982, device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "criterion(logits_vec, labels_vec) * n_samples / 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnr_layer = nn.Linear(2048,2048)\n",
    "lnr_layer_2 = nn.Linear(2048,1)\n",
    "relu = nn.ReLU()\n",
    "layers = [lnr_layer, relu, lnr_layer_2]\n",
    "linear_layer = nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_embeddings = train_embeddings.cuda()\n",
    "net = model_utils.Attention(input_size=2048,hidden_size=2048,output_size=1)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "step_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attention(\n",
       "  (V): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "  (w): Linear(in_features=2048, out_features=1, bias=True)\n",
       "  (sigm): Sigmoid()\n",
       "  (tanh): Tanh()\n",
       "  (sm): Softmax()\n",
       "  (linear_layer): Linear(in_features=2048, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-5\n",
    "optimizer = torch.optim.Adam(params=net.parameters(),lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,patience=3,min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_val = val_jpgs_to_slide.max()\n",
    "n_samples_train = train_jpgs_to_slide.max()\n",
    "idxs_train = np.linspace(0,n_samples_train,n_samples_train+1,dtype=int)\n",
    "labels_to_idxs_train = np.concatenate([(train_labels[train_jpgs_to_slide==i]).unique().numpy() for i in idxs_train])\n",
    "weights = 1/np.sum(labels_to_idxs_train==0),1/np.sum(labels_to_idxs_train==1)\n",
    "sample_weight = [weights[l] for l in labels_to_idxs_train]\n",
    "sample_weight = sample_weight/np.sum(sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train NLL: 0.7205\n",
      "Epoch: 0, Validation NLL: 0.6953, Total Acc: 0.561, Acc by label; diploid:1.000 WGD:0.000\n",
      "Epoch: 1, Train NLL: 0.7094\n",
      "Epoch: 1, Validation NLL: 0.6912, Total Acc: 0.561, Acc by label; diploid:1.000 WGD:0.000\n",
      "Epoch: 2, Train NLL: 0.6937\n",
      "Epoch: 2, Validation NLL: 0.6877, Total Acc: 0.561, Acc by label; diploid:1.000 WGD:0.000\n",
      "Epoch: 3, Train NLL: 0.7000\n",
      "Epoch: 3, Validation NLL: 0.6869, Total Acc: 0.561, Acc by label; diploid:1.000 WGD:0.000\n",
      "Epoch: 4, Train NLL: 0.6924\n",
      "Epoch: 4, Validation NLL: 0.6865, Total Acc: 0.561, Acc by label; diploid:1.000 WGD:0.000\n",
      "Epoch: 5, Train NLL: 0.6859\n",
      "Epoch: 5, Validation NLL: 0.6854, Total Acc: 0.561, Acc by label; diploid:1.000 WGD:0.000\n",
      "Epoch: 6, Train NLL: 0.6918\n",
      "Epoch: 6, Validation NLL: 0.6833, Total Acc: 0.561, Acc by label; diploid:1.000 WGD:0.000\n",
      "Epoch: 7, Train NLL: 0.6911\n",
      "Epoch: 7, Validation NLL: 0.6817, Total Acc: 0.561, Acc by label; diploid:1.000 WGD:0.000\n",
      "Epoch: 8, Train NLL: 0.6781\n",
      "Epoch: 8, Validation NLL: 0.6816, Total Acc: 0.561, Acc by label; diploid:1.000 WGD:0.000\n",
      "Epoch: 9, Train NLL: 0.6913\n",
      "Epoch: 9, Validation NLL: 0.6809, Total Acc: 0.561, Acc by label; diploid:1.000 WGD:0.000\n",
      "Epoch: 10, Train NLL: 0.6830\n",
      "Epoch: 10, Validation NLL: 0.6807, Total Acc: 0.561, Acc by label; diploid:1.000 WGD:0.000\n",
      "Epoch: 11, Train NLL: 0.6648\n",
      "Epoch: 11, Validation NLL: 0.6814, Total Acc: 0.549, Acc by label; diploid:0.978 WGD:0.000\n",
      "Epoch: 12, Train NLL: 0.6769\n",
      "Epoch: 12, Validation NLL: 0.6805, Total Acc: 0.561, Acc by label; diploid:0.978 WGD:0.028\n",
      "Epoch: 13, Train NLL: 0.6707\n",
      "Epoch: 13, Validation NLL: 0.6767, Total Acc: 0.561, Acc by label; diploid:0.978 WGD:0.028\n",
      "Epoch: 14, Train NLL: 0.6560\n",
      "Epoch: 14, Validation NLL: 0.6710, Total Acc: 0.561, Acc by label; diploid:1.000 WGD:0.000\n",
      "Epoch: 15, Train NLL: 0.6690\n",
      "Epoch: 15, Validation NLL: 0.6672, Total Acc: 0.561, Acc by label; diploid:1.000 WGD:0.000\n",
      "Epoch: 16, Train NLL: 0.6568\n",
      "Epoch: 16, Validation NLL: 0.6673, Total Acc: 0.549, Acc by label; diploid:0.978 WGD:0.000\n",
      "Epoch: 17, Train NLL: 0.6478\n",
      "Epoch: 17, Validation NLL: 0.6675, Total Acc: 0.549, Acc by label; diploid:0.957 WGD:0.028\n",
      "Epoch: 18, Train NLL: 0.6478\n",
      "Epoch: 18, Validation NLL: 0.6693, Total Acc: 0.561, Acc by label; diploid:0.957 WGD:0.056\n",
      "Epoch: 19, Train NLL: 0.6614\n",
      "Epoch: 19, Validation NLL: 0.6668, Total Acc: 0.561, Acc by label; diploid:0.957 WGD:0.056\n",
      "Epoch: 20, Train NLL: 0.6471\n",
      "Epoch: 20, Validation NLL: 0.6614, Total Acc: 0.561, Acc by label; diploid:0.957 WGD:0.056\n",
      "Epoch: 21, Train NLL: 0.6293\n",
      "Epoch: 21, Validation NLL: 0.6567, Total Acc: 0.573, Acc by label; diploid:0.978 WGD:0.056\n",
      "Epoch: 22, Train NLL: 0.6404\n",
      "Epoch: 22, Validation NLL: 0.6566, Total Acc: 0.573, Acc by label; diploid:0.957 WGD:0.083\n",
      "Epoch: 23, Train NLL: 0.6256\n",
      "Epoch: 23, Validation NLL: 0.6569, Total Acc: 0.598, Acc by label; diploid:0.957 WGD:0.139\n",
      "Epoch: 24, Train NLL: 0.6195\n",
      "Epoch: 24, Validation NLL: 0.6562, Total Acc: 0.622, Acc by label; diploid:0.957 WGD:0.194\n",
      "Epoch: 25, Train NLL: 0.6200\n",
      "Epoch: 25, Validation NLL: 0.6556, Total Acc: 0.610, Acc by label; diploid:0.935 WGD:0.194\n",
      "Epoch: 26, Train NLL: 0.6209\n",
      "Epoch: 26, Validation NLL: 0.6588, Total Acc: 0.634, Acc by label; diploid:0.913 WGD:0.278\n",
      "Epoch: 27, Train NLL: 0.6311\n",
      "Epoch: 27, Validation NLL: 0.6531, Total Acc: 0.634, Acc by label; diploid:0.935 WGD:0.250\n",
      "Epoch: 28, Train NLL: 0.6025\n",
      "Epoch: 28, Validation NLL: 0.6507, Total Acc: 0.634, Acc by label; diploid:0.935 WGD:0.250\n",
      "Epoch: 29, Train NLL: 0.6165\n",
      "Epoch: 29, Validation NLL: 0.6569, Total Acc: 0.671, Acc by label; diploid:0.913 WGD:0.361\n",
      "Epoch: 30, Train NLL: 0.6153\n",
      "Epoch: 30, Validation NLL: 0.6620, Total Acc: 0.683, Acc by label; diploid:0.913 WGD:0.389\n",
      "Epoch: 31, Train NLL: 0.5905\n",
      "Epoch: 31, Validation NLL: 0.6626, Total Acc: 0.695, Acc by label; diploid:0.891 WGD:0.444\n",
      "Epoch: 32, Train NLL: 0.6173\n",
      "Epoch: 32, Validation NLL: 0.6463, Total Acc: 0.695, Acc by label; diploid:0.935 WGD:0.389\n",
      "Epoch: 33, Train NLL: 0.5869\n",
      "Epoch: 33, Validation NLL: 0.6347, Total Acc: 0.659, Acc by label; diploid:0.935 WGD:0.306\n",
      "Epoch: 34, Train NLL: 0.5896\n",
      "Epoch: 34, Validation NLL: 0.6268, Total Acc: 0.671, Acc by label; diploid:0.978 WGD:0.278\n",
      "Epoch: 35, Train NLL: 0.5686\n",
      "Epoch: 35, Validation NLL: 0.6255, Total Acc: 0.707, Acc by label; diploid:0.978 WGD:0.361\n",
      "Epoch: 36, Train NLL: 0.5666\n",
      "Epoch: 36, Validation NLL: 0.6349, Total Acc: 0.695, Acc by label; diploid:0.913 WGD:0.417\n",
      "Epoch: 37, Train NLL: 0.5464\n",
      "Epoch: 37, Validation NLL: 0.6410, Total Acc: 0.683, Acc by label; diploid:0.826 WGD:0.500\n",
      "Epoch: 38, Train NLL: 0.5733\n",
      "Epoch: 38, Validation NLL: 0.6313, Total Acc: 0.695, Acc by label; diploid:0.913 WGD:0.417\n",
      "Epoch: 39, Train NLL: 0.5465\n",
      "Epoch: 39, Validation NLL: 0.6253, Total Acc: 0.720, Acc by label; diploid:0.935 WGD:0.444\n",
      "Epoch: 40, Train NLL: 0.5721\n",
      "Epoch: 40, Validation NLL: 0.6193, Total Acc: 0.720, Acc by label; diploid:0.935 WGD:0.444\n",
      "Epoch: 41, Train NLL: 0.5661\n",
      "Epoch: 41, Validation NLL: 0.6222, Total Acc: 0.720, Acc by label; diploid:0.913 WGD:0.472\n",
      "Epoch: 42, Train NLL: 0.5560\n",
      "Epoch: 42, Validation NLL: 0.6271, Total Acc: 0.695, Acc by label; diploid:0.848 WGD:0.500\n",
      "Epoch: 43, Train NLL: 0.5375\n",
      "Epoch: 43, Validation NLL: 0.6144, Total Acc: 0.707, Acc by label; diploid:0.913 WGD:0.444\n",
      "Epoch: 44, Train NLL: 0.5090\n",
      "Epoch: 44, Validation NLL: 0.6043, Total Acc: 0.707, Acc by label; diploid:0.957 WGD:0.389\n",
      "Epoch: 45, Train NLL: 0.5272\n",
      "Epoch: 45, Validation NLL: 0.6035, Total Acc: 0.683, Acc by label; diploid:0.913 WGD:0.389\n",
      "Epoch: 46, Train NLL: 0.5406\n",
      "Epoch: 46, Validation NLL: 0.6086, Total Acc: 0.707, Acc by label; diploid:0.913 WGD:0.444\n",
      "Epoch: 47, Train NLL: 0.5117\n",
      "Epoch: 47, Validation NLL: 0.6049, Total Acc: 0.707, Acc by label; diploid:0.913 WGD:0.444\n",
      "Epoch: 48, Train NLL: 0.5118\n",
      "Epoch: 48, Validation NLL: 0.6049, Total Acc: 0.683, Acc by label; diploid:0.891 WGD:0.417\n",
      "Epoch: 49, Train NLL: 0.5221\n",
      "Epoch: 49, Validation NLL: 0.6068, Total Acc: 0.671, Acc by label; diploid:0.870 WGD:0.417\n",
      "Epoch: 50, Train NLL: 0.4764\n",
      "Epoch: 50, Validation NLL: 0.6072, Total Acc: 0.683, Acc by label; diploid:0.870 WGD:0.444\n",
      "Epoch: 51, Train NLL: 0.5312\n",
      "Epoch: 51, Validation NLL: 0.6067, Total Acc: 0.695, Acc by label; diploid:0.870 WGD:0.472\n",
      "Epoch: 52, Train NLL: 0.5322\n",
      "Epoch: 52, Validation NLL: 0.6055, Total Acc: 0.695, Acc by label; diploid:0.870 WGD:0.472\n",
      "Epoch: 53, Train NLL: 0.5422\n",
      "Epoch: 53, Validation NLL: 0.6050, Total Acc: 0.695, Acc by label; diploid:0.870 WGD:0.472\n",
      "Epoch: 54, Train NLL: 0.5432\n",
      "Epoch: 54, Validation NLL: 0.6049, Total Acc: 0.695, Acc by label; diploid:0.870 WGD:0.472\n",
      "Epoch: 55, Train NLL: 0.4976\n",
      "Epoch: 55, Validation NLL: 0.6045, Total Acc: 0.707, Acc by label; diploid:0.891 WGD:0.472\n",
      "Epoch: 56, Train NLL: 0.5001\n",
      "Epoch: 56, Validation NLL: 0.6038, Total Acc: 0.707, Acc by label; diploid:0.891 WGD:0.472\n",
      "Epoch: 57, Train NLL: 0.5112\n",
      "Epoch: 57, Validation NLL: 0.6039, Total Acc: 0.707, Acc by label; diploid:0.891 WGD:0.472\n",
      "Epoch: 58, Train NLL: 0.5216\n",
      "Epoch: 58, Validation NLL: 0.6037, Total Acc: 0.720, Acc by label; diploid:0.891 WGD:0.500\n",
      "Epoch: 59, Train NLL: 0.5201\n",
      "Epoch: 59, Validation NLL: 0.6036, Total Acc: 0.720, Acc by label; diploid:0.891 WGD:0.500\n",
      "Epoch: 60, Train NLL: 0.5068\n",
      "Epoch: 60, Validation NLL: 0.6041, Total Acc: 0.707, Acc by label; diploid:0.870 WGD:0.500\n",
      "Epoch: 61, Train NLL: 0.4962\n",
      "Epoch: 61, Validation NLL: 0.6046, Total Acc: 0.707, Acc by label; diploid:0.870 WGD:0.500\n",
      "Epoch: 62, Train NLL: 0.5111\n",
      "Epoch: 62, Validation NLL: 0.6046, Total Acc: 0.720, Acc by label; diploid:0.870 WGD:0.528\n",
      "Epoch: 63, Train NLL: 0.5376\n",
      "Epoch: 63, Validation NLL: 0.6044, Total Acc: 0.720, Acc by label; diploid:0.870 WGD:0.528\n",
      "Epoch: 64, Train NLL: 0.5278\n",
      "Epoch: 64, Validation NLL: 0.6037, Total Acc: 0.720, Acc by label; diploid:0.870 WGD:0.528\n",
      "Epoch: 65, Train NLL: 0.5057\n",
      "Epoch: 65, Validation NLL: 0.6033, Total Acc: 0.720, Acc by label; diploid:0.870 WGD:0.528\n",
      "Epoch: 66, Train NLL: 0.5044\n",
      "Epoch: 66, Validation NLL: 0.6024, Total Acc: 0.720, Acc by label; diploid:0.870 WGD:0.528\n",
      "Epoch: 67, Train NLL: 0.5097\n",
      "Epoch: 67, Validation NLL: 0.6013, Total Acc: 0.732, Acc by label; diploid:0.891 WGD:0.528\n",
      "Epoch: 68, Train NLL: 0.5137\n",
      "Epoch: 68, Validation NLL: 0.6005, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 69, Train NLL: 0.5212\n",
      "Epoch: 69, Validation NLL: 0.5991, Total Acc: 0.732, Acc by label; diploid:0.913 WGD:0.500\n",
      "Epoch: 70, Train NLL: 0.4857\n",
      "Epoch: 70, Validation NLL: 0.5981, Total Acc: 0.732, Acc by label; diploid:0.913 WGD:0.500\n",
      "Epoch: 71, Train NLL: 0.4942\n",
      "Epoch: 71, Validation NLL: 0.5975, Total Acc: 0.732, Acc by label; diploid:0.913 WGD:0.500\n",
      "Epoch: 72, Train NLL: 0.5247\n",
      "Epoch: 72, Validation NLL: 0.5971, Total Acc: 0.732, Acc by label; diploid:0.913 WGD:0.500\n",
      "Epoch: 73, Train NLL: 0.5084\n",
      "Epoch: 73, Validation NLL: 0.5972, Total Acc: 0.732, Acc by label; diploid:0.913 WGD:0.500\n",
      "Epoch: 74, Train NLL: 0.4891\n",
      "Epoch: 74, Validation NLL: 0.5975, Total Acc: 0.732, Acc by label; diploid:0.913 WGD:0.500\n",
      "Epoch: 75, Train NLL: 0.5094\n",
      "Epoch: 75, Validation NLL: 0.5977, Total Acc: 0.732, Acc by label; diploid:0.913 WGD:0.500\n",
      "Epoch: 76, Train NLL: 0.5332\n",
      "Epoch: 76, Validation NLL: 0.5971, Total Acc: 0.732, Acc by label; diploid:0.913 WGD:0.500\n",
      "Epoch: 77, Train NLL: 0.5259\n",
      "Epoch: 77, Validation NLL: 0.5960, Total Acc: 0.732, Acc by label; diploid:0.913 WGD:0.500\n",
      "Epoch: 78, Train NLL: 0.5112\n",
      "Epoch: 78, Validation NLL: 0.5955, Total Acc: 0.732, Acc by label; diploid:0.913 WGD:0.500\n",
      "Epoch: 79, Train NLL: 0.5167\n",
      "Epoch: 79, Validation NLL: 0.5950, Total Acc: 0.732, Acc by label; diploid:0.913 WGD:0.500\n",
      "Epoch: 80, Train NLL: 0.5025\n",
      "Epoch: 80, Validation NLL: 0.5948, Total Acc: 0.732, Acc by label; diploid:0.913 WGD:0.500\n",
      "Epoch: 81, Train NLL: 0.4959\n",
      "Epoch: 81, Validation NLL: 0.5953, Total Acc: 0.732, Acc by label; diploid:0.913 WGD:0.500\n",
      "Epoch: 82, Train NLL: 0.5207\n",
      "Epoch: 82, Validation NLL: 0.5954, Total Acc: 0.732, Acc by label; diploid:0.913 WGD:0.500\n",
      "Epoch: 83, Train NLL: 0.4940\n",
      "Epoch: 83, Validation NLL: 0.5960, Total Acc: 0.732, Acc by label; diploid:0.913 WGD:0.500\n",
      "Epoch: 84, Train NLL: 0.4772\n",
      "Epoch: 84, Validation NLL: 0.5968, Total Acc: 0.732, Acc by label; diploid:0.913 WGD:0.500\n",
      "Epoch: 85, Train NLL: 0.5176\n",
      "Epoch: 85, Validation NLL: 0.5977, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 86, Train NLL: 0.4937\n",
      "Epoch: 86, Validation NLL: 0.5977, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 87, Train NLL: 0.5091\n",
      "Epoch: 87, Validation NLL: 0.5976, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 88, Train NLL: 0.4874\n",
      "Epoch: 88, Validation NLL: 0.5981, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 89, Train NLL: 0.4574\n",
      "Epoch: 89, Validation NLL: 0.5983, Total Acc: 0.732, Acc by label; diploid:0.891 WGD:0.528\n",
      "Epoch: 90, Train NLL: 0.4520\n",
      "Epoch: 90, Validation NLL: 0.5982, Total Acc: 0.732, Acc by label; diploid:0.891 WGD:0.528\n",
      "Epoch: 91, Train NLL: 0.4999\n",
      "Epoch: 91, Validation NLL: 0.5979, Total Acc: 0.732, Acc by label; diploid:0.891 WGD:0.528\n",
      "Epoch: 92, Train NLL: 0.4943\n",
      "Epoch: 92, Validation NLL: 0.5975, Total Acc: 0.732, Acc by label; diploid:0.891 WGD:0.528\n",
      "Epoch: 93, Train NLL: 0.4778\n",
      "Epoch: 93, Validation NLL: 0.5959, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 94, Train NLL: 0.4833\n",
      "Epoch: 94, Validation NLL: 0.5952, Total Acc: 0.732, Acc by label; diploid:0.913 WGD:0.500\n",
      "Epoch: 95, Train NLL: 0.5064\n",
      "Epoch: 95, Validation NLL: 0.5955, Total Acc: 0.732, Acc by label; diploid:0.913 WGD:0.500\n",
      "Epoch: 96, Train NLL: 0.4790\n",
      "Epoch: 96, Validation NLL: 0.5961, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 97, Train NLL: 0.4901\n",
      "Epoch: 97, Validation NLL: 0.5954, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 98, Train NLL: 0.5154\n",
      "Epoch: 98, Validation NLL: 0.5941, Total Acc: 0.732, Acc by label; diploid:0.913 WGD:0.500\n",
      "Epoch: 99, Train NLL: 0.5009\n",
      "Epoch: 99, Validation NLL: 0.5930, Total Acc: 0.732, Acc by label; diploid:0.913 WGD:0.500\n",
      "Epoch: 100, Train NLL: 0.5186\n",
      "Epoch: 100, Validation NLL: 0.5919, Total Acc: 0.732, Acc by label; diploid:0.913 WGD:0.500\n",
      "Epoch: 101, Train NLL: 0.4740\n",
      "Epoch: 101, Validation NLL: 0.5906, Total Acc: 0.732, Acc by label; diploid:0.913 WGD:0.500\n",
      "Epoch: 102, Train NLL: 0.5051\n",
      "Epoch: 102, Validation NLL: 0.5900, Total Acc: 0.732, Acc by label; diploid:0.913 WGD:0.500\n",
      "Epoch: 103, Train NLL: 0.5064\n",
      "Epoch: 103, Validation NLL: 0.5898, Total Acc: 0.732, Acc by label; diploid:0.913 WGD:0.500\n",
      "Epoch: 104, Train NLL: 0.5049\n",
      "Epoch: 104, Validation NLL: 0.5894, Total Acc: 0.732, Acc by label; diploid:0.913 WGD:0.500\n",
      "Epoch: 105, Train NLL: 0.4995\n",
      "Epoch: 105, Validation NLL: 0.5898, Total Acc: 0.732, Acc by label; diploid:0.913 WGD:0.500\n",
      "Epoch: 106, Train NLL: 0.5111\n",
      "Epoch: 106, Validation NLL: 0.5902, Total Acc: 0.732, Acc by label; diploid:0.913 WGD:0.500\n",
      "Epoch: 107, Train NLL: 0.5086\n",
      "Epoch: 107, Validation NLL: 0.5907, Total Acc: 0.732, Acc by label; diploid:0.913 WGD:0.500\n",
      "Epoch: 108, Train NLL: 0.4822\n",
      "Epoch: 108, Validation NLL: 0.5917, Total Acc: 0.732, Acc by label; diploid:0.913 WGD:0.500\n",
      "Epoch: 109, Train NLL: 0.4940\n",
      "Epoch: 109, Validation NLL: 0.5932, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 110, Train NLL: 0.4798\n",
      "Epoch: 110, Validation NLL: 0.5949, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 111, Train NLL: 0.4885\n",
      "Epoch: 111, Validation NLL: 0.5957, Total Acc: 0.732, Acc by label; diploid:0.891 WGD:0.528\n",
      "Epoch: 112, Train NLL: 0.4900\n",
      "Epoch: 112, Validation NLL: 0.5960, Total Acc: 0.732, Acc by label; diploid:0.891 WGD:0.528\n",
      "Epoch: 113, Train NLL: 0.4886\n",
      "Epoch: 113, Validation NLL: 0.5966, Total Acc: 0.732, Acc by label; diploid:0.891 WGD:0.528\n",
      "Epoch: 114, Train NLL: 0.4744\n",
      "Epoch: 114, Validation NLL: 0.5965, Total Acc: 0.732, Acc by label; diploid:0.891 WGD:0.528\n",
      "Epoch: 115, Train NLL: 0.4967\n",
      "Epoch: 115, Validation NLL: 0.5969, Total Acc: 0.732, Acc by label; diploid:0.891 WGD:0.528\n",
      "Epoch: 116, Train NLL: 0.4961\n",
      "Epoch: 116, Validation NLL: 0.5957, Total Acc: 0.732, Acc by label; diploid:0.891 WGD:0.528\n",
      "Epoch: 117, Train NLL: 0.4883\n",
      "Epoch: 117, Validation NLL: 0.5942, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 118, Train NLL: 0.4745\n",
      "Epoch: 118, Validation NLL: 0.5935, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 119, Train NLL: 0.4856\n",
      "Epoch: 119, Validation NLL: 0.5934, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 120, Train NLL: 0.4931\n",
      "Epoch: 120, Validation NLL: 0.5921, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 121, Train NLL: 0.4743\n",
      "Epoch: 121, Validation NLL: 0.5914, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 122, Train NLL: 0.4879\n",
      "Epoch: 122, Validation NLL: 0.5912, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 123, Train NLL: 0.4679\n",
      "Epoch: 123, Validation NLL: 0.5910, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 124, Train NLL: 0.4804\n",
      "Epoch: 124, Validation NLL: 0.5902, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 125, Train NLL: 0.5039\n",
      "Epoch: 125, Validation NLL: 0.5900, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 126, Train NLL: 0.4698\n",
      "Epoch: 126, Validation NLL: 0.5894, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 127, Train NLL: 0.4859\n",
      "Epoch: 127, Validation NLL: 0.5894, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 128, Train NLL: 0.4746\n",
      "Epoch: 128, Validation NLL: 0.5889, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 129, Train NLL: 0.4881\n",
      "Epoch: 129, Validation NLL: 0.5881, Total Acc: 0.732, Acc by label; diploid:0.913 WGD:0.500\n",
      "Epoch: 130, Train NLL: 0.5013\n",
      "Epoch: 130, Validation NLL: 0.5881, Total Acc: 0.732, Acc by label; diploid:0.913 WGD:0.500\n",
      "Epoch: 131, Train NLL: 0.4764\n",
      "Epoch: 131, Validation NLL: 0.5888, Total Acc: 0.732, Acc by label; diploid:0.913 WGD:0.500\n",
      "Epoch: 132, Train NLL: 0.4544\n",
      "Epoch: 132, Validation NLL: 0.5889, Total Acc: 0.732, Acc by label; diploid:0.913 WGD:0.500\n",
      "Epoch: 133, Train NLL: 0.4489\n",
      "Epoch: 133, Validation NLL: 0.5895, Total Acc: 0.732, Acc by label; diploid:0.913 WGD:0.500\n",
      "Epoch: 134, Train NLL: 0.4560\n",
      "Epoch: 134, Validation NLL: 0.5900, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 135, Train NLL: 0.4778\n",
      "Epoch: 135, Validation NLL: 0.5901, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 136, Train NLL: 0.4902\n",
      "Epoch: 136, Validation NLL: 0.5902, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 137, Train NLL: 0.4845\n",
      "Epoch: 137, Validation NLL: 0.5898, Total Acc: 0.732, Acc by label; diploid:0.913 WGD:0.500\n",
      "Epoch: 138, Train NLL: 0.5121\n",
      "Epoch: 138, Validation NLL: 0.5895, Total Acc: 0.732, Acc by label; diploid:0.913 WGD:0.500\n",
      "Epoch: 139, Train NLL: 0.4511\n",
      "Epoch: 139, Validation NLL: 0.5891, Total Acc: 0.732, Acc by label; diploid:0.913 WGD:0.500\n",
      "Epoch: 140, Train NLL: 0.4526\n",
      "Epoch: 140, Validation NLL: 0.5897, Total Acc: 0.756, Acc by label; diploid:0.913 WGD:0.556\n",
      "Epoch: 141, Train NLL: 0.5023\n",
      "Epoch: 141, Validation NLL: 0.5906, Total Acc: 0.756, Acc by label; diploid:0.913 WGD:0.556\n",
      "Epoch: 142, Train NLL: 0.4808\n",
      "Epoch: 142, Validation NLL: 0.5914, Total Acc: 0.744, Acc by label; diploid:0.891 WGD:0.556\n",
      "Epoch: 143, Train NLL: 0.5039\n",
      "Epoch: 143, Validation NLL: 0.5923, Total Acc: 0.744, Acc by label; diploid:0.891 WGD:0.556\n",
      "Epoch: 144, Train NLL: 0.4729\n",
      "Epoch: 144, Validation NLL: 0.5927, Total Acc: 0.744, Acc by label; diploid:0.891 WGD:0.556\n",
      "Epoch: 145, Train NLL: 0.4750\n",
      "Epoch: 145, Validation NLL: 0.5924, Total Acc: 0.744, Acc by label; diploid:0.891 WGD:0.556\n",
      "Epoch: 146, Train NLL: 0.4930\n",
      "Epoch: 146, Validation NLL: 0.5919, Total Acc: 0.756, Acc by label; diploid:0.891 WGD:0.583\n",
      "Epoch: 147, Train NLL: 0.4762\n",
      "Epoch: 147, Validation NLL: 0.5917, Total Acc: 0.756, Acc by label; diploid:0.891 WGD:0.583\n",
      "Epoch: 148, Train NLL: 0.4437\n",
      "Epoch: 148, Validation NLL: 0.5913, Total Acc: 0.756, Acc by label; diploid:0.891 WGD:0.583\n",
      "Epoch: 149, Train NLL: 0.4553\n",
      "Epoch: 149, Validation NLL: 0.5906, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 150, Train NLL: 0.5106\n",
      "Epoch: 150, Validation NLL: 0.5899, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 151, Train NLL: 0.4883\n",
      "Epoch: 151, Validation NLL: 0.5892, Total Acc: 0.756, Acc by label; diploid:0.913 WGD:0.556\n",
      "Epoch: 152, Train NLL: 0.4545\n",
      "Epoch: 152, Validation NLL: 0.5882, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 153, Train NLL: 0.4799\n",
      "Epoch: 153, Validation NLL: 0.5886, Total Acc: 0.756, Acc by label; diploid:0.913 WGD:0.556\n",
      "Epoch: 154, Train NLL: 0.4738\n",
      "Epoch: 154, Validation NLL: 0.5890, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 155, Train NLL: 0.4785\n",
      "Epoch: 155, Validation NLL: 0.5892, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 156, Train NLL: 0.4774\n",
      "Epoch: 156, Validation NLL: 0.5891, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 157, Train NLL: 0.4760\n",
      "Epoch: 157, Validation NLL: 0.5886, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 158, Train NLL: 0.4799\n",
      "Epoch: 158, Validation NLL: 0.5887, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 159, Train NLL: 0.4458\n",
      "Epoch: 159, Validation NLL: 0.5881, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 160, Train NLL: 0.5008\n",
      "Epoch: 160, Validation NLL: 0.5882, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 161, Train NLL: 0.4694\n",
      "Epoch: 161, Validation NLL: 0.5887, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 162, Train NLL: 0.4801\n",
      "Epoch: 162, Validation NLL: 0.5876, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 163, Train NLL: 0.4716\n",
      "Epoch: 163, Validation NLL: 0.5867, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 164, Train NLL: 0.4770\n",
      "Epoch: 164, Validation NLL: 0.5859, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 165, Train NLL: 0.4659\n",
      "Epoch: 165, Validation NLL: 0.5853, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 166, Train NLL: 0.4613\n",
      "Epoch: 166, Validation NLL: 0.5840, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 167, Train NLL: 0.4379\n",
      "Epoch: 167, Validation NLL: 0.5835, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 168, Train NLL: 0.4550\n",
      "Epoch: 168, Validation NLL: 0.5828, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 169, Train NLL: 0.4727\n",
      "Epoch: 169, Validation NLL: 0.5832, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 170, Train NLL: 0.4474\n",
      "Epoch: 170, Validation NLL: 0.5833, Total Acc: 0.756, Acc by label; diploid:0.913 WGD:0.556\n",
      "Epoch: 171, Train NLL: 0.4947\n",
      "Epoch: 171, Validation NLL: 0.5828, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 172, Train NLL: 0.4680\n",
      "Epoch: 172, Validation NLL: 0.5823, Total Acc: 0.756, Acc by label; diploid:0.913 WGD:0.556\n",
      "Epoch: 173, Train NLL: 0.4486\n",
      "Epoch: 173, Validation NLL: 0.5817, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 174, Train NLL: 0.4832\n",
      "Epoch: 174, Validation NLL: 0.5807, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 175, Train NLL: 0.5029\n",
      "Epoch: 175, Validation NLL: 0.5797, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 176, Train NLL: 0.4288\n",
      "Epoch: 176, Validation NLL: 0.5790, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 177, Train NLL: 0.4919\n",
      "Epoch: 177, Validation NLL: 0.5788, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 178, Train NLL: 0.4695\n",
      "Epoch: 178, Validation NLL: 0.5796, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 179, Train NLL: 0.4594\n",
      "Epoch: 179, Validation NLL: 0.5799, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 180, Train NLL: 0.4681\n",
      "Epoch: 180, Validation NLL: 0.5794, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 181, Train NLL: 0.4516\n",
      "Epoch: 181, Validation NLL: 0.5788, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 182, Train NLL: 0.4614\n",
      "Epoch: 182, Validation NLL: 0.5783, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 183, Train NLL: 0.4605\n",
      "Epoch: 183, Validation NLL: 0.5781, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 184, Train NLL: 0.4652\n",
      "Epoch: 184, Validation NLL: 0.5782, Total Acc: 0.756, Acc by label; diploid:0.913 WGD:0.556\n",
      "Epoch: 185, Train NLL: 0.4776\n",
      "Epoch: 185, Validation NLL: 0.5783, Total Acc: 0.756, Acc by label; diploid:0.913 WGD:0.556\n",
      "Epoch: 186, Train NLL: 0.4400\n",
      "Epoch: 186, Validation NLL: 0.5781, Total Acc: 0.756, Acc by label; diploid:0.913 WGD:0.556\n",
      "Epoch: 187, Train NLL: 0.4573\n",
      "Epoch: 187, Validation NLL: 0.5774, Total Acc: 0.756, Acc by label; diploid:0.913 WGD:0.556\n",
      "Epoch: 188, Train NLL: 0.4572\n",
      "Epoch: 188, Validation NLL: 0.5771, Total Acc: 0.756, Acc by label; diploid:0.913 WGD:0.556\n",
      "Epoch: 189, Train NLL: 0.4679\n",
      "Epoch: 189, Validation NLL: 0.5761, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 190, Train NLL: 0.4715\n",
      "Epoch: 190, Validation NLL: 0.5754, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 191, Train NLL: 0.4720\n",
      "Epoch: 191, Validation NLL: 0.5751, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 192, Train NLL: 0.4754\n",
      "Epoch: 192, Validation NLL: 0.5752, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 193, Train NLL: 0.4794\n",
      "Epoch: 193, Validation NLL: 0.5754, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 194, Train NLL: 0.4603\n",
      "Epoch: 194, Validation NLL: 0.5764, Total Acc: 0.744, Acc by label; diploid:0.913 WGD:0.528\n",
      "Epoch: 195, Train NLL: 0.4399\n",
      "Epoch: 195, Validation NLL: 0.5771, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 196, Train NLL: 0.4852\n",
      "Epoch: 196, Validation NLL: 0.5774, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 197, Train NLL: 0.4655\n",
      "Epoch: 197, Validation NLL: 0.5772, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 198, Train NLL: 0.4571\n",
      "Epoch: 198, Validation NLL: 0.5760, Total Acc: 0.756, Acc by label; diploid:0.913 WGD:0.556\n",
      "Epoch: 199, Train NLL: 0.4437\n",
      "Epoch: 199, Validation NLL: 0.5754, Total Acc: 0.756, Acc by label; diploid:0.913 WGD:0.556\n",
      "Epoch: 200, Train NLL: 0.4631\n",
      "Epoch: 200, Validation NLL: 0.5751, Total Acc: 0.756, Acc by label; diploid:0.913 WGD:0.556\n",
      "Epoch: 201, Train NLL: 0.4425\n",
      "Epoch: 201, Validation NLL: 0.5748, Total Acc: 0.756, Acc by label; diploid:0.913 WGD:0.556\n",
      "Epoch: 202, Train NLL: 0.4376\n",
      "Epoch: 202, Validation NLL: 0.5752, Total Acc: 0.756, Acc by label; diploid:0.913 WGD:0.556\n",
      "Epoch: 203, Train NLL: 0.4545\n",
      "Epoch: 203, Validation NLL: 0.5759, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 204, Train NLL: 0.4599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 204, Validation NLL: 0.5753, Total Acc: 0.756, Acc by label; diploid:0.913 WGD:0.556\n",
      "Epoch: 205, Train NLL: 0.4546\n",
      "Epoch: 205, Validation NLL: 0.5742, Total Acc: 0.756, Acc by label; diploid:0.913 WGD:0.556\n",
      "Epoch: 206, Train NLL: 0.4725\n",
      "Epoch: 206, Validation NLL: 0.5740, Total Acc: 0.756, Acc by label; diploid:0.913 WGD:0.556\n",
      "Epoch: 207, Train NLL: 0.4469\n",
      "Epoch: 207, Validation NLL: 0.5736, Total Acc: 0.756, Acc by label; diploid:0.913 WGD:0.556\n",
      "Epoch: 208, Train NLL: 0.4517\n",
      "Epoch: 208, Validation NLL: 0.5733, Total Acc: 0.756, Acc by label; diploid:0.913 WGD:0.556\n",
      "Epoch: 209, Train NLL: 0.4605\n",
      "Epoch: 209, Validation NLL: 0.5729, Total Acc: 0.756, Acc by label; diploid:0.913 WGD:0.556\n",
      "Epoch: 210, Train NLL: 0.4930\n",
      "Epoch: 210, Validation NLL: 0.5728, Total Acc: 0.756, Acc by label; diploid:0.913 WGD:0.556\n",
      "Epoch: 211, Train NLL: 0.4427\n",
      "Epoch: 211, Validation NLL: 0.5731, Total Acc: 0.756, Acc by label; diploid:0.913 WGD:0.556\n",
      "Epoch: 212, Train NLL: 0.4440\n",
      "Epoch: 212, Validation NLL: 0.5725, Total Acc: 0.756, Acc by label; diploid:0.913 WGD:0.556\n",
      "Epoch: 213, Train NLL: 0.4361\n",
      "Epoch: 213, Validation NLL: 0.5719, Total Acc: 0.756, Acc by label; diploid:0.913 WGD:0.556\n",
      "Epoch: 214, Train NLL: 0.4652\n",
      "Epoch: 214, Validation NLL: 0.5716, Total Acc: 0.756, Acc by label; diploid:0.913 WGD:0.556\n",
      "Epoch: 215, Train NLL: 0.4382\n",
      "Epoch: 215, Validation NLL: 0.5714, Total Acc: 0.756, Acc by label; diploid:0.913 WGD:0.556\n",
      "Epoch: 216, Train NLL: 0.4295\n",
      "Epoch: 216, Validation NLL: 0.5717, Total Acc: 0.756, Acc by label; diploid:0.913 WGD:0.556\n",
      "Epoch: 217, Train NLL: 0.4644\n",
      "Epoch: 217, Validation NLL: 0.5720, Total Acc: 0.756, Acc by label; diploid:0.913 WGD:0.556\n",
      "Epoch: 218, Train NLL: 0.4421\n",
      "Epoch: 218, Validation NLL: 0.5724, Total Acc: 0.756, Acc by label; diploid:0.913 WGD:0.556\n",
      "Epoch: 219, Train NLL: 0.4688\n",
      "Epoch: 219, Validation NLL: 0.5724, Total Acc: 0.756, Acc by label; diploid:0.913 WGD:0.556\n",
      "Epoch: 220, Train NLL: 0.4556\n",
      "Epoch: 220, Validation NLL: 0.5720, Total Acc: 0.756, Acc by label; diploid:0.913 WGD:0.556\n",
      "Epoch: 221, Train NLL: 0.4338\n",
      "Epoch: 221, Validation NLL: 0.5713, Total Acc: 0.756, Acc by label; diploid:0.913 WGD:0.556\n",
      "Epoch: 222, Train NLL: 0.4704\n",
      "Epoch: 222, Validation NLL: 0.5705, Total Acc: 0.756, Acc by label; diploid:0.913 WGD:0.556\n",
      "Epoch: 223, Train NLL: 0.4672\n",
      "Epoch: 223, Validation NLL: 0.5706, Total Acc: 0.756, Acc by label; diploid:0.913 WGD:0.556\n",
      "Epoch: 224, Train NLL: 0.4469\n",
      "Epoch: 224, Validation NLL: 0.5717, Total Acc: 0.756, Acc by label; diploid:0.913 WGD:0.556\n",
      "Epoch: 225, Train NLL: 0.4598\n",
      "Epoch: 225, Validation NLL: 0.5729, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 226, Train NLL: 0.4664\n",
      "Epoch: 226, Validation NLL: 0.5735, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 227, Train NLL: 0.4394\n",
      "Epoch: 227, Validation NLL: 0.5733, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 228, Train NLL: 0.4725\n",
      "Epoch: 228, Validation NLL: 0.5729, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 229, Train NLL: 0.4566\n",
      "Epoch: 229, Validation NLL: 0.5721, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 230, Train NLL: 0.4464\n",
      "Epoch: 230, Validation NLL: 0.5718, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 231, Train NLL: 0.4582\n",
      "Epoch: 231, Validation NLL: 0.5720, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 232, Train NLL: 0.4059\n",
      "Epoch: 232, Validation NLL: 0.5718, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 233, Train NLL: 0.4528\n",
      "Epoch: 233, Validation NLL: 0.5719, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 234, Train NLL: 0.4642\n",
      "Epoch: 234, Validation NLL: 0.5718, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 235, Train NLL: 0.4056\n",
      "Epoch: 235, Validation NLL: 0.5710, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 236, Train NLL: 0.4521\n",
      "Epoch: 236, Validation NLL: 0.5700, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 237, Train NLL: 0.4379\n",
      "Epoch: 237, Validation NLL: 0.5689, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 238, Train NLL: 0.4338\n",
      "Epoch: 238, Validation NLL: 0.5682, Total Acc: 0.756, Acc by label; diploid:0.913 WGD:0.556\n",
      "Epoch: 239, Train NLL: 0.4676\n",
      "Epoch: 239, Validation NLL: 0.5681, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 240, Train NLL: 0.4409\n",
      "Epoch: 240, Validation NLL: 0.5676, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 241, Train NLL: 0.4521\n",
      "Epoch: 241, Validation NLL: 0.5674, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 242, Train NLL: 0.4391\n",
      "Epoch: 242, Validation NLL: 0.5676, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 243, Train NLL: 0.4909\n",
      "Epoch: 243, Validation NLL: 0.5679, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 244, Train NLL: 0.4364\n",
      "Epoch: 244, Validation NLL: 0.5686, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 245, Train NLL: 0.4355\n",
      "Epoch: 245, Validation NLL: 0.5682, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 246, Train NLL: 0.4522\n",
      "Epoch: 246, Validation NLL: 0.5671, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 247, Train NLL: 0.4317\n",
      "Epoch: 247, Validation NLL: 0.5660, Total Acc: 0.768, Acc by label; diploid:0.935 WGD:0.556\n",
      "Epoch: 248, Train NLL: 0.4333\n",
      "Epoch: 248, Validation NLL: 0.5659, Total Acc: 0.780, Acc by label; diploid:0.935 WGD:0.583\n",
      "Epoch: 249, Train NLL: 0.4690\n",
      "Epoch: 249, Validation NLL: 0.5666, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 250, Train NLL: 0.4547\n",
      "Epoch: 250, Validation NLL: 0.5662, Total Acc: 0.780, Acc by label; diploid:0.935 WGD:0.583\n",
      "Epoch: 251, Train NLL: 0.4418\n",
      "Epoch: 251, Validation NLL: 0.5652, Total Acc: 0.780, Acc by label; diploid:0.935 WGD:0.583\n",
      "Epoch: 252, Train NLL: 0.4332\n",
      "Epoch: 252, Validation NLL: 0.5649, Total Acc: 0.780, Acc by label; diploid:0.935 WGD:0.583\n",
      "Epoch: 253, Train NLL: 0.4379\n",
      "Epoch: 253, Validation NLL: 0.5648, Total Acc: 0.780, Acc by label; diploid:0.935 WGD:0.583\n",
      "Epoch: 254, Train NLL: 0.4362\n",
      "Epoch: 254, Validation NLL: 0.5648, Total Acc: 0.780, Acc by label; diploid:0.935 WGD:0.583\n",
      "Epoch: 255, Train NLL: 0.4187\n",
      "Epoch: 255, Validation NLL: 0.5650, Total Acc: 0.780, Acc by label; diploid:0.935 WGD:0.583\n",
      "Epoch: 256, Train NLL: 0.4338\n",
      "Epoch: 256, Validation NLL: 0.5644, Total Acc: 0.780, Acc by label; diploid:0.935 WGD:0.583\n",
      "Epoch: 257, Train NLL: 0.4264\n",
      "Epoch: 257, Validation NLL: 0.5628, Total Acc: 0.780, Acc by label; diploid:0.935 WGD:0.583\n",
      "Epoch: 258, Train NLL: 0.4513\n",
      "Epoch: 258, Validation NLL: 0.5623, Total Acc: 0.768, Acc by label; diploid:0.935 WGD:0.556\n",
      "Epoch: 259, Train NLL: 0.4382\n",
      "Epoch: 259, Validation NLL: 0.5627, Total Acc: 0.780, Acc by label; diploid:0.935 WGD:0.583\n",
      "Epoch: 260, Train NLL: 0.4372\n",
      "Epoch: 260, Validation NLL: 0.5622, Total Acc: 0.780, Acc by label; diploid:0.935 WGD:0.583\n",
      "Epoch: 261, Train NLL: 0.4494\n",
      "Epoch: 261, Validation NLL: 0.5618, Total Acc: 0.768, Acc by label; diploid:0.935 WGD:0.556\n",
      "Epoch: 262, Train NLL: 0.4442\n",
      "Epoch: 262, Validation NLL: 0.5618, Total Acc: 0.768, Acc by label; diploid:0.935 WGD:0.556\n",
      "Epoch: 263, Train NLL: 0.4179\n",
      "Epoch: 263, Validation NLL: 0.5618, Total Acc: 0.768, Acc by label; diploid:0.935 WGD:0.556\n",
      "Epoch: 264, Train NLL: 0.4183\n",
      "Epoch: 264, Validation NLL: 0.5618, Total Acc: 0.768, Acc by label; diploid:0.935 WGD:0.556\n",
      "Epoch: 265, Train NLL: 0.4080\n",
      "Epoch: 265, Validation NLL: 0.5618, Total Acc: 0.768, Acc by label; diploid:0.935 WGD:0.556\n",
      "Epoch: 266, Train NLL: 0.4185\n",
      "Epoch: 266, Validation NLL: 0.5621, Total Acc: 0.768, Acc by label; diploid:0.935 WGD:0.556\n",
      "Epoch: 267, Train NLL: 0.4394\n",
      "Epoch: 267, Validation NLL: 0.5621, Total Acc: 0.768, Acc by label; diploid:0.935 WGD:0.556\n",
      "Epoch: 268, Train NLL: 0.4494\n",
      "Epoch: 268, Validation NLL: 0.5621, Total Acc: 0.780, Acc by label; diploid:0.935 WGD:0.583\n",
      "Epoch: 269, Train NLL: 0.4607\n",
      "Epoch: 269, Validation NLL: 0.5619, Total Acc: 0.768, Acc by label; diploid:0.935 WGD:0.556\n",
      "Epoch: 270, Train NLL: 0.4244\n",
      "Epoch: 270, Validation NLL: 0.5622, Total Acc: 0.780, Acc by label; diploid:0.935 WGD:0.583\n",
      "Epoch: 271, Train NLL: 0.4220\n",
      "Epoch: 271, Validation NLL: 0.5621, Total Acc: 0.780, Acc by label; diploid:0.935 WGD:0.583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 272, Train NLL: 0.4138\n",
      "Epoch: 272, Validation NLL: 0.5622, Total Acc: 0.780, Acc by label; diploid:0.935 WGD:0.583\n",
      "Epoch: 273, Train NLL: 0.4107\n",
      "Epoch: 273, Validation NLL: 0.5624, Total Acc: 0.780, Acc by label; diploid:0.935 WGD:0.583\n",
      "Epoch: 274, Train NLL: 0.4093\n",
      "Epoch: 274, Validation NLL: 0.5622, Total Acc: 0.780, Acc by label; diploid:0.935 WGD:0.583\n",
      "Epoch: 275, Train NLL: 0.4125\n",
      "Epoch: 275, Validation NLL: 0.5625, Total Acc: 0.780, Acc by label; diploid:0.935 WGD:0.583\n",
      "Epoch: 276, Train NLL: 0.4230\n",
      "Epoch: 276, Validation NLL: 0.5630, Total Acc: 0.780, Acc by label; diploid:0.935 WGD:0.583\n",
      "Epoch: 277, Train NLL: 0.4085\n",
      "Epoch: 277, Validation NLL: 0.5636, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 278, Train NLL: 0.3978\n",
      "Epoch: 278, Validation NLL: 0.5636, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 279, Train NLL: 0.4382\n",
      "Epoch: 279, Validation NLL: 0.5638, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 280, Train NLL: 0.4219\n",
      "Epoch: 280, Validation NLL: 0.5632, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 281, Train NLL: 0.4109\n",
      "Epoch: 281, Validation NLL: 0.5620, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 282, Train NLL: 0.4596\n",
      "Epoch: 282, Validation NLL: 0.5612, Total Acc: 0.780, Acc by label; diploid:0.935 WGD:0.583\n",
      "Epoch: 283, Train NLL: 0.4092\n",
      "Epoch: 283, Validation NLL: 0.5604, Total Acc: 0.780, Acc by label; diploid:0.935 WGD:0.583\n",
      "Epoch: 284, Train NLL: 0.4273\n",
      "Epoch: 284, Validation NLL: 0.5603, Total Acc: 0.780, Acc by label; diploid:0.935 WGD:0.583\n",
      "Epoch: 285, Train NLL: 0.4498\n",
      "Epoch: 285, Validation NLL: 0.5597, Total Acc: 0.780, Acc by label; diploid:0.935 WGD:0.583\n",
      "Epoch: 286, Train NLL: 0.4451\n",
      "Epoch: 286, Validation NLL: 0.5594, Total Acc: 0.780, Acc by label; diploid:0.935 WGD:0.583\n",
      "Epoch: 287, Train NLL: 0.4216\n",
      "Epoch: 287, Validation NLL: 0.5588, Total Acc: 0.780, Acc by label; diploid:0.935 WGD:0.583\n",
      "Epoch: 288, Train NLL: 0.4458\n",
      "Epoch: 288, Validation NLL: 0.5576, Total Acc: 0.768, Acc by label; diploid:0.935 WGD:0.556\n",
      "Epoch: 289, Train NLL: 0.4314\n",
      "Epoch: 289, Validation NLL: 0.5568, Total Acc: 0.768, Acc by label; diploid:0.935 WGD:0.556\n",
      "Epoch: 290, Train NLL: 0.4258\n",
      "Epoch: 290, Validation NLL: 0.5564, Total Acc: 0.768, Acc by label; diploid:0.935 WGD:0.556\n",
      "Epoch: 291, Train NLL: 0.4333\n",
      "Epoch: 291, Validation NLL: 0.5562, Total Acc: 0.768, Acc by label; diploid:0.935 WGD:0.556\n",
      "Epoch: 292, Train NLL: 0.4260\n",
      "Epoch: 292, Validation NLL: 0.5568, Total Acc: 0.768, Acc by label; diploid:0.935 WGD:0.556\n",
      "Epoch: 293, Train NLL: 0.4145\n",
      "Epoch: 293, Validation NLL: 0.5581, Total Acc: 0.780, Acc by label; diploid:0.935 WGD:0.583\n",
      "Epoch: 294, Train NLL: 0.4421\n",
      "Epoch: 294, Validation NLL: 0.5596, Total Acc: 0.780, Acc by label; diploid:0.935 WGD:0.583\n",
      "Epoch: 295, Train NLL: 0.4262\n",
      "Epoch: 295, Validation NLL: 0.5608, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 296, Train NLL: 0.4405\n",
      "Epoch: 296, Validation NLL: 0.5612, Total Acc: 0.780, Acc by label; diploid:0.913 WGD:0.611\n",
      "Epoch: 297, Train NLL: 0.4218\n",
      "Epoch: 297, Validation NLL: 0.5609, Total Acc: 0.780, Acc by label; diploid:0.913 WGD:0.611\n",
      "Epoch: 298, Train NLL: 0.4423\n",
      "Epoch: 298, Validation NLL: 0.5603, Total Acc: 0.780, Acc by label; diploid:0.913 WGD:0.611\n",
      "Epoch: 299, Train NLL: 0.4312\n",
      "Epoch: 299, Validation NLL: 0.5595, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n"
     ]
    }
   ],
   "source": [
    "train_embeddings, val_embeddings = train_embeddings.cuda(),val_embeddings.cuda()\n",
    "best_loss = 1e8\n",
    "best_acc = 0\n",
    "for e in range(300):\n",
    "    train_utils.training_loop_pooled_embeddings(e,step_size,optimizer,net,train_embeddings,train_jpgs_to_slide\n",
    "                                    ,train_labels,criterion,n_samples_train,sample_weight)\n",
    "    \n",
    "    loss,acc = train_utils.validation_loop_pooled_embeddings(e,scheduler,net,val_embeddings,val_jpgs_to_slide\n",
    "                                    ,val_labels,criterion,n_samples_val)\n",
    "    if loss < best_loss:\n",
    "        torch.save(net.state_dict(), '/n/tcga_models/COAD_attention_model_reworked_5_8.pt')\n",
    "        best_loss = loss\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        torch.save(net.state_dict(), '/n/tcga_models/COAD_attention_model_reworked_5_8_acc.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 300, Train NLL: 0.4541\n",
      "Epoch: 300, Validation NLL: 0.5582, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 301, Train NLL: 0.4867\n",
      "Epoch: 301, Validation NLL: 0.5569, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 302, Train NLL: 0.4261\n",
      "Epoch: 302, Validation NLL: 0.5560, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 303, Train NLL: 0.4259\n",
      "Epoch: 303, Validation NLL: 0.5554, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 304, Train NLL: 0.4213\n",
      "Epoch: 304, Validation NLL: 0.5549, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 305, Train NLL: 0.4507\n",
      "Epoch: 305, Validation NLL: 0.5541, Total Acc: 0.756, Acc by label; diploid:0.913 WGD:0.556\n",
      "Epoch: 306, Train NLL: 0.4471\n",
      "Epoch: 306, Validation NLL: 0.5542, Total Acc: 0.756, Acc by label; diploid:0.913 WGD:0.556\n",
      "Epoch: 307, Train NLL: 0.4044\n",
      "Epoch: 307, Validation NLL: 0.5545, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 308, Train NLL: 0.4597\n",
      "Epoch: 308, Validation NLL: 0.5549, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 309, Train NLL: 0.4197\n",
      "Epoch: 309, Validation NLL: 0.5557, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 310, Train NLL: 0.4287\n",
      "Epoch: 310, Validation NLL: 0.5566, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 311, Train NLL: 0.4269\n",
      "Epoch: 311, Validation NLL: 0.5575, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 312, Train NLL: 0.4068\n",
      "Epoch: 312, Validation NLL: 0.5583, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 313, Train NLL: 0.4309\n",
      "Epoch: 313, Validation NLL: 0.5584, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 314, Train NLL: 0.4388\n",
      "Epoch: 314, Validation NLL: 0.5593, Total Acc: 0.780, Acc by label; diploid:0.913 WGD:0.611\n",
      "Epoch: 315, Train NLL: 0.4205\n",
      "Epoch: 315, Validation NLL: 0.5599, Total Acc: 0.780, Acc by label; diploid:0.913 WGD:0.611\n",
      "Epoch: 316, Train NLL: 0.4235\n",
      "Epoch: 316, Validation NLL: 0.5596, Total Acc: 0.780, Acc by label; diploid:0.913 WGD:0.611\n",
      "Epoch: 317, Train NLL: 0.4150\n",
      "Epoch: 317, Validation NLL: 0.5588, Total Acc: 0.780, Acc by label; diploid:0.913 WGD:0.611\n",
      "Epoch: 318, Train NLL: 0.4255\n",
      "Epoch: 318, Validation NLL: 0.5580, Total Acc: 0.780, Acc by label; diploid:0.913 WGD:0.611\n",
      "Epoch: 319, Train NLL: 0.4374\n",
      "Epoch: 319, Validation NLL: 0.5579, Total Acc: 0.780, Acc by label; diploid:0.913 WGD:0.611\n",
      "Epoch: 320, Train NLL: 0.4261\n",
      "Epoch: 320, Validation NLL: 0.5569, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 321, Train NLL: 0.4344\n",
      "Epoch: 321, Validation NLL: 0.5569, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 322, Train NLL: 0.4220\n",
      "Epoch: 322, Validation NLL: 0.5563, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 323, Train NLL: 0.4377\n",
      "Epoch: 323, Validation NLL: 0.5558, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 324, Train NLL: 0.4436\n",
      "Epoch: 324, Validation NLL: 0.5550, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 325, Train NLL: 0.4603\n",
      "Epoch: 325, Validation NLL: 0.5546, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 326, Train NLL: 0.3714\n",
      "Epoch: 326, Validation NLL: 0.5537, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 327, Train NLL: 0.4338\n",
      "Epoch: 327, Validation NLL: 0.5536, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 328, Train NLL: 0.3963\n",
      "Epoch: 328, Validation NLL: 0.5540, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 329, Train NLL: 0.4097\n",
      "Epoch: 329, Validation NLL: 0.5548, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 330, Train NLL: 0.4408\n",
      "Epoch: 330, Validation NLL: 0.5546, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 331, Train NLL: 0.4310\n",
      "Epoch: 331, Validation NLL: 0.5532, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 332, Train NLL: 0.4110\n",
      "Epoch: 332, Validation NLL: 0.5525, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 333, Train NLL: 0.4437\n",
      "Epoch: 333, Validation NLL: 0.5519, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 334, Train NLL: 0.3961\n",
      "Epoch: 334, Validation NLL: 0.5519, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 335, Train NLL: 0.4013\n",
      "Epoch: 335, Validation NLL: 0.5519, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 336, Train NLL: 0.4053\n",
      "Epoch: 336, Validation NLL: 0.5522, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 337, Train NLL: 0.4368\n",
      "Epoch: 337, Validation NLL: 0.5520, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 338, Train NLL: 0.4130\n",
      "Epoch: 338, Validation NLL: 0.5523, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 339, Train NLL: 0.3987\n",
      "Epoch: 339, Validation NLL: 0.5520, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 340, Train NLL: 0.4237\n",
      "Epoch: 340, Validation NLL: 0.5519, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 341, Train NLL: 0.3701\n",
      "Epoch: 341, Validation NLL: 0.5524, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 342, Train NLL: 0.4014\n",
      "Epoch: 342, Validation NLL: 0.5527, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 343, Train NLL: 0.4387\n",
      "Epoch: 343, Validation NLL: 0.5525, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 344, Train NLL: 0.4111\n",
      "Epoch: 344, Validation NLL: 0.5517, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 345, Train NLL: 0.4294\n",
      "Epoch: 345, Validation NLL: 0.5505, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 346, Train NLL: 0.4152\n",
      "Epoch: 346, Validation NLL: 0.5502, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 347, Train NLL: 0.3935\n",
      "Epoch: 347, Validation NLL: 0.5496, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 348, Train NLL: 0.4148\n",
      "Epoch: 348, Validation NLL: 0.5484, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 349, Train NLL: 0.4505\n",
      "Epoch: 349, Validation NLL: 0.5475, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 350, Train NLL: 0.3905\n",
      "Epoch: 350, Validation NLL: 0.5472, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 351, Train NLL: 0.4077\n",
      "Epoch: 351, Validation NLL: 0.5476, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 352, Train NLL: 0.3891\n",
      "Epoch: 352, Validation NLL: 0.5484, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 353, Train NLL: 0.4255\n",
      "Epoch: 353, Validation NLL: 0.5492, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 354, Train NLL: 0.3792\n",
      "Epoch: 354, Validation NLL: 0.5499, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 355, Train NLL: 0.3972\n",
      "Epoch: 355, Validation NLL: 0.5509, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 356, Train NLL: 0.4105\n",
      "Epoch: 356, Validation NLL: 0.5517, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 357, Train NLL: 0.4467\n",
      "Epoch: 357, Validation NLL: 0.5518, Total Acc: 0.780, Acc by label; diploid:0.913 WGD:0.611\n",
      "Epoch: 358, Train NLL: 0.4125\n",
      "Epoch: 358, Validation NLL: 0.5514, Total Acc: 0.780, Acc by label; diploid:0.913 WGD:0.611\n",
      "Epoch: 359, Train NLL: 0.3921\n",
      "Epoch: 359, Validation NLL: 0.5509, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 360, Train NLL: 0.3745\n",
      "Epoch: 360, Validation NLL: 0.5501, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 361, Train NLL: 0.3883\n",
      "Epoch: 361, Validation NLL: 0.5491, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 362, Train NLL: 0.3816\n",
      "Epoch: 362, Validation NLL: 0.5482, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 363, Train NLL: 0.4033\n",
      "Epoch: 363, Validation NLL: 0.5479, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 364, Train NLL: 0.4357\n",
      "Epoch: 364, Validation NLL: 0.5485, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 365, Train NLL: 0.4325\n",
      "Epoch: 365, Validation NLL: 0.5490, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 366, Train NLL: 0.3924\n",
      "Epoch: 366, Validation NLL: 0.5484, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 367, Train NLL: 0.4286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 367, Validation NLL: 0.5478, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 368, Train NLL: 0.4078\n",
      "Epoch: 368, Validation NLL: 0.5474, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 369, Train NLL: 0.4019\n",
      "Epoch: 369, Validation NLL: 0.5474, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 370, Train NLL: 0.4354\n",
      "Epoch: 370, Validation NLL: 0.5481, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 371, Train NLL: 0.4184\n",
      "Epoch: 371, Validation NLL: 0.5485, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 372, Train NLL: 0.4439\n",
      "Epoch: 372, Validation NLL: 0.5490, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 373, Train NLL: 0.4144\n",
      "Epoch: 373, Validation NLL: 0.5490, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 374, Train NLL: 0.4145\n",
      "Epoch: 374, Validation NLL: 0.5479, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 375, Train NLL: 0.3953\n",
      "Epoch: 375, Validation NLL: 0.5471, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 376, Train NLL: 0.4109\n",
      "Epoch: 376, Validation NLL: 0.5469, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 377, Train NLL: 0.4191\n",
      "Epoch: 377, Validation NLL: 0.5471, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 378, Train NLL: 0.4512\n",
      "Epoch: 378, Validation NLL: 0.5471, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 379, Train NLL: 0.4025\n",
      "Epoch: 379, Validation NLL: 0.5469, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 380, Train NLL: 0.4186\n",
      "Epoch: 380, Validation NLL: 0.5475, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 381, Train NLL: 0.3824\n",
      "Epoch: 381, Validation NLL: 0.5484, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 382, Train NLL: 0.3917\n",
      "Epoch: 382, Validation NLL: 0.5493, Total Acc: 0.780, Acc by label; diploid:0.913 WGD:0.611\n",
      "Epoch: 383, Train NLL: 0.4498\n",
      "Epoch: 383, Validation NLL: 0.5505, Total Acc: 0.768, Acc by label; diploid:0.891 WGD:0.611\n",
      "Epoch: 384, Train NLL: 0.3919\n",
      "Epoch: 384, Validation NLL: 0.5513, Total Acc: 0.768, Acc by label; diploid:0.891 WGD:0.611\n",
      "Epoch: 385, Train NLL: 0.4060\n",
      "Epoch: 385, Validation NLL: 0.5523, Total Acc: 0.780, Acc by label; diploid:0.891 WGD:0.639\n",
      "Epoch: 386, Train NLL: 0.3922\n",
      "Epoch: 386, Validation NLL: 0.5519, Total Acc: 0.780, Acc by label; diploid:0.891 WGD:0.639\n",
      "Epoch: 387, Train NLL: 0.4325\n",
      "Epoch: 387, Validation NLL: 0.5516, Total Acc: 0.780, Acc by label; diploid:0.891 WGD:0.639\n",
      "Epoch: 388, Train NLL: 0.3856\n",
      "Epoch: 388, Validation NLL: 0.5511, Total Acc: 0.780, Acc by label; diploid:0.891 WGD:0.639\n",
      "Epoch: 389, Train NLL: 0.4150\n",
      "Epoch: 389, Validation NLL: 0.5504, Total Acc: 0.768, Acc by label; diploid:0.891 WGD:0.611\n",
      "Epoch: 390, Train NLL: 0.4123\n",
      "Epoch: 390, Validation NLL: 0.5487, Total Acc: 0.768, Acc by label; diploid:0.891 WGD:0.611\n",
      "Epoch: 391, Train NLL: 0.4282\n",
      "Epoch: 391, Validation NLL: 0.5472, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 392, Train NLL: 0.4005\n",
      "Epoch: 392, Validation NLL: 0.5476, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 393, Train NLL: 0.4161\n",
      "Epoch: 393, Validation NLL: 0.5482, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 394, Train NLL: 0.3907\n",
      "Epoch: 394, Validation NLL: 0.5476, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 395, Train NLL: 0.4044\n",
      "Epoch: 395, Validation NLL: 0.5474, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 396, Train NLL: 0.4532\n",
      "Epoch: 396, Validation NLL: 0.5475, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 397, Train NLL: 0.4278\n",
      "Epoch: 397, Validation NLL: 0.5476, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n",
      "Epoch: 398, Train NLL: 0.3744\n",
      "Epoch: 398, Validation NLL: 0.5477, Total Acc: 0.768, Acc by label; diploid:0.913 WGD:0.583\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-e48aab0682d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     train_utils.training_loop_pooled_embeddings(e,step_size,optimizer,net,train_embeddings,train_jpgs_to_slide\n\u001b[0;32m----> 3\u001b[0;31m                                     ,train_labels,criterion,n_samples_train,sample_weight)\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     loss,acc = train_utils.validation_loop_pooled_embeddings(e,scheduler,net,val_embeddings,val_jpgs_to_slide\n",
      "\u001b[0;32m~/MSI_prediction/tcga_project/train_utils.py\u001b[0m in \u001b[0;36mtraining_loop_pooled_embeddings\u001b[0;34m(e, step_size, optimizer, net, train_embeddings, train_jpgs_to_slide, train_labels, criterion, n_samples, sample_weight)\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midexs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0mslide\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_jpgs_to_slide\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m         \u001b[0mlabels_vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_jpgs_to_slide\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m         \u001b[0mlogits_vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslide\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for e in range(300,600):\n",
    "    train_utils.training_loop_pooled_embeddings(e,step_size,optimizer,net,train_embeddings,train_jpgs_to_slide\n",
    "                                    ,train_labels,criterion,n_samples_train,sample_weight)\n",
    "    \n",
    "    loss,acc = train_utils.validation_loop_pooled_embeddings(e,scheduler,net,val_embeddings,val_jpgs_to_slide\n",
    "                                    ,val_labels,criterion,n_samples_val)\n",
    "    if loss < best_loss:\n",
    "        torch.save(net.state_dict(), '/n/tcga_models/COAD_attention_model_reworked_5_8.pt')\n",
    "        best_loss = loss\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        torch.save(net.state_dict(), '/n/tcga_models/COAD_attention_model_reworked_5_8_acc.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5232198142414861"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(labels_to_idxs_train[idexs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1,  ..., 1, 1, 1])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6049382716049383"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for idx in range(n_samples):\n",
    "    with torch.no_grad():\n",
    "        slide = train_embeddings[train_jpgs_to_slide==idx]\n",
    "        labels_vec[idx] = train_labels[train_jpgs_to_slide==idx].unique().float().cuda()\n",
    "        logits_vec[idx] = torch.mean(linear_layer(slide))\n",
    "np.mean(labels_vec.cpu().numpy() == (logits_vec>0.5).float().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_embeddings\n",
    "torch.cuda.empty_cache()\n",
    "val_embeddings = val_embeddings.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.573170731707317"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = val_jpgs_to_slide.max()+1\n",
    "logits_vec = torch.zeros((n_samples,1)).cuda()\n",
    "labels_vec = torch.zeros_like(logits_vec).cuda()\n",
    "for idx in range(n_samples):\n",
    "    with torch.no_grad():\n",
    "        slide = val_embeddings[val_jpgs_to_slide==idx]\n",
    "        labels_vec[idx] = val_labels[val_jpgs_to_slide==idx].unique().float().cuda()\n",
    "        logits_vec[idx] = torch.mean(linear_layer(slide))\n",
    "np.mean(labels_vec.cpu().numpy() == (logits_vec>0.5).float().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "del val_embeddings\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   0,   0,  ..., 323, 323, 323])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_jpgs_to_slide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([ 2.3519e-01,  2.6554e-01, -5.1096e-08,  5.1923e-01,  3.4404e-09,\n",
       "          2.2344e-01,  4.2637e-01,  1.3153e-07,  2.5157e-01,  1.5152e-06,\n",
       "          3.1649e-01,  2.5043e-01,  3.7927e-01,  1.0862e-05,  2.7462e-01,\n",
       "          2.3937e-01,  2.4569e-01,  3.9352e-01,  4.6928e-01,  2.8979e-01,\n",
       "          2.7206e-01,  2.7792e-01,  2.9089e-01,  2.0875e-01,  2.6028e-01,\n",
       "          2.7721e-01,  2.9026e-01,  3.1510e-01,  3.8906e-01,  3.0260e-01,\n",
       "          2.6793e-01,  2.1056e-01,  2.9101e-01,  3.3062e-01,  4.2879e-01,\n",
       "          3.7352e-01,  7.4804e-08,  1.9000e-01,  1.4740e-08,  2.2349e-01,\n",
       "          1.8079e-01,  2.4823e-01,  2.7352e-01,  2.5917e-01,  2.9366e-01,\n",
       "          3.0109e-01,  2.2261e-01,  2.6257e-01,  2.2001e-08,  2.6461e-01,\n",
       "          2.2089e-01,  2.8305e-01,  3.2998e-01,  2.2688e-01,  3.6608e-01,\n",
       "          2.1172e-01,  2.3945e-01,  2.4885e-01,  5.2481e-01,  2.4803e-01,\n",
       "          2.9450e-01,  2.6038e-01,  4.8347e-01,  2.6588e-01]),\n",
       " Parameter containing:\n",
       " tensor([ 2.2954e-01,  2.5401e-01, -1.0543e-06, -6.6424e-01, -1.6571e-08,\n",
       "          1.6263e-01,  4.5518e-01, -4.3020e-07,  3.0035e-01, -8.0052e-06,\n",
       "          3.4888e-01,  3.1225e-01, -2.4968e-01, -3.4749e-05,  1.0783e-01,\n",
       "          2.2189e-01,  3.8360e-01, -5.3182e-01, -6.2936e-01,  5.6901e-01,\n",
       "          2.9901e-01,  5.8455e-01,  4.8208e-01,  3.3082e-01,  1.9727e-01,\n",
       "          1.9508e-01,  1.5226e-01,  8.4807e-02,  5.1254e-01,  1.3805e-02,\n",
       "          1.6597e-01,  3.3180e-01,  2.5182e-01,  4.4212e-01, -2.7840e-01,\n",
       "         -1.8520e-02, -2.4507e-07,  3.2190e-01, -4.9152e-08,  2.3802e-01,\n",
       "          2.3291e-01,  3.1531e-01,  4.2660e-01,  2.9376e-01,  2.6400e-01,\n",
       "          6.7600e-01,  4.2829e-01,  3.4663e-01, -8.6909e-08,  2.4705e-01,\n",
       "          3.0248e-01,  6.1644e-01,  3.9994e-01,  3.3317e-01, -4.1267e-01,\n",
       "          3.7662e-01,  1.7738e-01,  2.5774e-01, -4.5077e-01,  2.1234e-01,\n",
       "          5.6915e-01,  5.7272e-01, -4.0310e-01,  2.3473e-01])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p for p in resnet.bn1.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

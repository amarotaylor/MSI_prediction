{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import psutil\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, set_image_backend\n",
    "\n",
    "import data_utils\n",
    "import train_utils\n",
    "import model_utils\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "set_image_backend('accimage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = 1\n",
    "state_dict_file = '/n/tcga_models/ResNet_10x_retrain_5-4-18_lr_log.pt'\n",
    "resnet = models.resnet18(pretrained=False)\n",
    "resnet.fc = nn.Linear(2048, output_size)\n",
    "saved_state = torch.load(state_dict_file, map_location=lambda storage, loc: storage)\n",
    "resnet.load_state_dict(saved_state)\n",
    "for p in resnet.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = '/n/data_labeled_histopathology_images/COAD/train.pkl'\n",
    "with open(pickle_file, 'rb') as f: \n",
    "    train_embeddings,train_labels,train_jpgs_to_slide = pickle.load(f)\n",
    "    \n",
    "pickle_file = '/n/data_labeled_histopathology_images/COAD/val.pkl'\n",
    "with open(pickle_file, 'rb') as f: \n",
    "    val_embeddings,val_labels,val_jpgs_to_slide = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_fc = resnet.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = train_jpgs_to_slide.max()+1\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "logits_vec = torch.zeros((n_samples,1)).cuda()\n",
    "labels_vec = torch.zeros_like(logits_vec).cuda()\n",
    "train_embeddings = train_embeddings.cuda()\n",
    "resnet_fc.cuda()\n",
    "\n",
    "for idx in range(n_samples):\n",
    "    with torch.no_grad():\n",
    "        slide = train_embeddings[train_jpgs_to_slide==idx]\n",
    "        labels_vec[idx] = train_labels[train_jpgs_to_slide==idx].unique().float().cuda()\n",
    "        logits_vec[idx] = torch.mean(resnet_fc(slide))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5487804878048781"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(labels_vec.cpu().numpy() == (logits_vec>0.5).float().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.4817, device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "criterion(logits_vec, labels_vec) * n_samples / 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnr_layer = nn.Linear(2048,2048)\n",
    "lnr_layer_2 = nn.Linear(2048,1)\n",
    "relu = nn.ReLU()\n",
    "layers = [lnr_layer, relu, lnr_layer_2]\n",
    "linear_layer = nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_embeddings = train_embeddings.cuda()\n",
    "net = model_utils.Attention(input_size=2048,hidden_size=2048,output_size=1)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "step_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attention(\n",
       "  (V): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "  (w): Linear(in_features=2048, out_features=1, bias=True)\n",
       "  (sigm): Sigmoid()\n",
       "  (tanh): Tanh()\n",
       "  (sm): Softmax()\n",
       "  (linear_layer): Linear(in_features=2048, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(params=net.parameters(),lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,patience=10,min_lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_val = val_jpgs_to_slide.max()\n",
    "n_samples_train = train_jpgs_to_slide.max()\n",
    "idxs_train = np.linspace(0,n_samples_train,n_samples_train+1,dtype=int)\n",
    "labels_to_idxs_train = np.concatenate([(train_labels[train_jpgs_to_slide==i]).unique().numpy() for i in idxs_train])\n",
    "weights = 1/np.sum(labels_to_idxs_train==0),1/np.sum(labels_to_idxs_train==1)\n",
    "sample_weight = [weights[l] for l in labels_to_idxs_train]\n",
    "sample_weight = sample_weight/np.sum(sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train NLL: 0.7045\n",
      "Epoch: 0, Validation NLL: 0.6925, Total Acc: 0.573, Acc by label; diploid:1.000 WGD:0.000\n",
      "Epoch: 1, Train NLL: 0.6791\n",
      "Epoch: 1, Validation NLL: 0.7287, Total Acc: 0.549, Acc by label; diploid:0.915 WGD:0.057\n",
      "Epoch: 2, Train NLL: 0.6506\n",
      "Epoch: 2, Validation NLL: 0.7252, Total Acc: 0.561, Acc by label; diploid:0.787 WGD:0.257\n",
      "Epoch: 3, Train NLL: 0.6445\n",
      "Epoch: 3, Validation NLL: 0.6898, Total Acc: 0.573, Acc by label; diploid:1.000 WGD:0.000\n",
      "Epoch: 4, Train NLL: 0.6016\n",
      "Epoch: 4, Validation NLL: 0.7507, Total Acc: 0.610, Acc by label; diploid:0.638 WGD:0.571\n",
      "Epoch: 5, Train NLL: 0.5620\n",
      "Epoch: 5, Validation NLL: 0.6955, Total Acc: 0.622, Acc by label; diploid:0.979 WGD:0.143\n",
      "Epoch: 6, Train NLL: 0.5789\n",
      "Epoch: 6, Validation NLL: 0.7442, Total Acc: 0.561, Acc by label; diploid:0.596 WGD:0.514\n",
      "Epoch: 7, Train NLL: 0.5241\n",
      "Epoch: 7, Validation NLL: 0.7194, Total Acc: 0.634, Acc by label; diploid:0.915 WGD:0.257\n",
      "Epoch: 8, Train NLL: 0.5269\n",
      "Epoch: 8, Validation NLL: 0.7820, Total Acc: 0.512, Acc by label; diploid:0.617 WGD:0.371\n",
      "Epoch: 9, Train NLL: 0.4665\n",
      "Epoch: 9, Validation NLL: 0.7995, Total Acc: 0.573, Acc by label; diploid:0.830 WGD:0.229\n",
      "Epoch: 10, Train NLL: 0.4601\n",
      "Epoch: 10, Validation NLL: 0.8323, Total Acc: 0.610, Acc by label; diploid:0.660 WGD:0.543\n",
      "Epoch: 11, Train NLL: 0.4706\n",
      "Epoch: 11, Validation NLL: 0.8458, Total Acc: 0.561, Acc by label; diploid:0.702 WGD:0.371\n",
      "Epoch: 12, Train NLL: 0.4327\n",
      "Epoch: 12, Validation NLL: 0.8493, Total Acc: 0.561, Acc by label; diploid:0.787 WGD:0.257\n",
      "Epoch: 13, Train NLL: 0.3990\n",
      "Epoch: 13, Validation NLL: 0.8793, Total Acc: 0.549, Acc by label; diploid:0.681 WGD:0.371\n",
      "Epoch: 14, Train NLL: 0.3921\n",
      "Epoch: 14, Validation NLL: 0.9120, Total Acc: 0.561, Acc by label; diploid:0.723 WGD:0.343\n",
      "Epoch: 15, Train NLL: 0.3620\n",
      "Epoch: 15, Validation NLL: 0.9043, Total Acc: 0.561, Acc by label; diploid:0.723 WGD:0.343\n",
      "Epoch: 16, Train NLL: 0.3561\n",
      "Epoch: 16, Validation NLL: 0.9167, Total Acc: 0.537, Acc by label; diploid:0.617 WGD:0.429\n",
      "Epoch: 17, Train NLL: 0.3655\n",
      "Epoch: 17, Validation NLL: 0.9318, Total Acc: 0.500, Acc by label; diploid:0.574 WGD:0.400\n",
      "Epoch: 18, Train NLL: 0.3499\n",
      "Epoch: 18, Validation NLL: 0.9380, Total Acc: 0.512, Acc by label; diploid:0.638 WGD:0.343\n",
      "Epoch: 19, Train NLL: 0.3295\n",
      "Epoch: 19, Validation NLL: 0.9381, Total Acc: 0.524, Acc by label; diploid:0.681 WGD:0.314\n",
      "Epoch: 20, Train NLL: 0.3056\n",
      "Epoch: 20, Validation NLL: 0.9388, Total Acc: 0.524, Acc by label; diploid:0.681 WGD:0.314\n",
      "Epoch: 21, Train NLL: 0.3309\n",
      "Epoch: 21, Validation NLL: 0.9368, Total Acc: 0.561, Acc by label; diploid:0.702 WGD:0.371\n",
      "Epoch: 22, Train NLL: 0.3219\n",
      "Epoch: 22, Validation NLL: 0.9428, Total Acc: 0.549, Acc by label; diploid:0.660 WGD:0.400\n",
      "Epoch: 23, Train NLL: 0.3037\n",
      "Epoch: 23, Validation NLL: 0.9573, Total Acc: 0.524, Acc by label; diploid:0.596 WGD:0.429\n",
      "Epoch: 24, Train NLL: 0.3160\n",
      "Epoch: 24, Validation NLL: 0.9688, Total Acc: 0.512, Acc by label; diploid:0.574 WGD:0.429\n",
      "Epoch: 25, Train NLL: 0.2760\n",
      "Epoch: 25, Validation NLL: 0.9703, Total Acc: 0.524, Acc by label; diploid:0.596 WGD:0.429\n",
      "Epoch: 26, Train NLL: 0.3172\n",
      "Epoch: 26, Validation NLL: 0.9705, Total Acc: 0.537, Acc by label; diploid:0.617 WGD:0.429\n",
      "Epoch: 27, Train NLL: 0.3219\n",
      "Epoch: 27, Validation NLL: 0.9710, Total Acc: 0.537, Acc by label; diploid:0.617 WGD:0.429\n",
      "Epoch: 28, Train NLL: 0.2843\n",
      "Epoch: 28, Validation NLL: 0.9722, Total Acc: 0.537, Acc by label; diploid:0.617 WGD:0.429\n",
      "Epoch: 29, Train NLL: 0.3035\n",
      "Epoch: 29, Validation NLL: 0.9734, Total Acc: 0.537, Acc by label; diploid:0.617 WGD:0.429\n",
      "Epoch: 30, Train NLL: 0.2837\n",
      "Epoch: 30, Validation NLL: 0.9743, Total Acc: 0.537, Acc by label; diploid:0.617 WGD:0.429\n",
      "Epoch: 31, Train NLL: 0.3456\n",
      "Epoch: 31, Validation NLL: 0.9755, Total Acc: 0.537, Acc by label; diploid:0.617 WGD:0.429\n",
      "Epoch: 32, Train NLL: 0.3387\n",
      "Epoch: 32, Validation NLL: 0.9765, Total Acc: 0.537, Acc by label; diploid:0.617 WGD:0.429\n",
      "Epoch: 33, Train NLL: 0.2902\n",
      "Epoch: 33, Validation NLL: 0.9772, Total Acc: 0.537, Acc by label; diploid:0.617 WGD:0.429\n",
      "Epoch: 34, Train NLL: 0.3255\n",
      "Epoch: 34, Validation NLL: 0.9775, Total Acc: 0.537, Acc by label; diploid:0.617 WGD:0.429\n",
      "Epoch: 35, Train NLL: 0.3299\n",
      "Epoch: 35, Validation NLL: 0.9772, Total Acc: 0.537, Acc by label; diploid:0.617 WGD:0.429\n",
      "Epoch: 36, Train NLL: 0.3389\n",
      "Epoch: 36, Validation NLL: 0.9768, Total Acc: 0.537, Acc by label; diploid:0.617 WGD:0.429\n",
      "Epoch: 37, Train NLL: 0.3200\n",
      "Epoch: 37, Validation NLL: 0.9762, Total Acc: 0.537, Acc by label; diploid:0.617 WGD:0.429\n",
      "Epoch: 38, Train NLL: 0.3413\n",
      "Epoch: 38, Validation NLL: 0.9761, Total Acc: 0.537, Acc by label; diploid:0.617 WGD:0.429\n",
      "Epoch: 39, Train NLL: 0.2983\n",
      "Epoch: 39, Validation NLL: 0.9770, Total Acc: 0.537, Acc by label; diploid:0.617 WGD:0.429\n",
      "Epoch: 40, Train NLL: 0.3053\n",
      "Epoch: 40, Validation NLL: 0.9783, Total Acc: 0.537, Acc by label; diploid:0.617 WGD:0.429\n",
      "Epoch: 41, Train NLL: 0.2814\n",
      "Epoch: 41, Validation NLL: 0.9794, Total Acc: 0.537, Acc by label; diploid:0.617 WGD:0.429\n",
      "Epoch: 42, Train NLL: 0.3074\n",
      "Epoch: 42, Validation NLL: 0.9809, Total Acc: 0.537, Acc by label; diploid:0.617 WGD:0.429\n",
      "Epoch: 43, Train NLL: 0.3439\n",
      "Epoch: 43, Validation NLL: 0.9820, Total Acc: 0.537, Acc by label; diploid:0.617 WGD:0.429\n",
      "Epoch: 44, Train NLL: 0.3341\n",
      "Epoch: 44, Validation NLL: 0.9818, Total Acc: 0.537, Acc by label; diploid:0.617 WGD:0.429\n",
      "Epoch: 45, Train NLL: 0.3165\n",
      "Epoch: 45, Validation NLL: 0.9819, Total Acc: 0.537, Acc by label; diploid:0.617 WGD:0.429\n",
      "Epoch: 46, Train NLL: 0.3312\n",
      "Epoch: 46, Validation NLL: 0.9819, Total Acc: 0.537, Acc by label; diploid:0.617 WGD:0.429\n",
      "Epoch: 47, Train NLL: 0.3429\n",
      "Epoch: 47, Validation NLL: 0.9822, Total Acc: 0.537, Acc by label; diploid:0.617 WGD:0.429\n",
      "Epoch: 48, Train NLL: 0.3090\n",
      "Epoch: 48, Validation NLL: 0.9825, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 49, Train NLL: 0.2901\n",
      "Epoch: 49, Validation NLL: 0.9828, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 50, Train NLL: 0.3085\n",
      "Epoch: 50, Validation NLL: 0.9839, Total Acc: 0.537, Acc by label; diploid:0.617 WGD:0.429\n",
      "Epoch: 51, Train NLL: 0.2638\n",
      "Epoch: 51, Validation NLL: 0.9850, Total Acc: 0.537, Acc by label; diploid:0.617 WGD:0.429\n",
      "Epoch: 52, Train NLL: 0.3592\n",
      "Epoch: 52, Validation NLL: 0.9853, Total Acc: 0.537, Acc by label; diploid:0.617 WGD:0.429\n",
      "Epoch: 53, Train NLL: 0.3188\n",
      "Epoch: 53, Validation NLL: 0.9860, Total Acc: 0.537, Acc by label; diploid:0.617 WGD:0.429\n",
      "Epoch: 54, Train NLL: 0.2758\n",
      "Epoch: 54, Validation NLL: 0.9865, Total Acc: 0.537, Acc by label; diploid:0.617 WGD:0.429\n",
      "Epoch: 55, Train NLL: 0.2851\n",
      "Epoch: 55, Validation NLL: 0.9870, Total Acc: 0.537, Acc by label; diploid:0.617 WGD:0.429\n",
      "Epoch: 56, Train NLL: 0.3075\n",
      "Epoch: 56, Validation NLL: 0.9869, Total Acc: 0.537, Acc by label; diploid:0.617 WGD:0.429\n",
      "Epoch: 57, Train NLL: 0.3236\n",
      "Epoch: 57, Validation NLL: 0.9875, Total Acc: 0.537, Acc by label; diploid:0.617 WGD:0.429\n",
      "Epoch: 58, Train NLL: 0.3141\n",
      "Epoch: 58, Validation NLL: 0.9885, Total Acc: 0.537, Acc by label; diploid:0.617 WGD:0.429\n",
      "Epoch: 59, Train NLL: 0.2820\n",
      "Epoch: 59, Validation NLL: 0.9894, Total Acc: 0.537, Acc by label; diploid:0.617 WGD:0.429\n",
      "Epoch: 60, Train NLL: 0.3157\n",
      "Epoch: 60, Validation NLL: 0.9904, Total Acc: 0.537, Acc by label; diploid:0.617 WGD:0.429\n",
      "Epoch: 61, Train NLL: 0.3434\n",
      "Epoch: 61, Validation NLL: 0.9912, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 62, Train NLL: 0.3227\n",
      "Epoch: 62, Validation NLL: 0.9916, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 63, Train NLL: 0.3321\n",
      "Epoch: 63, Validation NLL: 0.9913, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 64, Train NLL: 0.3001\n",
      "Epoch: 64, Validation NLL: 0.9915, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 65, Train NLL: 0.2675\n",
      "Epoch: 65, Validation NLL: 0.9922, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 66, Train NLL: 0.2974\n",
      "Epoch: 66, Validation NLL: 0.9933, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 67, Train NLL: 0.2948\n",
      "Epoch: 67, Validation NLL: 0.9941, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 68, Train NLL: 0.3156\n",
      "Epoch: 68, Validation NLL: 0.9948, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 69, Train NLL: 0.3034\n",
      "Epoch: 69, Validation NLL: 0.9952, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 70, Train NLL: 0.3181\n",
      "Epoch: 70, Validation NLL: 0.9953, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 71, Train NLL: 0.2988\n",
      "Epoch: 71, Validation NLL: 0.9957, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 72, Train NLL: 0.2940\n",
      "Epoch: 72, Validation NLL: 0.9968, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 73, Train NLL: 0.2966\n",
      "Epoch: 73, Validation NLL: 0.9980, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 74, Train NLL: 0.2855\n",
      "Epoch: 74, Validation NLL: 0.9988, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 75, Train NLL: 0.3153\n",
      "Epoch: 75, Validation NLL: 0.9992, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 76, Train NLL: 0.2962\n",
      "Epoch: 76, Validation NLL: 0.9992, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 77, Train NLL: 0.2870\n",
      "Epoch: 77, Validation NLL: 0.9996, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 78, Train NLL: 0.3134\n",
      "Epoch: 78, Validation NLL: 1.0000, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 79, Train NLL: 0.3198\n",
      "Epoch: 79, Validation NLL: 1.0003, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 80, Train NLL: 0.2929\n",
      "Epoch: 80, Validation NLL: 1.0009, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 81, Train NLL: 0.2996\n",
      "Epoch: 81, Validation NLL: 1.0017, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 82, Train NLL: 0.3088\n",
      "Epoch: 82, Validation NLL: 1.0027, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 83, Train NLL: 0.2896\n",
      "Epoch: 83, Validation NLL: 1.0039, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 84, Train NLL: 0.2743\n",
      "Epoch: 84, Validation NLL: 1.0049, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 85, Train NLL: 0.3079\n",
      "Epoch: 85, Validation NLL: 1.0054, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 86, Train NLL: 0.3001\n",
      "Epoch: 86, Validation NLL: 1.0057, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 87, Train NLL: 0.2724\n",
      "Epoch: 87, Validation NLL: 1.0062, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 88, Train NLL: 0.2848\n",
      "Epoch: 88, Validation NLL: 1.0068, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 89, Train NLL: 0.2929\n",
      "Epoch: 89, Validation NLL: 1.0069, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 90, Train NLL: 0.2872\n",
      "Epoch: 90, Validation NLL: 1.0071, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 91, Train NLL: 0.3092\n",
      "Epoch: 91, Validation NLL: 1.0072, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 92, Train NLL: 0.3237\n",
      "Epoch: 92, Validation NLL: 1.0073, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 93, Train NLL: 0.2907\n",
      "Epoch: 93, Validation NLL: 1.0078, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 94, Train NLL: 0.2853\n",
      "Epoch: 94, Validation NLL: 1.0086, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 95, Train NLL: 0.2852\n",
      "Epoch: 95, Validation NLL: 1.0100, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 96, Train NLL: 0.2788\n",
      "Epoch: 96, Validation NLL: 1.0111, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 97, Train NLL: 0.3057\n",
      "Epoch: 97, Validation NLL: 1.0115, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 98, Train NLL: 0.2949\n",
      "Epoch: 98, Validation NLL: 1.0118, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 99, Train NLL: 0.3043\n",
      "Epoch: 99, Validation NLL: 1.0116, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 100, Train NLL: 0.2848\n",
      "Epoch: 100, Validation NLL: 1.0114, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 101, Train NLL: 0.3168\n",
      "Epoch: 101, Validation NLL: 1.0116, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 102, Train NLL: 0.2917\n",
      "Epoch: 102, Validation NLL: 1.0122, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 103, Train NLL: 0.3197\n",
      "Epoch: 103, Validation NLL: 1.0129, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 104, Train NLL: 0.3033\n",
      "Epoch: 104, Validation NLL: 1.0135, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 105, Train NLL: 0.3162\n",
      "Epoch: 105, Validation NLL: 1.0139, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 106, Train NLL: 0.2980\n",
      "Epoch: 106, Validation NLL: 1.0145, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 107, Train NLL: 0.2859\n",
      "Epoch: 107, Validation NLL: 1.0149, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 108, Train NLL: 0.3036\n",
      "Epoch: 108, Validation NLL: 1.0150, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 109, Train NLL: 0.3078\n",
      "Epoch: 109, Validation NLL: 1.0149, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 110, Train NLL: 0.2559\n",
      "Epoch: 110, Validation NLL: 1.0154, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 111, Train NLL: 0.2931\n",
      "Epoch: 111, Validation NLL: 1.0162, Total Acc: 0.524, Acc by label; diploid:0.617 WGD:0.400\n",
      "Epoch: 112, Train NLL: 0.3038\n",
      "Epoch: 112, Validation NLL: 1.0173, Total Acc: 0.537, Acc by label; diploid:0.617 WGD:0.429\n",
      "Epoch: 113, Train NLL: 0.2965\n",
      "Epoch: 113, Validation NLL: 1.0184, Total Acc: 0.537, Acc by label; diploid:0.617 WGD:0.429\n",
      "Epoch: 114, Train NLL: 0.2731\n",
      "Epoch: 114, Validation NLL: 1.0189, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 115, Train NLL: 0.2852\n",
      "Epoch: 115, Validation NLL: 1.0188, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 116, Train NLL: 0.2821\n",
      "Epoch: 116, Validation NLL: 1.0190, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 117, Train NLL: 0.2874\n",
      "Epoch: 117, Validation NLL: 1.0190, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 118, Train NLL: 0.2601\n",
      "Epoch: 118, Validation NLL: 1.0191, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 119, Train NLL: 0.3083\n",
      "Epoch: 119, Validation NLL: 1.0194, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 120, Train NLL: 0.2926\n",
      "Epoch: 120, Validation NLL: 1.0196, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 121, Train NLL: 0.3148\n",
      "Epoch: 121, Validation NLL: 1.0192, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 122, Train NLL: 0.2665\n",
      "Epoch: 122, Validation NLL: 1.0190, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 123, Train NLL: 0.2672\n",
      "Epoch: 123, Validation NLL: 1.0187, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 124, Train NLL: 0.2820\n",
      "Epoch: 124, Validation NLL: 1.0187, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 125, Train NLL: 0.2898\n",
      "Epoch: 125, Validation NLL: 1.0194, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 126, Train NLL: 0.3031\n",
      "Epoch: 126, Validation NLL: 1.0198, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 127, Train NLL: 0.3126\n",
      "Epoch: 127, Validation NLL: 1.0207, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 128, Train NLL: 0.2759\n",
      "Epoch: 128, Validation NLL: 1.0210, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 129, Train NLL: 0.2998\n",
      "Epoch: 129, Validation NLL: 1.0211, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 130, Train NLL: 0.3281\n",
      "Epoch: 130, Validation NLL: 1.0214, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 131, Train NLL: 0.2713\n",
      "Epoch: 131, Validation NLL: 1.0223, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 132, Train NLL: 0.2947\n",
      "Epoch: 132, Validation NLL: 1.0235, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 133, Train NLL: 0.2922\n",
      "Epoch: 133, Validation NLL: 1.0245, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 134, Train NLL: 0.2834\n",
      "Epoch: 134, Validation NLL: 1.0256, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 135, Train NLL: 0.2798\n",
      "Epoch: 135, Validation NLL: 1.0266, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 136, Train NLL: 0.2759\n",
      "Epoch: 136, Validation NLL: 1.0275, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 137, Train NLL: 0.2949\n",
      "Epoch: 137, Validation NLL: 1.0277, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 138, Train NLL: 0.2848\n",
      "Epoch: 138, Validation NLL: 1.0275, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 139, Train NLL: 0.2626\n",
      "Epoch: 139, Validation NLL: 1.0272, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 140, Train NLL: 0.2669\n",
      "Epoch: 140, Validation NLL: 1.0271, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 141, Train NLL: 0.2751\n",
      "Epoch: 141, Validation NLL: 1.0277, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 142, Train NLL: 0.2788\n",
      "Epoch: 142, Validation NLL: 1.0288, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 143, Train NLL: 0.2979\n",
      "Epoch: 143, Validation NLL: 1.0296, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 144, Train NLL: 0.3162\n",
      "Epoch: 144, Validation NLL: 1.0296, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 145, Train NLL: 0.2663\n",
      "Epoch: 145, Validation NLL: 1.0295, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 146, Train NLL: 0.3001\n",
      "Epoch: 146, Validation NLL: 1.0294, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 147, Train NLL: 0.2484\n",
      "Epoch: 147, Validation NLL: 1.0300, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 148, Train NLL: 0.2927\n",
      "Epoch: 148, Validation NLL: 1.0303, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 149, Train NLL: 0.2748\n",
      "Epoch: 149, Validation NLL: 1.0304, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 150, Train NLL: 0.2844\n",
      "Epoch: 150, Validation NLL: 1.0302, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 151, Train NLL: 0.2982\n",
      "Epoch: 151, Validation NLL: 1.0298, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 152, Train NLL: 0.2781\n",
      "Epoch: 152, Validation NLL: 1.0299, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 153, Train NLL: 0.3105\n",
      "Epoch: 153, Validation NLL: 1.0301, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 154, Train NLL: 0.2779\n",
      "Epoch: 154, Validation NLL: 1.0300, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 155, Train NLL: 0.2887\n",
      "Epoch: 155, Validation NLL: 1.0297, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 156, Train NLL: 0.2813\n",
      "Epoch: 156, Validation NLL: 1.0302, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 157, Train NLL: 0.3114\n",
      "Epoch: 157, Validation NLL: 1.0313, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 158, Train NLL: 0.2824\n",
      "Epoch: 158, Validation NLL: 1.0318, Total Acc: 0.561, Acc by label; diploid:0.617 WGD:0.486\n",
      "Epoch: 159, Train NLL: 0.2721\n",
      "Epoch: 159, Validation NLL: 1.0312, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 160, Train NLL: 0.2972\n",
      "Epoch: 160, Validation NLL: 1.0307, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 161, Train NLL: 0.2932\n",
      "Epoch: 161, Validation NLL: 1.0301, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 162, Train NLL: 0.2548\n",
      "Epoch: 162, Validation NLL: 1.0301, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 163, Train NLL: 0.2761\n",
      "Epoch: 163, Validation NLL: 1.0300, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 164, Train NLL: 0.2605\n",
      "Epoch: 164, Validation NLL: 1.0302, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 165, Train NLL: 0.2774\n",
      "Epoch: 165, Validation NLL: 1.0305, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 166, Train NLL: 0.2747\n",
      "Epoch: 166, Validation NLL: 1.0306, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 167, Train NLL: 0.2511\n",
      "Epoch: 167, Validation NLL: 1.0306, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 168, Train NLL: 0.2651\n",
      "Epoch: 168, Validation NLL: 1.0308, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 169, Train NLL: 0.2766\n",
      "Epoch: 169, Validation NLL: 1.0309, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 170, Train NLL: 0.2612\n",
      "Epoch: 170, Validation NLL: 1.0316, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n",
      "Epoch: 171, Train NLL: 0.2795\n",
      "Epoch: 171, Validation NLL: 1.0327, Total Acc: 0.549, Acc by label; diploid:0.617 WGD:0.457\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-85f7d06cf4a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     train_utils.training_loop_pooled_embeddings(e,step_size,optimizer,net,train_embeddings,train_jpgs_to_slide\n\u001b[0;32m----> 5\u001b[0;31m                                     ,train_labels,criterion,n_samples_train,sample_weight)\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     loss,acc = train_utils.validation_loop_pooled_embeddings(e,scheduler,net,val_embeddings,val_jpgs_to_slide\n",
      "\u001b[0;32m~/MSI_prediction/tcga_project/train_utils.py\u001b[0m in \u001b[0;36mtraining_loop_pooled_embeddings\u001b[0;34m(e, step_size, optimizer, net, train_embeddings, train_jpgs_to_slide, train_labels, criterion, n_samples, sample_weight)\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits_vec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m             \u001b[0mtrack_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_embeddings, val_embeddings = train_embeddings.cuda(),val_embeddings.cuda()\n",
    "\n",
    "for e in range(300):\n",
    "    train_utils.training_loop_pooled_embeddings(e,step_size,optimizer,net,train_embeddings,train_jpgs_to_slide\n",
    "                                    ,train_labels,criterion,n_samples_train,sample_weight)\n",
    "    \n",
    "    loss,acc = train_utils.validation_loop_pooled_embeddings(e,scheduler,net,val_embeddings,val_jpgs_to_slide\n",
    "                                    ,val_labels,criterion,n_samples_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "idexs = np.random.choice(idxs_train,size=n_samples_train.numpy(),p=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5232198142414861"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(labels_to_idxs_train[idexs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1,  ..., 1, 1, 1])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6049382716049383"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for idx in range(n_samples):\n",
    "    with torch.no_grad():\n",
    "        slide = train_embeddings[train_jpgs_to_slide==idx]\n",
    "        labels_vec[idx] = train_labels[train_jpgs_to_slide==idx].unique().float().cuda()\n",
    "        logits_vec[idx] = torch.mean(linear_layer(slide))\n",
    "np.mean(labels_vec.cpu().numpy() == (logits_vec>0.5).float().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_embeddings\n",
    "torch.cuda.empty_cache()\n",
    "val_embeddings = val_embeddings.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.573170731707317"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = val_jpgs_to_slide.max()+1\n",
    "logits_vec = torch.zeros((n_samples,1)).cuda()\n",
    "labels_vec = torch.zeros_like(logits_vec).cuda()\n",
    "for idx in range(n_samples):\n",
    "    with torch.no_grad():\n",
    "        slide = val_embeddings[val_jpgs_to_slide==idx]\n",
    "        labels_vec[idx] = val_labels[val_jpgs_to_slide==idx].unique().float().cuda()\n",
    "        logits_vec[idx] = torch.mean(linear_layer(slide))\n",
    "np.mean(labels_vec.cpu().numpy() == (logits_vec>0.5).float().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "del val_embeddings\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   0,   0,  ..., 323, 323, 323])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_jpgs_to_slide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([ 2.3519e-01,  2.6554e-01, -5.1096e-08,  5.1923e-01,  3.4404e-09,\n",
       "          2.2344e-01,  4.2637e-01,  1.3153e-07,  2.5157e-01,  1.5152e-06,\n",
       "          3.1649e-01,  2.5043e-01,  3.7927e-01,  1.0862e-05,  2.7462e-01,\n",
       "          2.3937e-01,  2.4569e-01,  3.9352e-01,  4.6928e-01,  2.8979e-01,\n",
       "          2.7206e-01,  2.7792e-01,  2.9089e-01,  2.0875e-01,  2.6028e-01,\n",
       "          2.7721e-01,  2.9026e-01,  3.1510e-01,  3.8906e-01,  3.0260e-01,\n",
       "          2.6793e-01,  2.1056e-01,  2.9101e-01,  3.3062e-01,  4.2879e-01,\n",
       "          3.7352e-01,  7.4804e-08,  1.9000e-01,  1.4740e-08,  2.2349e-01,\n",
       "          1.8079e-01,  2.4823e-01,  2.7352e-01,  2.5917e-01,  2.9366e-01,\n",
       "          3.0109e-01,  2.2261e-01,  2.6257e-01,  2.2001e-08,  2.6461e-01,\n",
       "          2.2089e-01,  2.8305e-01,  3.2998e-01,  2.2688e-01,  3.6608e-01,\n",
       "          2.1172e-01,  2.3945e-01,  2.4885e-01,  5.2481e-01,  2.4803e-01,\n",
       "          2.9450e-01,  2.6038e-01,  4.8347e-01,  2.6588e-01]),\n",
       " Parameter containing:\n",
       " tensor([ 2.2954e-01,  2.5401e-01, -1.0543e-06, -6.6424e-01, -1.6571e-08,\n",
       "          1.6263e-01,  4.5518e-01, -4.3020e-07,  3.0035e-01, -8.0052e-06,\n",
       "          3.4888e-01,  3.1225e-01, -2.4968e-01, -3.4749e-05,  1.0783e-01,\n",
       "          2.2189e-01,  3.8360e-01, -5.3182e-01, -6.2936e-01,  5.6901e-01,\n",
       "          2.9901e-01,  5.8455e-01,  4.8208e-01,  3.3082e-01,  1.9727e-01,\n",
       "          1.9508e-01,  1.5226e-01,  8.4807e-02,  5.1254e-01,  1.3805e-02,\n",
       "          1.6597e-01,  3.3180e-01,  2.5182e-01,  4.4212e-01, -2.7840e-01,\n",
       "         -1.8520e-02, -2.4507e-07,  3.2190e-01, -4.9152e-08,  2.3802e-01,\n",
       "          2.3291e-01,  3.1531e-01,  4.2660e-01,  2.9376e-01,  2.6400e-01,\n",
       "          6.7600e-01,  4.2829e-01,  3.4663e-01, -8.6909e-08,  2.4705e-01,\n",
       "          3.0248e-01,  6.1644e-01,  3.9994e-01,  3.3317e-01, -4.1267e-01,\n",
       "          3.7662e-01,  1.7738e-01,  2.5774e-01, -4.5077e-01,  2.1234e-01,\n",
       "          5.6915e-01,  5.7272e-01, -4.0310e-01,  2.3473e-01])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p for p in resnet.bn1.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

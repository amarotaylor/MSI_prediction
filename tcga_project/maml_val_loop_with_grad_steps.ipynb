{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import torch\n",
    "import scipy\n",
    "import psutil\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, set_image_backend\n",
    "\n",
    "import data_utils\n",
    "import train_utils\n",
    "import model_utils\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "set_image_backend('accimage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "set_image_backend('accimage')\n",
    "device = torch.device('cuda', 1)\n",
    "\n",
    "# load sample annotations pickle\n",
    "pickle_file = '/home/sxchao/MSI_prediction/tcga_project/tcga_wgd_sa_all.pkl'\n",
    "batch_all, _, _, sa_trains, sa_vals = data_utils.load_COAD_train_val_sa_pickle(pickle_file=pickle_file,\n",
    "                                                                               return_all_cancers=True, \n",
    "                                                                               split_in_two=True)\n",
    "# normalize and tensorify jpegs\n",
    "val_transform = train_utils.transform_validation\n",
    "\n",
    "# initialize Datasets\n",
    "val_sets = []\n",
    "val_cancers = ['UCEC', 'LIHC_10x', 'KIRC_10x']\n",
    "magnification = '10.0'\n",
    "root_dir = '/n/mounted-data-drive/'\n",
    "for j in range(len(val_cancers)):\n",
    "    val_set = data_utils.TCGADataset_tiles(sa_vals[batch_all.index(val_cancers[j])], \n",
    "                                           root_dir + val_cancers[j] + '/', \n",
    "                                           transform=val_transform, \n",
    "                                           magnification=magnification, \n",
    "                                           batch_type='tile', \n",
    "                                           return_jpg_to_sample=True)\n",
    "    val_sets.append(val_set)\n",
    "\n",
    "# get DataLoaders    \n",
    "batch_size_val = 400\n",
    "n_workers = 16\n",
    "val_loaders = [torch.utils.data.DataLoader(val_set, batch_size=batch_size_val, shuffle=True, \n",
    "                                           num_workers=n_workers, pin_memory=True) for val_set in val_sets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model args\n",
    "state_dict_file_resnet = '/n/tcga_models/resnet18_WGD_all_10x.pt'\n",
    "state_dict_file_maml = '/n/tcga_models/maml_WGD_10x_v02a.pt'\n",
    "input_size = 2048\n",
    "hidden_size = 512\n",
    "output_size = 1\n",
    "\n",
    "# initialize trained resnet\n",
    "resnet = models.resnet18(pretrained=False)\n",
    "resnet.fc = nn.Linear(2048, output_size, bias=True)\n",
    "saved_state = torch.load(state_dict_file_resnet, map_location=lambda storage, loc: storage)\n",
    "resnet.load_state_dict(saved_state)\n",
    "\n",
    "# freeze layers\n",
    "resnet.fc = model_utils.Identity()\n",
    "resnet.cuda(device=device)\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "resnet.eval()\n",
    "\n",
    "# initialize theta_global\n",
    "net = model_utils.FeedForward(input_size, hidden_size, output_size)\n",
    "saved_state = torch.load(state_dict_file_maml, map_location=lambda storage, loc: storage)\n",
    "net.load_state_dict(saved_state)\n",
    "net.cuda(device=device)\n",
    "theta_global = [p.detach().clone() for p in net.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 5\n",
    "all_logits = {}\n",
    "for i in range(num_steps):\n",
    "    all_logits[i] = []\n",
    "all_labels = []\n",
    "all_types = []\n",
    "all_jpgs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1e-2\n",
    "criterion_mean = nn.BCEWithLogitsLoss()\n",
    "criterion_none = nn.BCEWithLogitsLoss(reduction = 'none')\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 "
     ]
    }
   ],
   "source": [
    "cancer_num = 1\n",
    "print(len(val_loaders[cancer_num]))\n",
    "for batch_num,(tiles,labels,jpg_to_sample) in enumerate(val_loaders[cancer_num]):\n",
    "    print(batch_num, end=' ')    \n",
    "    tiles, labels = tiles.cuda(device=device), labels.cuda(device=device).float()\n",
    "    idx = int(tiles.shape[0] / 2)\n",
    "    inputs_a = tiles[:idx,:,:,:]\n",
    "    inputs_b = tiles[idx:,:,:,:]\n",
    "    labels_a = labels[:idx].unsqueeze(1)\n",
    "    labels_b = labels[idx:].unsqueeze(1)    \n",
    "    labels = labels_b.contiguous().view(-1).detach().cpu().numpy()\n",
    "    jpg_to_sample = jpg_to_sample[idx:].view(-1).float().numpy()\n",
    "    all_labels.extend(labels)\n",
    "    all_types.extend([cancer_num] * round(tiles.shape[0] / 2)) # last batch may have odd number of tiles\n",
    "    all_jpgs.extend(jpg_to_sample)\n",
    "    \n",
    "    for step in range(num_steps): \n",
    "        optimizer.zero_grad()\n",
    "        if step == 0:\n",
    "            net.eval()                \n",
    "            output_b = net(resnet(inputs_b))\n",
    "            logits = output_b.contiguous().view(-1).float().detach().cpu().numpy()\n",
    "            all_logits[step].extend(logits)\n",
    "        else:\n",
    "            # first forward pass, step \n",
    "            net.train()\n",
    "            output_a = net(resnet(inputs_a))\n",
    "            loss = criterion_mean(output_a, labels_a)\n",
    "            loss.backward()\n",
    "            optimizer.step()            \n",
    "            # second forward pass   \n",
    "            net.eval()\n",
    "            output_b = net(resnet(inputs_b))\n",
    "            logits = output_b.contiguous().view(-1).float().detach().cpu().numpy()\n",
    "            all_logits[step].extend(logits)\n",
    "    net.update_params(theta_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'label': all_labels, 'logit': all_logits, 'type': all_types, 'sample': all_jpgs}\n",
    "df = pd.DataFrame(data = d)\n",
    "df2 = df.groupby(['type','sample'])['label','logit'].mean().round()\n",
    "loss = criterion_none(torch.tensor(df2['logit'].values, device=device), torch.tensor(df2['label'].values, device=device))\n",
    "torch.std(loss)\n",
    "torch.mean(loss)\n",
    "torch.median(loss)\n",
    "torch.exp(-loss)\n",
    "\n",
    "plt.hist(loss.detach().cpu().numpy(), bins=100, density=True)\n",
    "plt.show()\n",
    "\n",
    "#df2['loss'] = loss.detach().cpu().numpy()\n",
    "#df2.groupby(['label']).hist()\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(np.array(df2['label']), scipy.special.expit(np.array(df2['logit'])))\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Slide-level receiver operating characteristic (WGD)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

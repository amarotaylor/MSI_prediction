{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import accimage\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from imageio import imread\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, models, transforms, set_image_backend, get_image_backend\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "import train_utils\n",
    "import data_utils\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import torch\n",
    "import psutil\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, set_image_backend\n",
    "set_image_backend('accimage')\n",
    "from data_utils import *\n",
    "import train_utils\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "state_dict_file = '/n/tcga_models/resnet18_WGD_all_10x.pt'\n",
    "input_size = 2048\n",
    "hidden_size = 512\n",
    "output_size = 1\n",
    "\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, gated=False):\n",
    "        super(Attention, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.gated = gated\n",
    "        self.V = nn.Linear(input_size, hidden_size)\n",
    "        self.U = nn.Linear(input_size, hidden_size)\n",
    "        self.w = nn.Linear(hidden_size, output_size)\n",
    "        self.sigm = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.sm = nn.Softmax(dim=0)\n",
    "        self.linear_layer = nn.Linear(input_size,1)\n",
    "        \n",
    "    def forward(self, h):\n",
    "        if self.gated == True:\n",
    "            a = self.sm(self.w(self.tanh(self.V(h)) * self.sigm(self.U(h))))\n",
    "        else:\n",
    "            a = self.sm(self.w(self.tanh(self.V(h))))\n",
    "        z = torch.sum(a*h,dim=0)\n",
    "        logits = self.linear_layer(z)\n",
    "        return logits,a\n",
    "\n",
    "\n",
    "# initialize trained resnet\n",
    "resnet = models.resnet18(pretrained=False)\n",
    "resnet.fc = nn.Linear(2048, output_size, bias=True)\n",
    "saved_state = torch.load(state_dict_file, map_location=lambda storage, loc: storage)\n",
    "resnet.load_state_dict(saved_state)\n",
    "device = torch.device('cuda',1)\n",
    "for p in resnet.parameters():\n",
    "    p.requires_grad = False\n",
    "attend_and_pool = Attention(input_size, hidden_size, output_size)\n",
    "resnet.fc = attend_and_pool\n",
    "resnet.cuda(device=device)\n",
    "\n",
    "\n",
    "optim = torch.optim.Adam(resnet.fc.parameters(), lr = 1e-4)\n",
    "train_cancers = ['READ_10x']\n",
    "val_cancers = ['READ_10x']\n",
    "\n",
    "root_dir = '/n/mounted-data-drive/'\n",
    "magnification = '10.0'\n",
    "criterion=nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCGA_random_tiles_sampler(Dataset):\n",
    "    \"\"\"TCGA dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, sample_annotations, root_dir, transform=None, loader=default_loader, \n",
    "                 magnification='5.0', tile_batch_size = 256):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sample_annot (dict): dictionary of sample names and their respective labels.\n",
    "            root_dir (string): directory containing all of the samples and their respective images.\n",
    "            transform (callable, optional): optional transform to be applied on the images of a sample.\n",
    "        \"\"\"\n",
    "        self.sample_names = list(sample_annotations.keys())\n",
    "        self.sample_labels = list(sample_annotations.values())\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.loader = loader\n",
    "        self.magnification = magnification\n",
    "        self.img_dirs = [self.root_dir + sample_name + '.svs/' \\\n",
    "                         + sample_name + '_files/' + self.magnification for sample_name in self.sample_names]\n",
    "        self.jpegs = [os.listdir(img_dir) for img_dir in self.img_dirs]\n",
    "        self.all_jpegs = []\n",
    "        self.all_labels = []\n",
    "        self.jpg_to_sample = []\n",
    "        self.coords = []\n",
    "        self.tile_batch_size = tile_batch_size\n",
    "        for idx,(im_dir,label,l) in enumerate(zip(self.img_dirs,self.sample_labels,self.jpegs)):\n",
    "            sample_coords = []\n",
    "            for jpeg in l:\n",
    "                self.all_jpegs.append(im_dir+'/'+jpeg)\n",
    "                self.all_labels.append(label)\n",
    "                self.jpg_to_sample.append(idx)\n",
    "                x,y = jpeg[:-5].split('_') # 'X_Y.jpeg'\n",
    "                x,y = int(x), int(y)\n",
    "                sample_coords.append(torch.tensor([x,y]))\n",
    "            self.coords.append(torch.stack(sample_coords))\n",
    "                \n",
    "            \n",
    "    def __len__(self):\n",
    "        ''' number of slides: jpegs is a list of lists '''\n",
    "        return len(self.jpegs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        slide_tiles = []\n",
    "        tiles_batch = []\n",
    "        perm = torch.randperm(len(self.jpegs[idx]))\n",
    "        \n",
    "        if len(self.jpegs[idx]) > self.tile_batch_size:\n",
    "            idxs = perm[:self.tile_batch_size]\n",
    "        else: \n",
    "            idxs = range(len(self.jpegs[idx]))\n",
    "            \n",
    "        for tile_num in idxs:\n",
    "            im = self.jpegs[idx][tile_num]\n",
    "            path = self.img_dirs[idx] + '/' + im\n",
    "            image = self.loader(path)\n",
    "            \n",
    "            if self.transform is not None:\n",
    "                image = self.transform(image)\n",
    "            if image.shape[1] < 256 or image.shape[2] < 256:\n",
    "                image = pad_tensor_up_to(image,256,256,channels_last=False)\n",
    "            tiles_batch.append(image)\n",
    "\n",
    "        # create batch of random tiles\n",
    "        slide = torch.stack(tiles_batch)\n",
    "\n",
    "        label = self.sample_labels[idx]\n",
    "        coords = torch.stack([self.coords[idx][i] for i in idxs])\n",
    "        return slide, label, coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_train, sa_val = data_utils.load_COAD_train_val_sa_pickle('/n/tcga_models/resnet18_WGD_v04_sa.pkl')\n",
    "pickle_file = '/home/sxchao/MSI_prediction/tcga_project/tcga_wgd_sa_all.pkl'\n",
    "batch_all, sa_train1, sa_val1, sa_train2, sa_val2 = data_utils.load_COAD_train_val_sa_pickle(pickle_file=pickle_file,\n",
    "                                                                               return_all_cancers=True, \n",
    "                                                                               split_in_two=True)\n",
    "\n",
    "sa_trains = [dict(sa_train1[idx], **sa_train2[idx]) for idx,_ in enumerate(sa_train1)]\n",
    "sa_vals = [dict(sa_val1[idx], **sa_val2[idx]) for idx,_ in enumerate(sa_val1)]\n",
    "\n",
    "\n",
    "train_transform = train_utils.transform_train\n",
    "val_transform = train_utils.transform_validation\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "magnification = '10.0'\n",
    "root_dir = '/n/mounted-data-drive/'\n",
    "\n",
    "train_sets = []\n",
    "val_sets = []\n",
    "\n",
    "for i in range(len(train_cancers)):\n",
    "    train_set = data_utils.TCGA_random_tiles_sampler(sa_trains[batch_all.index(train_cancers[i])], \n",
    "                                             root_dir + train_cancers[i] + '/', \n",
    "                                             transform=train_transform, \n",
    "                                             magnification=magnification,tile_batch_size=512)\n",
    "    train_sets.append(train_set)    \n",
    "\n",
    "for j in range(len(val_cancers)):\n",
    "    val_set = data_utils.TCGA_random_tiles_sampler(sa_vals[batch_all.index(val_cancers[j])], \n",
    "                                           root_dir + val_cancers[j] + '/', \n",
    "                                           transform=val_transform, \n",
    "                                           magnification=magnification,tile_batch_size=512)\n",
    "    val_sets.append(val_set)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set,batch_size=1,shuffle=True,num_workers=16, \n",
    "                                            pin_memory=False)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_set,batch_size=1,shuffle=True,num_workers=16, \n",
    "                                            pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop_random_sampling(e,train_loader,device,criterion,resnet,optimizer,gradient_step_length=3,reporting_step_length=10):\n",
    "    grads = []\n",
    "    track_loss = torch.tensor(0.0,device=device)\n",
    "    for p in resnet.fc.parameters():\n",
    "        grads.append(torch.zeros_like(p.data,device=device))\n",
    "    for step,(slide, label, coords) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        slide,label = slide.squeeze(0).cuda(device),label.cuda(device)\n",
    "        logits,_ = resnet(slide)\n",
    "        loss = criterion(logits,label.float())\n",
    "        loss.backward()\n",
    "        track_loss += loss.detach().clone()\n",
    "        for ix,p in enumerate(resnet.fc.parameters()):\n",
    "            grads[ix] += p.grad.detach().clone()\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        if step%gradient_step_length ==0 and step>0:\n",
    "            for ix,p in enumerate(resnet.fc.parameters()):\n",
    "                p.grad.data = grads[ix]/gradient_step_length\n",
    "                grads[ix] = torch.zeros_like(p.data,device=device)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "                \n",
    "        if step%reporting_step_length == 0 and step>0:\n",
    "            print('Epoch: {0}, Step: {1}, Train NLL: {2:0.4f}'.format(e, step, track_loss.detach().cpu().numpy()/reporting_step_length))\n",
    "            track_loss = 0.0\n",
    "    del slide, label, loss, logits, _\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_loop_for_random_sampler(e,val_loader,device,criterion,resnet):\n",
    "    pred_batch = []\n",
    "    true_label = []\n",
    "    torch.cuda.empty_cache()\n",
    "    loss = torch.tensor(0.0,device=device)\n",
    "    with torch.no_grad():\n",
    "        for step,(slide, label, coords) in enumerate(val_loader):\n",
    "            slide,label = slide.squeeze(0).cuda(device),label.cuda(device)\n",
    "            logits,_ = resnet(slide)\n",
    "            loss += criterion(logits,label.float())\n",
    "            pred_batch.append(torch.sigmoid(logits).detach().cpu().numpy()>0.5)\n",
    "            true_label.append(label.detach().cpu().numpy())\n",
    "            \n",
    "            del slide,label,logits,_\n",
    "            torch.cuda.empty_cache()\n",
    "    #scheduler.step(loss)\n",
    "    pred_batch = np.array(pred_batch)\n",
    "    true_label = np.array(true_label)\n",
    "    acc = np.mean(pred_batch==true_label)\n",
    "    acc_1 = np.mean(pred_batch[true_label==1])\n",
    "    acc_0 = np.mean(1-pred_batch[true_label==0])\n",
    "    loss = loss.detach().cpu().numpy()\n",
    "    \n",
    "    print('Epoch: {0}, Val Mean NLL: {1:0.4f}, Val Accuracy: {2:0.2f} \\\n",
    "           Class Accuracy: WGD = {3:0.2f}, Diploid = {4:0.2f}'\\\n",
    "              .format(e,loss/step,acc,acc_1,acc_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Step: 0, Train NLL: 0.4971\n",
      "Epoch: 0, Step: 30, Train NLL: 9.5432\n",
      "Epoch: 0, Step: 60, Train NLL: 11.7971\n",
      "Epoch: 0, Step: 90, Train NLL: 15.6518\n",
      "Epoch: 0, Val Total NLL: 40.6831, Val Accuracy: 0.38            Class Accuracy: WGD = 0.40, Diploid = 0.37\n",
      "Epoch: 1, Step: 0, Train NLL: 0.1479\n",
      "Epoch: 1, Step: 30, Train NLL: 17.3398\n",
      "Epoch: 1, Step: 60, Train NLL: 9.5740\n",
      "Epoch: 1, Step: 90, Train NLL: 13.1353\n",
      "Epoch: 1, Val Total NLL: 30.3013, Val Accuracy: 0.41            Class Accuracy: WGD = 0.50, Diploid = 0.37\n",
      "Epoch: 2, Step: 0, Train NLL: 0.4447\n",
      "Epoch: 2, Step: 30, Train NLL: 11.6979\n",
      "Epoch: 2, Step: 60, Train NLL: 13.0108\n",
      "Epoch: 2, Step: 90, Train NLL: 16.3869\n",
      "Epoch: 2, Val Total NLL: 40.2237, Val Accuracy: 0.41            Class Accuracy: WGD = 0.50, Diploid = 0.37\n",
      "Epoch: 3, Step: 0, Train NLL: 0.4103\n",
      "Epoch: 3, Step: 30, Train NLL: 11.5963\n",
      "Epoch: 3, Step: 60, Train NLL: 10.4036\n",
      "Epoch: 3, Step: 90, Train NLL: 9.5632\n",
      "Epoch: 3, Val Total NLL: 35.9975, Val Accuracy: 0.38            Class Accuracy: WGD = 0.30, Diploid = 0.42\n",
      "Epoch: 4, Step: 0, Train NLL: 0.1966\n",
      "Epoch: 4, Step: 30, Train NLL: 13.3153\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-cf0d12a95dea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtraining_loop_random_sampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mvalidation_loop_for_random_sampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-efb89c6151ed>\u001b[0m in \u001b[0;36mtraining_loop_random_sampling\u001b[0;34m(e, train_loader, device, criterion, resnet, optimizer)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mslide\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslide\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslide\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for e in range(100):\n",
    "    training_loop_random_sampling(e,train_loader,device,criterion,resnet,optim)\n",
    "    validation_loop_for_random_sampler(e,val_loader,device,criterion,resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_dev_train = dict()\n",
    "for ix,(key, val) in enumerate(sa_trains[5].items()):\n",
    "    sa_dev_train[key] = val\n",
    "    if ix ==10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = data_utils.TCGA_random_tiles_sampler(sa_dev_train, \n",
    "                                             root_dir + train_cancers[0] + '/', \n",
    "                                             transform=train_transform, \n",
    "                                             magnification=magnification,tile_batch_size=512)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set,batch_size=1,shuffle=True,num_workers=16, \n",
    "                                            pin_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Step: 3, Train NLL: 0.1772\n",
      "Epoch: 0, Step: 6, Train NLL: 0.2087\n",
      "Epoch: 0, Step: 9, Train NLL: 0.2479\n",
      "Epoch: 1, Step: 3, Train NLL: 0.1943\n",
      "Epoch: 1, Step: 6, Train NLL: 0.1124\n",
      "Epoch: 1, Step: 9, Train NLL: 0.0910\n",
      "Epoch: 2, Step: 3, Train NLL: 0.1909\n",
      "Epoch: 2, Step: 6, Train NLL: 0.0399\n",
      "Epoch: 2, Step: 9, Train NLL: 0.1268\n",
      "Epoch: 3, Step: 3, Train NLL: 0.1708\n",
      "Epoch: 3, Step: 6, Train NLL: 0.1538\n",
      "Epoch: 3, Step: 9, Train NLL: 0.1201\n",
      "Epoch: 4, Step: 3, Train NLL: 0.8201\n",
      "Epoch: 4, Step: 6, Train NLL: 0.0482\n",
      "Epoch: 4, Step: 9, Train NLL: 0.1233\n",
      "Epoch: 5, Step: 3, Train NLL: 0.2890\n",
      "Epoch: 5, Step: 6, Train NLL: 0.1268\n",
      "Epoch: 5, Step: 9, Train NLL: 0.0539\n",
      "Epoch: 6, Step: 3, Train NLL: 0.3106\n",
      "Epoch: 6, Step: 6, Train NLL: 0.0617\n",
      "Epoch: 6, Step: 9, Train NLL: 0.1161\n",
      "Epoch: 7, Step: 3, Train NLL: 0.2309\n",
      "Epoch: 7, Step: 6, Train NLL: 0.1127\n",
      "Epoch: 7, Step: 9, Train NLL: 0.1715\n",
      "Epoch: 8, Step: 3, Train NLL: 0.1389\n",
      "Epoch: 8, Step: 6, Train NLL: 0.0622\n",
      "Epoch: 8, Step: 9, Train NLL: 0.1609\n",
      "Epoch: 9, Step: 3, Train NLL: 0.1523\n",
      "Epoch: 9, Step: 6, Train NLL: 0.2809\n",
      "Epoch: 9, Step: 9, Train NLL: 0.1051\n",
      "Epoch: 10, Step: 3, Train NLL: 0.0655\n",
      "Epoch: 10, Step: 6, Train NLL: 0.5083\n",
      "Epoch: 10, Step: 9, Train NLL: 0.0824\n",
      "Epoch: 11, Step: 3, Train NLL: 0.1076\n",
      "Epoch: 11, Step: 6, Train NLL: 0.0726\n",
      "Epoch: 11, Step: 9, Train NLL: 0.0901\n",
      "Epoch: 12, Step: 3, Train NLL: 0.0952\n",
      "Epoch: 12, Step: 6, Train NLL: 0.1385\n",
      "Epoch: 12, Step: 9, Train NLL: 0.4006\n",
      "Epoch: 13, Step: 3, Train NLL: 0.0574\n",
      "Epoch: 13, Step: 6, Train NLL: 0.4544\n",
      "Epoch: 13, Step: 9, Train NLL: 0.1334\n",
      "Epoch: 14, Step: 3, Train NLL: 0.2816\n",
      "Epoch: 14, Step: 6, Train NLL: 0.0558\n",
      "Epoch: 14, Step: 9, Train NLL: 0.0613\n",
      "Epoch: 15, Step: 3, Train NLL: 0.0989\n",
      "Epoch: 15, Step: 6, Train NLL: 0.1049\n",
      "Epoch: 15, Step: 9, Train NLL: 0.0728\n",
      "Epoch: 16, Step: 3, Train NLL: 0.0757\n",
      "Epoch: 16, Step: 6, Train NLL: 0.1605\n",
      "Epoch: 16, Step: 9, Train NLL: 0.1021\n",
      "Epoch: 17, Step: 3, Train NLL: 0.1371\n",
      "Epoch: 17, Step: 6, Train NLL: 0.0538\n",
      "Epoch: 17, Step: 9, Train NLL: 0.0622\n",
      "Epoch: 18, Step: 3, Train NLL: 0.0689\n",
      "Epoch: 18, Step: 6, Train NLL: 0.1266\n",
      "Epoch: 18, Step: 9, Train NLL: 0.0208\n",
      "Epoch: 19, Step: 3, Train NLL: 0.0841\n",
      "Epoch: 19, Step: 6, Train NLL: 0.5011\n",
      "Epoch: 19, Step: 9, Train NLL: 0.0437\n",
      "Epoch: 20, Step: 3, Train NLL: 0.1268\n",
      "Epoch: 20, Step: 6, Train NLL: 0.0659\n",
      "Epoch: 20, Step: 9, Train NLL: 0.0860\n",
      "Epoch: 21, Step: 3, Train NLL: 0.0571\n",
      "Epoch: 21, Step: 6, Train NLL: 0.2483\n",
      "Epoch: 21, Step: 9, Train NLL: 0.1622\n",
      "Epoch: 22, Step: 3, Train NLL: 0.2955\n",
      "Epoch: 22, Step: 6, Train NLL: 0.0556\n",
      "Epoch: 22, Step: 9, Train NLL: 0.0342\n",
      "Epoch: 23, Step: 3, Train NLL: 0.0856\n",
      "Epoch: 23, Step: 6, Train NLL: 0.0743\n",
      "Epoch: 23, Step: 9, Train NLL: 0.2329\n",
      "Epoch: 24, Step: 3, Train NLL: 0.1463\n",
      "Epoch: 24, Step: 6, Train NLL: 0.0558\n",
      "Epoch: 24, Step: 9, Train NLL: 0.0213\n",
      "Epoch: 25, Step: 3, Train NLL: 0.0818\n",
      "Epoch: 25, Step: 6, Train NLL: 0.0488\n",
      "Epoch: 25, Step: 9, Train NLL: 0.0524\n",
      "Epoch: 26, Step: 3, Train NLL: 0.1337\n",
      "Epoch: 26, Step: 6, Train NLL: 0.0211\n",
      "Epoch: 26, Step: 9, Train NLL: 0.0993\n",
      "Epoch: 27, Step: 3, Train NLL: 0.0237\n",
      "Epoch: 27, Step: 6, Train NLL: 0.0794\n",
      "Epoch: 27, Step: 9, Train NLL: 0.0463\n",
      "Epoch: 28, Step: 3, Train NLL: 0.0871\n",
      "Epoch: 28, Step: 6, Train NLL: 0.1777\n",
      "Epoch: 28, Step: 9, Train NLL: 0.0361\n",
      "Epoch: 29, Step: 3, Train NLL: 0.0421\n",
      "Epoch: 29, Step: 6, Train NLL: 0.0481\n",
      "Epoch: 29, Step: 9, Train NLL: 0.0294\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-234b840347b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtraining_loop_random_sampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgradient_step_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreporting_step_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-f3ce6c74c7a1>\u001b[0m in \u001b[0;36mtraining_loop_random_sampling\u001b[0;34m(e, train_loader, device, criterion, resnet, optimizer, gradient_step_length, reporting_step_length)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mslide\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslide\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;31m# need to call `.task_done()` because we don't use `.join()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/anaconda3/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/anaconda3/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/anaconda3/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/anaconda3/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for e in range(100):\n",
    "    training_loop_random_sampling(e,train_loader,device,criterion,resnet,optim,gradient_step_length=3,reporting_step_length=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

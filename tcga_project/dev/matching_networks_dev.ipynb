{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import psutil\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, set_image_backend\n",
    "\n",
    "import data_utils\n",
    "import train_utils\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "set_image_backend('accimage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define global variables\n",
    "classification = 'WGD'\n",
    "magnification = '10.0'\n",
    "output_shape = 1\n",
    "device = torch.device('cuda', 1)\n",
    "root_dir = '/n/mounted-data-drive/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep Images - DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get image file paths\n",
    "batch_one = ['COAD', 'BRCA', 'UCEC']\n",
    "batch_two_orig = ['BLCA', 'KIRC', 'READ', 'HNSC', 'LUSC', 'LIHC', 'LUAD', 'STAD']\n",
    "if magnification == '10.0':\n",
    "    batch_two = [b + '_10x' for b in batch_two_orig]\n",
    "elif magnification == '5.0':\n",
    "    batch_two = [b + '_5x' for b in batch_two_orig]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sample annotations\n",
    "# NOTE: ONLY FOR WGD\n",
    "wgd_path = 'ALL_WGD_TABLE.xlsx'\n",
    "wgd_raw = pd.read_excel(wgd_path)\n",
    "#wgd_raw.head(3)\n",
    "\n",
    "batch_all_orig = batch_one + batch_two_orig\n",
    "wgd_filtered = wgd_raw.loc[wgd_raw['Type'].isin(batch_all_orig)]\n",
    "#wgd_filtered.head(3)\n",
    "\n",
    "wgd_filtered.loc[wgd_filtered['Genome_doublings'].values == 2, 'Genome_doublings'] = 1\n",
    "\n",
    "wgd_filtered.set_index('Sample', inplace=True)\n",
    "#wgd_filtered.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting stats for poster\n",
    "sa_trains = []\n",
    "sa_vals = []\n",
    "batch_all = batch_one + batch_two\n",
    "val_transform = train_utils.transform_validation\n",
    "\n",
    "for cancer in batch_all:\n",
    "    print(cancer)\n",
    "    sa_train, sa_val = data_utils.process_WGD_data(root_dir='/n/mounted-data-drive/', cancer_type=cancer, wgd_path=None, \n",
    "                                                                         split_in_two=False, \n",
    "                                                                         print_stats=False, \n",
    "                                                                         wgd_raw=wgd_filtered)\n",
    "    print(len(list(sa_train.keys())) + len(list(sa_val.keys())), np.sum(np.array(list(sa_train.values()))) + np.sum(np.array(list(sa_val.values()))))\n",
    "    train_set = data_utils.TCGADataset_tiles(sa_train, root_dir + cancer + '/', transform=val_transform, magnification=magnification, batch_type='tile')\n",
    "    val_set = data_utils.TCGADataset_tiles(sa_val, root_dir + cancer + '/', transform=val_transform, magnification=magnification, batch_type='tile')\n",
    "    print(len(train_set.jpg_to_sample) + len(val_set.jpg_to_sample), np.sum(np.array(train_set.all_labels)) + np.sum(np.array(val_set.all_labels)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sample annotations for all cancer types\n",
    "# split samples into two sets of train/val\n",
    "sa_trains1 = []\n",
    "sa_vals1 = []\n",
    "sa_trains2 = []\n",
    "sa_vals2 = []\n",
    "batch_all = batch_one + batch_two\n",
    "\n",
    "print('Num Samples with Images and Labels:')\n",
    "for cancer in batch_all:\n",
    "    sa_train1, sa_val1, sa_train2, sa_val2 = data_utils.process_WGD_data(root_dir='/n/mounted-data-drive/', \n",
    "                                                                         cancer_type=cancer, \n",
    "                                                                         wgd_path=None, \n",
    "                                                                         split_in_two=True, \n",
    "                                                                         print_stats=True, \n",
    "                                                                         wgd_raw=wgd_filtered)\n",
    "    sa_trains1.append(sa_train1)\n",
    "    sa_vals1.append(sa_val1)\n",
    "    sa_trains2.append(sa_train2)\n",
    "    sa_vals2.append(sa_val2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save sample annotations in a pickle\n",
    "pickle_file = '/home/sxchao/MSI_prediction/tcga_project/tcga_wgd_sa_all.pkl'\n",
    "with open(pickle_file, 'wb') as f: \n",
    "    pickle.dump([batch_all, sa_trains1, sa_vals1, sa_trains2, sa_vals2], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sample annotations pickle\n",
    "pickle_file = '/home/sxchao/MSI_prediction/tcga_project/tcga_wgd_sa_all.pkl'\n",
    "batch_all, sa_trains1, sa_vals1, sa_trains, sa_vals = data_utils.load_COAD_train_val_sa_pickle(pickle_file=pickle_file, \n",
    "                                                                               return_all_cancers=True, \n",
    "                                                                               split_in_two=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize Datasets\n",
    "train_sets = []\n",
    "val_sets = []\n",
    "\n",
    "train_transform = train_utils.transform_train\n",
    "val_transform = train_utils.transform_validation\n",
    "\n",
    "train_cancers = ['COAD', 'BRCA', 'READ_10x', 'LUSC_10x', 'BLCA_10x', 'LUAD_10x', 'STAD_10x', 'HNSC_10x']\n",
    "val_cancers = ['UCEC', 'LIHC_10x', 'KIRC_10x']\n",
    "all_cancers = train_cancers + val_cancers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(all_cancers)):\n",
    "    print(all_cancers[i], end=' ')\n",
    "    train_set = data_utils.TCGADataset_tiles(sa_trains1[batch_all.index(all_cancers[i])], \n",
    "                                             root_dir + all_cancers[i] + '/', \n",
    "                                             transform=train_transform, \n",
    "                                             magnification=magnification, \n",
    "                                             batch_type='tile')\n",
    "    train_sets.append(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(all_cancers)):\n",
    "    print(all_cancers[j], end=' ')\n",
    "    val_set = data_utils.TCGADataset_tiles(sa_vals1[batch_all.index(all_cancers[j])], \n",
    "                                           root_dir + all_cancers[j] + '/', \n",
    "                                           transform=val_transform, \n",
    "                                           magnification=magnification, \n",
    "                                           batch_type='tile')\n",
    "    val_sets.append(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Num Tiles:')\n",
    "for cancer, tset, vset in zip(batch_all, train_sets, val_sets):\n",
    "    print('{0:<8}  Train: {1:>10,d}              Val: {2:>8,d}'.format(cancer, tset.__len__(), vset.__len__()))\n",
    "    print('          Train: (0) {0:0.4f}, (1) {1:0.4f}  Val: (0) {2:0.4f} (1) {3:0.4f}'.format(np.mean(np.array(tset.all_labels) == 0),\n",
    "                                                                                              np.mean(np.array(tset.all_labels) == 1),\n",
    "                                                                                              np.mean(np.array(vset.all_labels) == 0),\n",
    "                                                                                              np.mean(np.array(vset.all_labels) == 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model file paths\n",
    "if classification == 'WGD':\n",
    "    if magnification == '10.0':\n",
    "        #sa_file = '/n/tcga_models/resnet18_WGD_10x_sa.pkl'\n",
    "        #state_dict_file = '/n/tcga_models/resnet18_WGD_10x.pt'\n",
    "        sa_file = '/home/sxchao/MSI_prediction/tcga_project/tcga_wgd_sa_all.pkl'\n",
    "        state_dict_file = '/n/tcga_models/resnet18_WGD_all_10x.pt'\n",
    "    elif magnification == '5.0':\n",
    "        #sa_file = '/n/tcga_models/resnet18_WGD_v04_sa.pkl'\n",
    "        state_dict_file = '/n/tcga_models/resnet18_WGD_v04.pt'\n",
    "elif classification == 'MSI':\n",
    "    if magnification == '10.0':\n",
    "        #sa_file = '/n/tcga_models/resnet18_MSI_singlelabel_10x_sa.pkl'\n",
    "        state_dict_file = '/n/tcga_models/resnet18_MSI_singlelabel_10x.pt'\n",
    "    elif magnification == '5.0':\n",
    "        #sa_file = '/n/tcga_models/resnet18_MSI_singlelabel_v02_sa.pkl'\n",
    "        state_dict_file = '/n/tcga_models/resnet18_MSI_singlelabel_v02.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load embedding network\n",
    "\n",
    "# alternative 1\n",
    "#resnet = models.resnet18(pretrained=True)\n",
    "\n",
    "# alternative 2\n",
    "resnet = models.resnet18(pretrained=False)\n",
    "resnet.fc = nn.Linear(2048, output_shape, bias=True)\n",
    "saved_state = torch.load(state_dict_file, map_location=lambda storage, loc: storage)\n",
    "resnet.load_state_dict(saved_state)\n",
    "\n",
    "# freeze layers\n",
    "resnet.fc = Identity()\n",
    "resnet.cuda(device=device)\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# initialize fully-connected final layer \n",
    "final_embed_layer = nn.Linear(2048, 2048)\n",
    "final_embed_layer.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConcatDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, *datasets):\n",
    "        self.datasets = datasets\n",
    "\n",
    "    def __len__(self):\n",
    "        return min(len(d) for d in self.datasets)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return torch.stack([d[i][0] for d in self.datasets]), torch.cat([torch.tensor(d[i][1]).view(-1) for d in self.datasets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "support_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(ConcatDataset(*train_sets), \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True, \n",
    "                                           num_workers=20, \n",
    "                                           pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(ConcatDataset(*val_sets), \n",
    "                                         batch_size=batch_size, \n",
    "                                         shuffle=True, \n",
    "                                         num_workers=20, \n",
    "                                         pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-5\n",
    "lsm = nn.LogSoftmax(dim=1)\n",
    "criterion = nn.BCELoss()\n",
    "#optimizer = torch.optim.Adam(resnet.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(final_embed_layer.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=100, verbose=True, min_lr=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fewshot_training_loop(train_loader, train_cancers, batch_size, resnet, final_embed_layer, criterion, optimizer):\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    for step, (tiles, labels) in enumerate(train_loader):  \n",
    "        labels = labels.cuda().float().transpose(0,1)    \n",
    "\n",
    "        # flatten batch_size x num_cancer_types \n",
    "        batch = tiles.cuda().transpose(0,1).reshape(batch_size * len(train_cancers), 3, 256, 256)    \n",
    "\n",
    "        # forward pass\n",
    "        output = resnet(batch)\n",
    "\n",
    "        # un-flatten num_cancer_types x batch_size\n",
    "        cancers_by_feats = torch.stack(torch.chunk(output, len(train_cancers)))    \n",
    "\n",
    "        # split feats, labels into support, query sets\n",
    "        feats_support = cancers_by_feats[:, :support_size, :]\n",
    "        feats_support = feats_support.reshape(support_size * len(train_cancers), 2048)\n",
    "        feats_support = final_embed_layer(feats_support)\n",
    "        feats_support = torch.stack(torch.chunk(feats_support, len(train_cancers)))    \n",
    "        feats_query = cancers_by_feats[:, support_size:, :]    \n",
    "        labels_support = labels[:,:support_size]\n",
    "        labels_query = labels[:,support_size:]\n",
    "\n",
    "        # get preds    \n",
    "        scores = lsm(torch.bmm(feats_support, feats_query.transpose(1,2))).exp()\n",
    "        preds = torch.bmm(labels_support.unsqueeze(1), scores).squeeze(1)\n",
    "        clamped_preds = torch.clamp(preds, 0, 1)\n",
    "\n",
    "        # calc loss, backprop, step    \n",
    "        loss = criterion(clamped_preds, labels_query)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        clamped_preds = (clamped_preds.contiguous().view(-1) > 0.5).float().detach().cpu().numpy()\n",
    "        labels_query = labels_query.contiguous().view(-1).float().detach().cpu().numpy()\n",
    "        all_preds.extend(clamped_preds)\n",
    "        all_labels.extend(labels_query)\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            acc, tile_acc_by_label = train_utils.calc_tile_acc_stats(labels_query, clamped_preds)\n",
    "            print('Epoch: {0}, Step: {1}, Train NLL: {2:0.4f}, Acc: {3:04f}, By Label: {4}'.format(e, step, loss.detach().cpu().numpy(), acc, tile_acc_by_label))\n",
    "        \n",
    "    acc, tile_acc_by_label = train_utils.calc_tile_acc_stats(all_labels, all_preds)\n",
    "    print('Epoch: {0}, Train NLL: {1:0.4f}, Acc: {2:0.4f}, By Label: {3}'.format(e, loss.detach().cpu().numpy(), acc, tile_acc_by_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fewshot_validation_loop(val_loader, val_cancers, batch_size, resnet, final_embed_layer, criterion):\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    for step, (tiles, labels) in enumerate(val_loader):  \n",
    "        labels = labels.cuda().float().transpose(0,1)    \n",
    "\n",
    "        # flatten batch_size x num_cancer_types \n",
    "        batch = tiles.cuda().transpose(0,1).reshape(batch_size * len(val_cancers), 3, 256, 256)    \n",
    "\n",
    "        # forward pass\n",
    "        output = resnet(batch)\n",
    "\n",
    "        # un-flatten num_cancer_types x batch_size\n",
    "        cancers_by_feats = torch.stack(torch.chunk(output, len(val_cancers)))    \n",
    "\n",
    "        # split feats, labels into support, query sets\n",
    "        feats_support = cancers_by_feats[:, :support_size, :]\n",
    "        feats_support = feats_support.reshape(support_size * len(val_cancers), 2048)\n",
    "        feats_support = final_embed_layer(feats_support)\n",
    "        feats_support = torch.stack(torch.chunk(feats_support, len(val_cancers)))    \n",
    "        feats_query = cancers_by_feats[:, support_size:, :]    \n",
    "        labels_support = labels[:,:support_size]\n",
    "        labels_query = labels[:,support_size:]\n",
    "\n",
    "        # get preds    \n",
    "        scores = lsm(torch.bmm(feats_support, feats_query.transpose(1,2))).exp()\n",
    "        preds = torch.bmm(labels_support.unsqueeze(1), scores).squeeze(1)\n",
    "        clamped_preds = torch.clamp(preds, 0, 1)\n",
    "\n",
    "        # calc loss\n",
    "        loss = criterion(clamped_preds, labels_query)\n",
    "        \n",
    "        clamped_preds = (clamped_preds.contiguous().view(-1) > 0.5).float().detach().cpu().numpy()\n",
    "        labels_query = labels_query.contiguous().view(-1).float().detach().cpu().numpy()\n",
    "        all_preds.extend(clamped_preds)\n",
    "        all_labels.extend(labels_query)\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            acc, tile_acc_by_label = train_utils.calc_tile_acc_stats(labels_query, clamped_preds)\n",
    "            print('Epoch: {0}, Step: {1}, Val NLL: {2:0.4f}, Acc: {3:04f}, By Label: {4}'.format(e, step, loss.detach().cpu().numpy(), acc, tile_acc_by_label))\n",
    "    \n",
    "    acc, tile_acc_by_label = train_utils.calc_tile_acc_stats(all_labels, all_preds)\n",
    "    print('Epoch: {0}, Val NLL: {1:0.4f}, Acc: {2:0.4f}, By Label: {3}'.format(e, loss.detach().cpu().numpy(), acc, tile_acc_by_label))\n",
    "    \n",
    "    if e > 1000:\n",
    "        scheduler.step(loss)\n",
    "     \n",
    "    return total_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for e in range(5000):\n",
    "    fewshot_training_loop(train_loader, train_cancers, batch_size, resnet, final_embed_layer, criterion, optimizer)\n",
    "    loss, acc = fewshot_validation_loop(val_loader, val_cancers, batch_size, resnet, final_embed_layer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

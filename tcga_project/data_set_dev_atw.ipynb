{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import accimage\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from imageio import imread\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, models, transforms, set_image_backend, get_image_backend\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "import train_utils\n",
    "import data_utils\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import torch\n",
    "import psutil\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, set_image_backend\n",
    "set_image_backend('accimage')\n",
    "import data_utils\n",
    "import train_utils\n",
    "root_dir_coad = '/n/mounted-data-drive/COAD/'\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_train, sa_val = data_utils.load_COAD_train_val_sa_pickle()\n",
    "root_dir = '/n/mounted-data-drive/COAD/'\n",
    "magnification = '10.0'\n",
    "batch_type = 'slide'\n",
    "\n",
    "train_transform = train_utils.transform_train\n",
    "val_transform = train_utils.transform_validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = data_utils.TCGADataset_tiled_slides(sa_train, root_dir, transform=train_transform, magnification=magnification)\n",
    "train_loader = DataLoader(train_set, batch_size=256, pin_memory=True, num_workers=32)\n",
    "\n",
    "\n",
    "val_set = data_utils.TCGADataset_tiled_slides(sa_val, root_dir, transform=val_transform, magnification=magnification)\n",
    "val_loader = DataLoader(val_set, batch_size=256, pin_memory=True, num_workers=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict_file = '/n/tcga_models/resnet18_WGD_10x.pt'\n",
    "device = torch.device('cuda', 0)\n",
    "output_shape = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = models.resnet18(pretrained=False)\n",
    "resnet.fc = nn.Linear(2048, output_shape, bias=True)\n",
    "saved_state = torch.load(state_dict_file, map_location=lambda storage, loc: storage)\n",
    "resnet.load_state_dict(saved_state)\n",
    "resnet.fc = nn.Linear(2048, 2048, bias=False)\n",
    "resnet.fc.weight.data = torch.eye(2048)\n",
    "resnet.cuda(device=device)\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=2048, out_features=1, bias=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pool_fn(x):\n",
    "    #v,a = torch.max(x,0)\n",
    "    v = torch.mean(x,0)\n",
    "    return v\n",
    "\n",
    "\n",
    "slide_level_classification_layer = nn.Linear(2048,1)\n",
    "slide_level_classification_layer.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = 0\n",
    "learning_rate = 1e-4\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(slide_level_classification_layer.parameters(), lr = learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, min_lr=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Step: 0, Slide Number: 20, Train Batch NLL: 0.6677\n",
      "Epoch: 0, Step: 1, Slide Number: 30, Train Batch NLL: 0.7208\n",
      "Epoch: 0, Step: 2, Slide Number: 35, Train Batch NLL: 0.6314\n",
      "Epoch: 0, Step: 3, Slide Number: 46, Train Batch NLL: 0.7131\n",
      "Epoch: 0, Step: 4, Slide Number: 53, Train Batch NLL: 0.6682\n",
      "Epoch: 0, Step: 5, Slide Number: 60, Train Batch NLL: 0.6581\n",
      "Epoch: 0, Step: 6, Slide Number: 69, Train Batch NLL: 0.6737\n",
      "Epoch: 0, Step: 7, Slide Number: 81, Train Batch NLL: 0.6465\n",
      "Epoch: 0, Step: 8, Slide Number: 100, Train Batch NLL: 0.6728\n",
      "Epoch: 0, Step: 9, Slide Number: 114, Train Batch NLL: 0.7716\n",
      "Epoch: 0, Step: 10, Slide Number: 133, Train Batch NLL: 0.7215\n",
      "Epoch: 0, Step: 11, Slide Number: 154, Train Batch NLL: 0.7501\n",
      "Epoch: 0, Step: 12, Slide Number: 164, Train Batch NLL: 0.6630\n",
      "Epoch: 0, Step: 13, Slide Number: 169, Train Batch NLL: 0.5819\n",
      "Epoch: 0, Step: 14, Slide Number: 176, Train Batch NLL: 0.6041\n",
      "Epoch: 0, Step: 15, Slide Number: 188, Train Batch NLL: 0.5952\n",
      "Epoch: 0, Step: 16, Slide Number: 192, Train Batch NLL: 0.7586\n",
      "Epoch: 0, Step: 17, Slide Number: 203, Train Batch NLL: 0.6387\n",
      "Epoch: 0, Step: 18, Slide Number: 212, Train Batch NLL: 0.5742\n",
      "Epoch: 0, Step: 19, Slide Number: 226, Train Batch NLL: 0.6417\n",
      "Epoch: 0, Step: 20, Slide Number: 237, Train Batch NLL: 0.6888\n",
      "Epoch: 0, Step: 21, Slide Number: 243, Train Batch NLL: 0.7069\n",
      "Epoch: 0, Step: 22, Slide Number: 251, Train Batch NLL: 0.8760\n",
      "Epoch: 0, Step: 23, Slide Number: 255, Train Batch NLL: 0.6812\n",
      "Epoch: 0, Step: 24, Slide Number: 261, Train Batch NLL: 0.6043\n",
      "Epoch: 0, Step: 25, Slide Number: 272, Train Batch NLL: 0.6940\n",
      "Epoch: 0, Step: 26, Slide Number: 293, Train Batch NLL: 0.5972\n",
      "Epoch: 0, Step: 27, Slide Number: 302, Train Batch NLL: 0.7359\n",
      "Epoch: 0, Step: 28, Slide Number: 307, Train Batch NLL: 0.7278\n",
      "Epoch: 0, Step: 29, Slide Number: 314, Train Batch NLL: 0.7354\n",
      "Epoch: 0, Step: 30, Slide Number: 323, Train Batch NLL: 0.5675\n"
     ]
    }
   ],
   "source": [
    "train_utils.tcga_tiled_slides_training_loop(e, train_loader, resnet, \n",
    "                                    slide_level_classification_layer, criterion, \n",
    "                                 optimizer, pool_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Step: 0, Slide Number: 81, Val Total NLL: 0.6701, Val Accuracy: 0.61\n"
     ]
    }
   ],
   "source": [
    "train_utils.tcga_tiled_slides_validation_loop(e, val_loader, resnet, \n",
    "                                    slide_level_classification_layer, criterion, \n",
    "                                 scheduler, pool_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

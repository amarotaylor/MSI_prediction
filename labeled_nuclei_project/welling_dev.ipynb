{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "import data_utils\n",
    "import train_utils\n",
    "import models\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = data_utils.COAD_dataset(data_utils.COAD_DEV)\n",
    "dev_loader = torch.utils.data.DataLoader(dev, batch_size=1, shuffle=True , pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (m): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (n): Dropout(p=0.5)\n",
       "  (relu): ReLU()\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(3, 36, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(36, 48, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=1200, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.5)\n",
       "  )\n",
       "  (classification_layer): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_conv_layers = 2\n",
    "n_fc_layers = 2\n",
    "kernel_size = [4,3]\n",
    "n_conv_filters = [36,48]\n",
    "hidden_size = [512,512]\n",
    "dropout=0.5\n",
    "net = models.ConvNet(n_conv_layers, n_fc_layers, kernel_size, n_conv_filters, hidden_size, dropout=dropout)\n",
    "net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100 \n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "weight_decay = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data_utils.COAD_dataset(data_utils.COAD_TRAIN)\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=1, shuffle=True , pin_memory=True)\n",
    "\n",
    "valid = data_utils.COAD_dataset(data_utils.COAD_VALID)\n",
    "valid_loader = torch.utils.data.DataLoader(valid, batch_size=1, shuffle=True , pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", patience=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train NLL: 34.7338\n",
      "Epoch: 0, Val NLL: 34.2249, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 1, Train NLL: 34.9582\n",
      "Epoch: 1, Val NLL: 34.6048, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 2, Train NLL: 34.5777\n",
      "Epoch: 2, Val NLL: 34.9021, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 3, Train NLL: 34.5222\n",
      "Epoch: 3, Val NLL: 34.5258, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 4, Train NLL: 34.3403\n",
      "Epoch: 4, Val NLL: 34.9956, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 5, Train NLL: 34.3574\n",
      "Epoch: 5, Val NLL: 35.1883, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 6, Train NLL: 34.3542\n",
      "Epoch: 6, Val NLL: 34.9374, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 7, Train NLL: 34.1592\n",
      "Epoch: 7, Val NLL: 35.0457, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 8, Train NLL: 34.6030\n",
      "Epoch: 8, Val NLL: 34.4113, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 9, Train NLL: 34.4462\n",
      "Epoch: 9, Val NLL: 34.1298, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 10, Train NLL: 34.1670\n",
      "Epoch: 10, Val NLL: 34.7604, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 11, Train NLL: 33.8684\n",
      "Epoch: 11, Val NLL: 33.9141, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 12, Train NLL: 33.6740\n",
      "Epoch: 12, Val NLL: 34.1209, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 13, Train NLL: 33.7831\n",
      "Epoch: 13, Val NLL: 33.7183, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 14, Train NLL: 33.2253\n",
      "Epoch: 14, Val NLL: 33.8661, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 15, Train NLL: 32.4537\n",
      "Epoch: 15, Val NLL: 33.9080, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 16, Train NLL: 32.9829\n",
      "Epoch: 16, Val NLL: 34.0699, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 17, Train NLL: 32.3956\n",
      "Epoch: 17, Val NLL: 36.7780, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 18, Train NLL: 32.1411\n",
      "Epoch: 18, Val NLL: 31.1532, Val Acc: 0.7755\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 19, Train NLL: 30.2238\n",
      "Epoch: 19, Val NLL: 29.7295, Val Acc: 0.7551\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 20, Train NLL: 30.4508\n",
      "Epoch: 20, Val NLL: 33.2387, Val Acc: 0.5714\n",
      "LR = 0.0001\n",
      "Epoch: 21, Train NLL: 28.9488\n",
      "Epoch: 21, Val NLL: 26.5894, Val Acc: 0.7347\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 22, Train NLL: 26.9679\n",
      "Epoch: 22, Val NLL: 30.8058, Val Acc: 0.6327\n",
      "LR = 0.0001\n",
      "Epoch: 23, Train NLL: 25.3279\n",
      "Epoch: 23, Val NLL: 29.4868, Val Acc: 0.6735\n",
      "LR = 0.0001\n",
      "Epoch: 24, Train NLL: 22.6711\n",
      "Epoch: 24, Val NLL: 21.7599, Val Acc: 0.7959\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 25, Train NLL: 23.2797\n",
      "Epoch: 25, Val NLL: 23.1702, Val Acc: 0.7959\n",
      "LR = 0.0001\n",
      "Epoch: 26, Train NLL: 20.5730\n",
      "Epoch: 26, Val NLL: 21.1427, Val Acc: 0.7755\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 27, Train NLL: 19.3634\n",
      "Epoch: 27, Val NLL: 19.5132, Val Acc: 0.8367\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 28, Train NLL: 21.6473\n",
      "Epoch: 28, Val NLL: 20.0617, Val Acc: 0.8163\n",
      "LR = 0.0001\n",
      "Epoch: 29, Train NLL: 17.8442\n",
      "Epoch: 29, Val NLL: 17.7323, Val Acc: 0.9184\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 30, Train NLL: 15.5606\n",
      "Epoch: 30, Val NLL: 17.8053, Val Acc: 0.8571\n",
      "LR = 0.0001\n",
      "Epoch: 31, Train NLL: 15.8260\n",
      "Epoch: 31, Val NLL: 17.4829, Val Acc: 0.7959\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 32, Train NLL: 13.0905\n",
      "Epoch: 32, Val NLL: 15.8301, Val Acc: 0.8980\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 33, Train NLL: 11.6050\n",
      "Epoch: 33, Val NLL: 16.6518, Val Acc: 0.8571\n",
      "LR = 0.0001\n",
      "Epoch: 34, Train NLL: 11.6888\n",
      "Epoch: 34, Val NLL: 15.9333, Val Acc: 0.8776\n",
      "LR = 0.0001\n",
      "Epoch: 35, Train NLL: 10.7235\n",
      "Epoch: 35, Val NLL: 14.8611, Val Acc: 0.8980\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 36, Train NLL: 8.6562\n",
      "Epoch: 36, Val NLL: 14.5988, Val Acc: 0.8776\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 37, Train NLL: 8.1187\n",
      "Epoch: 37, Val NLL: 18.0864, Val Acc: 0.8163\n",
      "LR = 0.0001\n",
      "Epoch: 38, Train NLL: 7.6147\n",
      "Epoch: 38, Val NLL: 13.4642, Val Acc: 0.8980\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 39, Train NLL: 5.6922\n",
      "Epoch: 39, Val NLL: 13.2163, Val Acc: 0.8776\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 40, Train NLL: 6.1343\n",
      "Epoch: 40, Val NLL: 13.1636, Val Acc: 0.8980\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 41, Train NLL: 7.6545\n",
      "Epoch: 41, Val NLL: 13.2763, Val Acc: 0.8776\n",
      "LR = 0.0001\n",
      "Epoch: 42, Train NLL: 4.4205\n",
      "Epoch: 42, Val NLL: 13.0194, Val Acc: 0.8776\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 43, Train NLL: 4.4980\n",
      "Epoch: 43, Val NLL: 12.8741, Val Acc: 0.8776\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 44, Train NLL: 2.7272\n",
      "Epoch: 44, Val NLL: 12.8737, Val Acc: 0.8776\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 45, Train NLL: 2.3902\n",
      "Epoch: 45, Val NLL: 12.0672, Val Acc: 0.8776\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 46, Train NLL: 2.9078\n",
      "Epoch: 46, Val NLL: 12.2382, Val Acc: 0.8776\n",
      "LR = 0.0001\n",
      "Epoch: 47, Train NLL: 1.8313\n",
      "Epoch: 47, Val NLL: 12.1219, Val Acc: 0.8776\n",
      "LR = 0.0001\n",
      "Epoch: 48, Train NLL: 1.5492\n",
      "Epoch: 48, Val NLL: 12.2412, Val Acc: 0.8776\n",
      "LR = 0.0001\n",
      "Epoch: 49, Train NLL: 1.4780\n",
      "Epoch: 49, Val NLL: 12.3220, Val Acc: 0.8776\n",
      "LR = 0.0001\n",
      "Epoch: 50, Train NLL: 1.3312\n",
      "Epoch: 50, Val NLL: 12.4881, Val Acc: 0.8571\n",
      "LR = 0.0001\n",
      "Epoch: 51, Train NLL: 1.2280\n",
      "Epoch: 51, Val NLL: 12.3085, Val Acc: 0.8571\n",
      "LR = 0.0001\n",
      "Epoch: 52, Train NLL: 0.9990\n",
      "Epoch: 52, Val NLL: 13.5200, Val Acc: 0.8571\n",
      "LR = 0.0001\n",
      "Epoch: 53, Train NLL: 1.0172\n",
      "Epoch: 53, Val NLL: 12.8537, Val Acc: 0.8571\n",
      "LR = 0.0001\n",
      "Epoch: 54, Train NLL: 1.0029\n",
      "Epoch: 54, Val NLL: 12.8743, Val Acc: 0.8776\n",
      "LR = 0.0001\n",
      "Epoch: 55, Train NLL: 0.7665\n",
      "Epoch: 55, Val NLL: 12.6307, Val Acc: 0.8776\n",
      "LR = 0.0001\n",
      "Epoch: 56, Train NLL: 0.7024\n",
      "Epoch: 56, Val NLL: 12.9461, Val Acc: 0.8776\n",
      "LR = 0.0001\n",
      "Epoch: 57, Train NLL: 0.6545\n",
      "Epoch: 57, Val NLL: 12.5621, Val Acc: 0.8776\n",
      "LR = 0.0001\n",
      "Epoch: 58, Train NLL: 0.5602\n",
      "Epoch: 58, Val NLL: 12.5782, Val Acc: 0.8571\n",
      "LR = 0.0001\n",
      "Epoch: 59, Train NLL: 0.4287\n",
      "Epoch: 59, Val NLL: 13.1313, Val Acc: 0.8776\n",
      "LR = 0.0001\n",
      "Epoch: 60, Train NLL: 0.5299\n",
      "Epoch: 60, Val NLL: 13.2418, Val Acc: 0.8776\n",
      "LR = 0.0001\n",
      "Epoch: 61, Train NLL: 0.5160\n",
      "Epoch: 61, Val NLL: 12.8822, Val Acc: 0.8776\n",
      "LR = 0.0001\n",
      "Epoch: 62, Train NLL: 0.4709\n",
      "Epoch: 62, Val NLL: 15.1014, Val Acc: 0.8571\n",
      "LR = 0.0001\n",
      "Epoch: 63, Train NLL: 0.3921\n",
      "Epoch: 63, Val NLL: 13.3182, Val Acc: 0.8571\n",
      "LR = 0.0001\n",
      "Epoch: 64, Train NLL: 0.3309\n",
      "Epoch: 64, Val NLL: 13.2038, Val Acc: 0.8776\n",
      "LR = 0.0001\n",
      "Epoch: 65, Train NLL: 0.2700\n",
      "Epoch: 65, Val NLL: 13.3967, Val Acc: 0.8571\n",
      "LR = 0.0001\n",
      "Epoch: 66, Train NLL: 0.2505\n",
      "Epoch: 66, Val NLL: 13.6134, Val Acc: 0.8776\n",
      "LR = 0.0001\n",
      "Epoch: 67, Train NLL: 0.2459\n",
      "Epoch: 67, Val NLL: 13.6427, Val Acc: 0.8776\n",
      "LR = 0.0001\n",
      "Epoch: 68, Train NLL: 0.2174\n",
      "Epoch: 68, Val NLL: 14.2630, Val Acc: 0.8776\n",
      "LR = 0.0001\n",
      "Epoch: 69, Train NLL: 0.2229\n",
      "Epoch: 69, Val NLL: 13.7869, Val Acc: 0.8776\n",
      "LR = 0.0001\n",
      "Epoch: 70, Train NLL: 0.1886\n",
      "Epoch: 70, Val NLL: 13.8321, Val Acc: 0.8776\n",
      "LR = 0.0001\n",
      "Epoch: 71, Train NLL: 0.1981\n",
      "Epoch: 71, Val NLL: 14.2328, Val Acc: 0.8776\n",
      "LR = 0.0001\n",
      "Epoch: 72, Train NLL: 0.1701\n",
      "Epoch: 72, Val NLL: 13.7331, Val Acc: 0.8776\n",
      "LR = 0.0001\n",
      "Epoch: 73, Train NLL: 0.1572\n",
      "Epoch: 73, Val NLL: 13.9882, Val Acc: 0.8571\n",
      "LR = 0.0001\n",
      "Epoch: 74, Train NLL: 0.1563\n",
      "Epoch: 74, Val NLL: 13.9830, Val Acc: 0.8571\n",
      "LR = 0.0001\n",
      "Epoch: 75, Train NLL: 0.1422\n",
      "Epoch: 75, Val NLL: 15.0592, Val Acc: 0.8776\n",
      "LR = 0.0001\n",
      "Epoch: 76, Train NLL: 0.1362\n",
      "Epoch: 76, Val NLL: 14.1140, Val Acc: 0.8571\n",
      "LR = 0.0001\n",
      "Epoch: 77, Train NLL: 0.1182\n",
      "Epoch: 77, Val NLL: 14.0962, Val Acc: 0.8571\n",
      "LR = 0.0001\n",
      "Epoch: 78, Train NLL: 0.1146\n",
      "Epoch: 78, Val NLL: 14.2588, Val Acc: 0.8571\n",
      "LR = 0.0001\n",
      "Epoch: 79, Train NLL: 0.1074\n",
      "Epoch: 79, Val NLL: 14.2819, Val Acc: 0.8571\n",
      "LR = 0.0001\n",
      "Epoch: 80, Train NLL: 0.1020\n",
      "Epoch: 80, Val NLL: 14.4755, Val Acc: 0.8776\n",
      "LR = 0.0001\n",
      "Epoch: 81, Train NLL: 0.0962\n",
      "Epoch: 81, Val NLL: 14.3235, Val Acc: 0.8571\n",
      "LR = 0.0001\n",
      "Epoch: 82, Train NLL: 0.0896\n",
      "Epoch: 82, Val NLL: 14.5800, Val Acc: 0.8776\n",
      "LR = 0.0001\n",
      "Epoch: 83, Train NLL: 0.0871\n",
      "Epoch: 83, Val NLL: 14.5086, Val Acc: 0.8571\n",
      "LR = 0.0001\n",
      "Epoch: 84, Train NLL: 0.0869\n",
      "Epoch: 84, Val NLL: 14.4846, Val Acc: 0.8776\n",
      "LR = 0.0001\n",
      "Epoch: 85, Train NLL: 0.0746\n",
      "Epoch: 85, Val NLL: 14.5759, Val Acc: 0.8571\n",
      "LR = 0.0001\n",
      "Epoch: 86, Train NLL: 0.0836\n",
      "Epoch: 86, Val NLL: 14.6645, Val Acc: 0.8571\n",
      "LR = 0.0001\n",
      "Epoch: 87, Train NLL: 0.0660\n",
      "Epoch: 87, Val NLL: 14.7451, Val Acc: 0.8571\n",
      "LR = 0.0001\n",
      "Epoch: 88, Train NLL: 0.0616\n",
      "Epoch: 88, Val NLL: 14.8253, Val Acc: 0.8571\n",
      "LR = 0.0001\n",
      "Epoch: 89, Train NLL: 0.0584\n",
      "Epoch: 89, Val NLL: 15.2517, Val Acc: 0.8776\n",
      "LR = 0.0001\n",
      "Epoch: 90, Train NLL: 0.0606\n",
      "Epoch: 90, Val NLL: 15.0249, Val Acc: 0.8571\n",
      "LR = 0.0001\n",
      "Epoch: 91, Train NLL: 0.0559\n",
      "Epoch: 91, Val NLL: 15.0726, Val Acc: 0.8571\n",
      "LR = 0.0001\n",
      "Epoch: 92, Train NLL: 0.0546\n",
      "Epoch: 92, Val NLL: 15.1496, Val Acc: 0.8571\n",
      "LR = 0.0001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 93, Train NLL: 0.0510\n",
      "Epoch: 93, Val NLL: 15.1567, Val Acc: 0.8571\n",
      "LR = 0.0001\n",
      "Epoch: 94, Train NLL: 0.0536\n",
      "Epoch: 94, Val NLL: 15.3927, Val Acc: 0.8571\n",
      "LR = 0.0001\n",
      "Epoch: 95, Train NLL: 0.0487\n",
      "Epoch: 95, Val NLL: 15.2665, Val Acc: 0.8571\n",
      "LR = 0.0001\n",
      "Epoch: 96, Train NLL: 0.0415\n",
      "Epoch: 96, Val NLL: 15.4121, Val Acc: 0.8571\n",
      "LR = 0.0001\n",
      "Epoch: 97, Train NLL: 0.0411\n",
      "Epoch: 97, Val NLL: 15.6417, Val Acc: 0.8571\n",
      "LR = 0.0001\n",
      "Epoch: 98, Train NLL: 0.0410\n",
      "Epoch: 98, Val NLL: 15.5140, Val Acc: 0.8571\n",
      "LR = 0.0001\n",
      "Epoch: 99, Train NLL: 0.0371\n",
      "Epoch: 99, Val NLL: 15.9755, Val Acc: 0.8776\n",
      "LR = 0.0001\n"
     ]
    }
   ],
   "source": [
    "def pool_fn(x):\n",
    "    #v,a = torch.max(x,0)\n",
    "    v = torch.mean(x,0)\n",
    "    return v\n",
    "\n",
    "best_loss = 1e8\n",
    "for e in range(epochs):\n",
    "    train_utils.embedding_training_loop(e, train_loader, net, criterion, optimizer,pool_fn)\n",
    "    loss = train_utils.embedding_validation_loop(e, valid_loader, net, criterion,pool_fn)\n",
    "    #scheduler.step(loss)\n",
    "    print('LR = {}'.format(optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "    if loss < best_loss:\n",
    "        torch.save(net.state_dict(),'best_convnet.pt')\n",
    "        best_loss = loss\n",
    "        print('WROTE MODEL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train NLL: 34.7253\n",
      "Epoch: 0, Val NLL: 34.5098, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 1, Train NLL: 34.4373\n",
      "Epoch: 1, Val NLL: 34.9781, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 2, Train NLL: 34.5094\n",
      "Epoch: 2, Val NLL: 34.7606, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 3, Train NLL: 34.5293\n",
      "Epoch: 3, Val NLL: 34.8371, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 4, Train NLL: 34.3855\n",
      "Epoch: 4, Val NLL: 34.7604, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 5, Train NLL: 34.3665\n",
      "Epoch: 5, Val NLL: 34.9662, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 6, Train NLL: 34.3384\n",
      "Epoch: 6, Val NLL: 34.5777, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 7, Train NLL: 34.4144\n",
      "Epoch: 7, Val NLL: 34.7917, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 8, Train NLL: 34.3746\n",
      "Epoch: 8, Val NLL: 34.8322, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 9, Train NLL: 34.3017\n",
      "Epoch: 9, Val NLL: 34.5868, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 10, Train NLL: 34.4337\n",
      "Epoch: 10, Val NLL: 34.3766, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 11, Train NLL: 34.4705\n",
      "Epoch: 11, Val NLL: 34.4495, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 12, Train NLL: 34.0451\n",
      "Epoch: 12, Val NLL: 34.5047, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 13, Train NLL: 33.9178\n",
      "Epoch: 13, Val NLL: 34.0394, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 14, Train NLL: 33.7593\n",
      "Epoch: 14, Val NLL: 34.4816, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 15, Train NLL: 33.8633\n",
      "Epoch: 15, Val NLL: 36.4187, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 16, Train NLL: 34.0904\n",
      "Epoch: 16, Val NLL: 32.8451, Val Acc: 0.4490\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 17, Train NLL: 32.6022\n",
      "Epoch: 17, Val NLL: 29.9192, Val Acc: 0.8776\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 18, Train NLL: 32.0232\n",
      "Epoch: 18, Val NLL: 28.6001, Val Acc: 0.8163\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 19, Train NLL: 31.2138\n",
      "Epoch: 19, Val NLL: 24.8225, Val Acc: 0.8980\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 20, Train NLL: 29.9320\n",
      "Epoch: 20, Val NLL: 34.9931, Val Acc: 0.4286\n",
      "LR = 0.0001\n",
      "Epoch: 21, Train NLL: 31.6767\n",
      "Epoch: 21, Val NLL: 25.7642, Val Acc: 0.7959\n",
      "LR = 0.0001\n",
      "Epoch: 22, Train NLL: 31.3949\n",
      "Epoch: 22, Val NLL: 23.8456, Val Acc: 0.8980\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 23, Train NLL: 28.4062\n",
      "Epoch: 23, Val NLL: 20.9956, Val Acc: 0.8163\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 24, Train NLL: 27.1337\n",
      "Epoch: 24, Val NLL: 20.8147, Val Acc: 0.8367\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 25, Train NLL: 27.1167\n",
      "Epoch: 25, Val NLL: 17.7537, Val Acc: 0.8980\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 26, Train NLL: 25.8483\n",
      "Epoch: 26, Val NLL: 15.7321, Val Acc: 0.8980\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 27, Train NLL: 24.2173\n",
      "Epoch: 27, Val NLL: 22.3506, Val Acc: 0.7755\n",
      "LR = 0.0001\n",
      "Epoch: 28, Train NLL: 27.2102\n",
      "Epoch: 28, Val NLL: 18.9860, Val Acc: 0.8571\n",
      "LR = 0.0001\n",
      "Epoch: 29, Train NLL: 23.5473\n",
      "Epoch: 29, Val NLL: 15.4028, Val Acc: 0.8980\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 30, Train NLL: 24.5664\n",
      "Epoch: 30, Val NLL: 18.8632, Val Acc: 0.8367\n",
      "LR = 0.0001\n",
      "Epoch: 31, Train NLL: 23.7868\n",
      "Epoch: 31, Val NLL: 13.6525, Val Acc: 0.9388\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 32, Train NLL: 21.2174\n",
      "Epoch: 32, Val NLL: 20.5518, Val Acc: 0.8163\n",
      "LR = 0.0001\n",
      "Epoch: 33, Train NLL: 26.3073\n",
      "Epoch: 33, Val NLL: 20.2479, Val Acc: 0.8163\n",
      "LR = 0.0001\n",
      "Epoch: 34, Train NLL: 22.3116\n",
      "Epoch: 34, Val NLL: 12.5545, Val Acc: 0.9592\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 35, Train NLL: 22.1433\n",
      "Epoch: 35, Val NLL: 14.8245, Val Acc: 0.8571\n",
      "LR = 0.0001\n",
      "Epoch: 36, Train NLL: 23.5026\n",
      "Epoch: 36, Val NLL: 16.2575, Val Acc: 0.8571\n",
      "LR = 0.0001\n",
      "Epoch: 37, Train NLL: 20.8977\n",
      "Epoch: 37, Val NLL: 11.9129, Val Acc: 0.9184\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 38, Train NLL: 22.1627\n",
      "Epoch: 38, Val NLL: 11.1595, Val Acc: 0.9592\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 39, Train NLL: 23.2741\n",
      "Epoch: 39, Val NLL: 12.3403, Val Acc: 0.9388\n",
      "LR = 0.0001\n",
      "Epoch: 40, Train NLL: 21.6740\n",
      "Epoch: 40, Val NLL: 11.1105, Val Acc: 0.9388\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 41, Train NLL: 19.4043\n",
      "Epoch: 41, Val NLL: 11.4487, Val Acc: 0.8980\n",
      "LR = 0.0001\n",
      "Epoch: 42, Train NLL: 20.0995\n",
      "Epoch: 42, Val NLL: 10.4048, Val Acc: 1.0000\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 43, Train NLL: 22.9499\n",
      "Epoch: 43, Val NLL: 11.5410, Val Acc: 0.9184\n",
      "LR = 0.0001\n",
      "Epoch: 44, Train NLL: 21.8058\n",
      "Epoch: 44, Val NLL: 10.2644, Val Acc: 0.9388\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 45, Train NLL: 19.9823\n",
      "Epoch: 45, Val NLL: 9.8031, Val Acc: 0.9592\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 46, Train NLL: 19.1451\n",
      "Epoch: 46, Val NLL: 9.3002, Val Acc: 0.9592\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 47, Train NLL: 17.7383\n",
      "Epoch: 47, Val NLL: 8.5334, Val Acc: 1.0000\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 48, Train NLL: 19.0708\n",
      "Epoch: 48, Val NLL: 8.5324, Val Acc: 1.0000\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 49, Train NLL: 18.7861\n",
      "Epoch: 49, Val NLL: 8.1396, Val Acc: 1.0000\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 50, Train NLL: 18.0692\n",
      "Epoch: 50, Val NLL: 13.0160, Val Acc: 0.8776\n",
      "LR = 0.0001\n",
      "Epoch: 51, Train NLL: 20.8068\n",
      "Epoch: 51, Val NLL: 14.4062, Val Acc: 0.8571\n",
      "LR = 0.0001\n",
      "Epoch: 52, Train NLL: 18.5557\n",
      "Epoch: 52, Val NLL: 9.0383, Val Acc: 1.0000\n",
      "LR = 0.0001\n",
      "Epoch: 53, Train NLL: 17.7963\n",
      "Epoch: 53, Val NLL: 8.1356, Val Acc: 1.0000\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 54, Train NLL: 16.9593\n",
      "Epoch: 54, Val NLL: 7.4746, Val Acc: 0.9796\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 55, Train NLL: 17.3809\n",
      "Epoch: 55, Val NLL: 11.7534, Val Acc: 0.8571\n",
      "LR = 0.0001\n",
      "Epoch: 56, Train NLL: 20.2139\n",
      "Epoch: 56, Val NLL: 17.6417, Val Acc: 0.8163\n",
      "LR = 0.0001\n",
      "Epoch: 57, Train NLL: 17.0174\n",
      "Epoch: 57, Val NLL: 7.3587, Val Acc: 0.9796\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 58, Train NLL: 16.9908\n",
      "Epoch: 58, Val NLL: 7.4178, Val Acc: 0.9796\n",
      "LR = 0.0001\n",
      "Epoch: 59, Train NLL: 15.2627\n",
      "Epoch: 59, Val NLL: 9.9744, Val Acc: 0.8980\n",
      "LR = 0.0001\n",
      "Epoch: 60, Train NLL: 16.8262\n",
      "Epoch: 60, Val NLL: 6.8965, Val Acc: 1.0000\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 61, Train NLL: 16.4553\n",
      "Epoch: 61, Val NLL: 7.8571, Val Acc: 0.9592\n",
      "LR = 0.0001\n",
      "Epoch: 62, Train NLL: 15.0112\n",
      "Epoch: 62, Val NLL: 19.1560, Val Acc: 0.8163\n",
      "LR = 0.0001\n",
      "Epoch: 63, Train NLL: 21.1151\n",
      "Epoch: 63, Val NLL: 6.8201, Val Acc: 0.9796\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 64, Train NLL: 14.8830\n",
      "Epoch: 64, Val NLL: 7.1125, Val Acc: 0.9796\n",
      "LR = 0.0001\n",
      "Epoch: 65, Train NLL: 15.1530\n",
      "Epoch: 65, Val NLL: 6.5792, Val Acc: 0.9796\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 66, Train NLL: 15.4003\n",
      "Epoch: 66, Val NLL: 5.7973, Val Acc: 1.0000\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 67, Train NLL: 15.0879\n",
      "Epoch: 67, Val NLL: 6.5145, Val Acc: 0.9796\n",
      "LR = 0.0001\n",
      "Epoch: 68, Train NLL: 14.1416\n",
      "Epoch: 68, Val NLL: 5.5579, Val Acc: 1.0000\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 69, Train NLL: 14.7496\n",
      "Epoch: 69, Val NLL: 5.2059, Val Acc: 1.0000\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 70, Train NLL: 13.0920\n",
      "Epoch: 70, Val NLL: 5.7056, Val Acc: 1.0000\n",
      "LR = 0.0001\n",
      "Epoch: 71, Train NLL: 17.9224\n",
      "Epoch: 71, Val NLL: 6.5694, Val Acc: 1.0000\n",
      "LR = 0.0001\n",
      "Epoch: 72, Train NLL: 14.8451\n",
      "Epoch: 72, Val NLL: 9.1955, Val Acc: 0.9184\n",
      "LR = 0.0001\n",
      "Epoch: 73, Train NLL: 13.9140\n",
      "Epoch: 73, Val NLL: 7.9444, Val Acc: 0.9388\n",
      "LR = 0.0001\n",
      "Epoch: 74, Train NLL: 13.9549\n",
      "Epoch: 74, Val NLL: 4.9503, Val Acc: 0.9796\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 75, Train NLL: 12.7832\n",
      "Epoch: 75, Val NLL: 5.5331, Val Acc: 1.0000\n",
      "LR = 0.0001\n",
      "Epoch: 76, Train NLL: 12.7797\n",
      "Epoch: 76, Val NLL: 5.5800, Val Acc: 1.0000\n",
      "LR = 0.0001\n",
      "Epoch: 77, Train NLL: 13.8887\n",
      "Epoch: 77, Val NLL: 5.0828, Val Acc: 1.0000\n",
      "LR = 0.0001\n",
      "Epoch: 78, Train NLL: 13.2654\n",
      "Epoch: 78, Val NLL: 5.7561, Val Acc: 0.9796\n",
      "LR = 0.0001\n",
      "Epoch: 79, Train NLL: 12.1804\n",
      "Epoch: 79, Val NLL: 4.6571, Val Acc: 1.0000\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 80, Train NLL: 13.8842\n",
      "Epoch: 80, Val NLL: 5.3706, Val Acc: 1.0000\n",
      "LR = 0.0001\n",
      "Epoch: 81, Train NLL: 14.5392\n",
      "Epoch: 81, Val NLL: 4.6829, Val Acc: 1.0000\n",
      "LR = 0.0001\n",
      "Epoch: 82, Train NLL: 11.7994\n",
      "Epoch: 82, Val NLL: 4.6860, Val Acc: 1.0000\n",
      "LR = 0.0001\n",
      "Epoch: 83, Train NLL: 11.5760\n",
      "Epoch: 83, Val NLL: 4.7264, Val Acc: 0.9796\n",
      "LR = 0.0001\n",
      "Epoch: 84, Train NLL: 11.6733\n",
      "Epoch: 84, Val NLL: 4.3343, Val Acc: 0.9796\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 85, Train NLL: 11.2306\n",
      "Epoch: 85, Val NLL: 5.8949, Val Acc: 0.9796\n",
      "LR = 0.0001\n",
      "Epoch: 86, Train NLL: 12.3466\n",
      "Epoch: 86, Val NLL: 4.1003, Val Acc: 1.0000\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 87, Train NLL: 11.3440\n",
      "Epoch: 87, Val NLL: 4.0855, Val Acc: 1.0000\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 88, Train NLL: 10.1668\n",
      "Epoch: 88, Val NLL: 4.4825, Val Acc: 1.0000\n",
      "LR = 0.0001\n",
      "Epoch: 89, Train NLL: 13.1780\n",
      "Epoch: 89, Val NLL: 4.8381, Val Acc: 1.0000\n",
      "LR = 0.0001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90, Train NLL: 9.8912\n",
      "Epoch: 90, Val NLL: 5.6295, Val Acc: 0.9592\n",
      "LR = 0.0001\n",
      "Epoch: 91, Train NLL: 10.3956\n",
      "Epoch: 91, Val NLL: 5.7194, Val Acc: 0.9592\n",
      "LR = 0.0001\n",
      "Epoch: 92, Train NLL: 10.2883\n",
      "Epoch: 92, Val NLL: 4.0148, Val Acc: 1.0000\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 93, Train NLL: 11.6157\n",
      "Epoch: 93, Val NLL: 4.6198, Val Acc: 1.0000\n",
      "LR = 0.0001\n",
      "Epoch: 94, Train NLL: 9.5605\n",
      "Epoch: 94, Val NLL: 5.2011, Val Acc: 0.9592\n",
      "LR = 0.0001\n",
      "Epoch: 95, Train NLL: 10.8057\n",
      "Epoch: 95, Val NLL: 3.4065, Val Acc: 1.0000\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 96, Train NLL: 10.0294\n",
      "Epoch: 96, Val NLL: 6.4258, Val Acc: 0.9388\n",
      "LR = 0.0001\n",
      "Epoch: 97, Train NLL: 10.6172\n",
      "Epoch: 97, Val NLL: 4.5113, Val Acc: 0.9592\n",
      "LR = 0.0001\n",
      "Epoch: 98, Train NLL: 10.2490\n",
      "Epoch: 98, Val NLL: 3.9005, Val Acc: 1.0000\n",
      "LR = 0.0001\n",
      "Epoch: 99, Train NLL: 9.6537\n",
      "Epoch: 99, Val NLL: 3.8658, Val Acc: 1.0000\n",
      "LR = 0.0001\n"
     ]
    }
   ],
   "source": [
    "def pool_fn(x):\n",
    "    #v,a = torch.max(x,0)\n",
    "    v = torch.mean(x,0)\n",
    "    return v\n",
    "\n",
    "best_loss = 1e8\n",
    "for e in range(epochs):\n",
    "    train_utils.instance_training_loop(e, train_loader, net, criterion, optimizer,pool_fn)\n",
    "    loss = train_utils.instance_validation_loop(e, valid_loader, net, criterion,pool_fn)\n",
    "    #scheduler.step(loss)\n",
    "    print('LR = {}'.format(optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "    if loss < best_loss:\n",
    "        torch.save(net.state_dict(),'best_convnet.pt')\n",
    "        best_loss = loss\n",
    "        print('WROTE MODEL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attention(\n",
       "  (V): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (U): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (w): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (sigm): Sigmoid()\n",
       "  (tanh): Tanh()\n",
       "  (sm): Softmax()\n",
       ")"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = 512\n",
    "hidden_size = 512\n",
    "output_size = 1\n",
    "attn = models.Attention(input_size, hidden_size, output_size)\n",
    "attn.cuda()\n",
    "#for slide,label in dev_loader:\n",
    "#    break\n",
    "\n",
    "#h = net(slide.squeeze_().cuda())\n",
    "#a = attn(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([196, 512])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([196, 1])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.transpose(a, dim0=0, dim1=1).matmul(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.4068,  4.2534]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = net.classification_layer(z)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "parameters = [p for p in net.parameters()]\n",
    "print(len(parameters))\n",
    "parameters.extend([p for p in attn.parameters()])\n",
    "print(len(parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(parameters, lr=lr, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_fn = models.pool(attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train NLL: 34.5292\n",
      "Epoch: 0, Val NLL: 34.7943, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 1, Train NLL: 34.4987\n",
      "Epoch: 1, Val NLL: 35.6473, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 2, Train NLL: 34.5297\n",
      "Epoch: 2, Val NLL: 35.1216, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 3, Train NLL: 34.4356\n",
      "Epoch: 3, Val NLL: 35.0022, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 4, Train NLL: 34.3379\n",
      "Epoch: 4, Val NLL: 35.0881, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 5, Train NLL: 34.5551\n",
      "Epoch: 5, Val NLL: 35.4290, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 6, Train NLL: 34.4301\n",
      "Epoch: 6, Val NLL: 34.9031, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 7, Train NLL: 34.3130\n",
      "Epoch: 7, Val NLL: 35.0679, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 8, Train NLL: 34.4213\n",
      "Epoch: 8, Val NLL: 35.0104, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 9, Train NLL: 34.2849\n",
      "Epoch: 9, Val NLL: 35.0321, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 10, Train NLL: 34.4514\n",
      "Epoch: 10, Val NLL: 34.9220, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 11, Train NLL: 34.3581\n",
      "Epoch: 11, Val NLL: 34.9893, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 12, Train NLL: 34.3138\n",
      "Epoch: 12, Val NLL: 34.9621, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 13, Train NLL: 34.7848\n",
      "Epoch: 13, Val NLL: 35.0149, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 14, Train NLL: 34.3580\n",
      "Epoch: 14, Val NLL: 34.7267, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 15, Train NLL: 34.4368\n",
      "Epoch: 15, Val NLL: 34.6579, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 16, Train NLL: 34.2188\n",
      "Epoch: 16, Val NLL: 34.7320, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 17, Train NLL: 34.1760\n",
      "Epoch: 17, Val NLL: 34.7126, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 18, Train NLL: 34.2105\n",
      "Epoch: 18, Val NLL: 35.0385, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 19, Train NLL: 34.4956\n",
      "Epoch: 19, Val NLL: 34.2167, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 20, Train NLL: 34.5144\n",
      "Epoch: 20, Val NLL: 34.6018, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 21, Train NLL: 34.2013\n",
      "Epoch: 21, Val NLL: 34.7407, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 22, Train NLL: 34.1229\n",
      "Epoch: 22, Val NLL: 34.6493, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 23, Train NLL: 34.1060\n",
      "Epoch: 23, Val NLL: 34.7176, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 24, Train NLL: 34.0292\n",
      "Epoch: 24, Val NLL: 34.0882, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 25, Train NLL: 33.9116\n",
      "Epoch: 25, Val NLL: 34.3432, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 26, Train NLL: 33.7396\n",
      "Epoch: 26, Val NLL: 33.7096, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 27, Train NLL: 34.3694\n",
      "Epoch: 27, Val NLL: 33.5632, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 28, Train NLL: 33.5700\n",
      "Epoch: 28, Val NLL: 33.8454, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "Epoch: 29, Train NLL: 33.3322\n",
      "Epoch: 29, Val NLL: 32.6698, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 30, Train NLL: 33.0446\n",
      "Epoch: 30, Val NLL: 32.5697, Val Acc: 0.4082\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 31, Train NLL: 32.2332\n",
      "Epoch: 31, Val NLL: 31.2597, Val Acc: 0.5102\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 32, Train NLL: 31.6907\n",
      "Epoch: 32, Val NLL: 29.0589, Val Acc: 0.7755\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 33, Train NLL: 30.2414\n",
      "Epoch: 33, Val NLL: 27.4369, Val Acc: 0.8163\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 34, Train NLL: 29.4282\n",
      "Epoch: 34, Val NLL: 23.0391, Val Acc: 0.8776\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 35, Train NLL: 26.1789\n",
      "Epoch: 35, Val NLL: 21.3682, Val Acc: 0.8776\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 36, Train NLL: 24.3696\n",
      "Epoch: 36, Val NLL: 19.9663, Val Acc: 0.8367\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 37, Train NLL: 25.3102\n",
      "Epoch: 37, Val NLL: 24.9435, Val Acc: 0.7143\n",
      "LR = 0.0001\n",
      "Epoch: 38, Train NLL: 23.2353\n",
      "Epoch: 38, Val NLL: 19.9166, Val Acc: 0.9184\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 39, Train NLL: 24.1715\n",
      "Epoch: 39, Val NLL: 21.1235, Val Acc: 0.8163\n",
      "LR = 0.0001\n",
      "Epoch: 40, Train NLL: 25.8872\n",
      "Epoch: 40, Val NLL: 19.4372, Val Acc: 0.8571\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 41, Train NLL: 25.3304\n",
      "Epoch: 41, Val NLL: 19.2600, Val Acc: 0.8776\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 42, Train NLL: 23.6721\n",
      "Epoch: 42, Val NLL: 18.7680, Val Acc: 0.8980\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 43, Train NLL: 22.5257\n",
      "Epoch: 43, Val NLL: 19.6854, Val Acc: 0.9184\n",
      "LR = 0.0001\n",
      "Epoch: 44, Train NLL: 22.0811\n",
      "Epoch: 44, Val NLL: 17.7883, Val Acc: 0.9184\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 45, Train NLL: 22.7491\n",
      "Epoch: 45, Val NLL: 17.0751, Val Acc: 0.9184\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 46, Train NLL: 23.2993\n",
      "Epoch: 46, Val NLL: 17.9538, Val Acc: 0.8367\n",
      "LR = 0.0001\n",
      "Epoch: 47, Train NLL: 21.0985\n",
      "Epoch: 47, Val NLL: 18.2785, Val Acc: 0.8163\n",
      "LR = 0.0001\n",
      "Epoch: 48, Train NLL: 26.6368\n",
      "Epoch: 48, Val NLL: 16.8505, Val Acc: 0.9184\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 49, Train NLL: 21.9295\n",
      "Epoch: 49, Val NLL: 16.6341, Val Acc: 0.9184\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 50, Train NLL: 21.9474\n",
      "Epoch: 50, Val NLL: 16.7068, Val Acc: 0.9184\n",
      "LR = 0.0001\n",
      "Epoch: 51, Train NLL: 19.5867\n",
      "Epoch: 51, Val NLL: 16.0262, Val Acc: 0.8571\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 52, Train NLL: 19.3772\n",
      "Epoch: 52, Val NLL: 16.7074, Val Acc: 0.8367\n",
      "LR = 0.0001\n",
      "Epoch: 53, Train NLL: 17.2650\n",
      "Epoch: 53, Val NLL: 24.3742, Val Acc: 0.7347\n",
      "LR = 0.0001\n",
      "Epoch: 54, Train NLL: 21.7784\n",
      "Epoch: 54, Val NLL: 15.1185, Val Acc: 0.9184\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 55, Train NLL: 21.2970\n",
      "Epoch: 55, Val NLL: 17.2777, Val Acc: 0.9184\n",
      "LR = 0.0001\n",
      "Epoch: 56, Train NLL: 21.7455\n",
      "Epoch: 56, Val NLL: 15.4934, Val Acc: 0.9592\n",
      "LR = 0.0001\n",
      "Epoch: 57, Train NLL: 19.7820\n",
      "Epoch: 57, Val NLL: 14.8393, Val Acc: 0.9388\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 58, Train NLL: 17.2610\n",
      "Epoch: 58, Val NLL: 14.5681, Val Acc: 0.9184\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 59, Train NLL: 15.8569\n",
      "Epoch: 59, Val NLL: 15.4666, Val Acc: 0.9388\n",
      "LR = 0.0001\n",
      "Epoch: 60, Train NLL: 18.7197\n",
      "Epoch: 60, Val NLL: 27.4284, Val Acc: 0.6939\n",
      "LR = 0.0001\n",
      "Epoch: 61, Train NLL: 21.6867\n",
      "Epoch: 61, Val NLL: 16.6755, Val Acc: 0.8980\n",
      "LR = 0.0001\n",
      "Epoch: 62, Train NLL: 18.0462\n",
      "Epoch: 62, Val NLL: 15.1505, Val Acc: 0.9388\n",
      "LR = 0.0001\n",
      "Epoch: 63, Train NLL: 16.2454\n",
      "Epoch: 63, Val NLL: 14.4937, Val Acc: 0.8776\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 64, Train NLL: 14.8271\n",
      "Epoch: 64, Val NLL: 15.0184, Val Acc: 0.8163\n",
      "LR = 0.0001\n",
      "Epoch: 65, Train NLL: 20.6829\n",
      "Epoch: 65, Val NLL: 14.5557, Val Acc: 0.8571\n",
      "LR = 0.0001\n",
      "Epoch: 66, Train NLL: 17.9360\n",
      "Epoch: 66, Val NLL: 14.0634, Val Acc: 0.9184\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 67, Train NLL: 17.7742\n",
      "Epoch: 67, Val NLL: 12.8561, Val Acc: 0.9388\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 68, Train NLL: 18.5698\n",
      "Epoch: 68, Val NLL: 12.9868, Val Acc: 0.9388\n",
      "LR = 0.0001\n",
      "Epoch: 69, Train NLL: 16.3509\n",
      "Epoch: 69, Val NLL: 14.3165, Val Acc: 0.9184\n",
      "LR = 0.0001\n",
      "Epoch: 70, Train NLL: 17.8207\n",
      "Epoch: 70, Val NLL: 12.8504, Val Acc: 0.9184\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 71, Train NLL: 15.3673\n",
      "Epoch: 71, Val NLL: 17.1595, Val Acc: 0.8367\n",
      "LR = 0.0001\n",
      "Epoch: 72, Train NLL: 15.7357\n",
      "Epoch: 72, Val NLL: 14.0870, Val Acc: 0.8367\n",
      "LR = 0.0001\n",
      "Epoch: 73, Train NLL: 18.0134\n",
      "Epoch: 73, Val NLL: 13.4356, Val Acc: 0.9388\n",
      "LR = 0.0001\n",
      "Epoch: 74, Train NLL: 14.2056\n",
      "Epoch: 74, Val NLL: 11.9788, Val Acc: 0.9388\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 75, Train NLL: 18.0265\n",
      "Epoch: 75, Val NLL: 13.2402, Val Acc: 0.8776\n",
      "LR = 0.0001\n",
      "Epoch: 76, Train NLL: 13.9828\n",
      "Epoch: 76, Val NLL: 11.4775, Val Acc: 0.9388\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 77, Train NLL: 14.4350\n",
      "Epoch: 77, Val NLL: 15.5272, Val Acc: 0.8776\n",
      "LR = 0.0001\n",
      "Epoch: 78, Train NLL: 14.9259\n",
      "Epoch: 78, Val NLL: 11.2248, Val Acc: 0.9388\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 79, Train NLL: 16.0971\n",
      "Epoch: 79, Val NLL: 25.1483, Val Acc: 0.7143\n",
      "LR = 0.0001\n",
      "Epoch: 80, Train NLL: 15.0444\n",
      "Epoch: 80, Val NLL: 16.4773, Val Acc: 0.8776\n",
      "LR = 0.0001\n",
      "Epoch: 81, Train NLL: 15.7468\n",
      "Epoch: 81, Val NLL: 10.9677, Val Acc: 0.9184\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 82, Train NLL: 14.4640\n",
      "Epoch: 82, Val NLL: 14.1638, Val Acc: 0.8571\n",
      "LR = 0.0001\n",
      "Epoch: 83, Train NLL: 12.7074\n",
      "Epoch: 83, Val NLL: 11.1402, Val Acc: 0.9184\n",
      "LR = 0.0001\n",
      "Epoch: 84, Train NLL: 13.8603\n",
      "Epoch: 84, Val NLL: 11.3281, Val Acc: 0.9184\n",
      "LR = 0.0001\n",
      "Epoch: 85, Train NLL: 14.9291\n",
      "Epoch: 85, Val NLL: 11.5610, Val Acc: 0.9184\n",
      "LR = 0.0001\n",
      "Epoch: 86, Train NLL: 15.7611\n",
      "Epoch: 86, Val NLL: 12.0305, Val Acc: 0.9388\n",
      "LR = 0.0001\n",
      "Epoch: 87, Train NLL: 12.2928\n",
      "Epoch: 87, Val NLL: 13.8331, Val Acc: 0.9184\n",
      "LR = 0.0001\n",
      "Epoch: 88, Train NLL: 15.0300\n",
      "Epoch: 88, Val NLL: 17.8375, Val Acc: 0.8163\n",
      "LR = 0.0001\n",
      "Epoch: 89, Train NLL: 14.7844\n",
      "Epoch: 89, Val NLL: 19.4872, Val Acc: 0.7959\n",
      "LR = 0.0001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90, Train NLL: 14.8006\n",
      "Epoch: 90, Val NLL: 11.5867, Val Acc: 0.8980\n",
      "LR = 0.0001\n",
      "Epoch: 91, Train NLL: 15.4109\n",
      "Epoch: 91, Val NLL: 10.3784, Val Acc: 0.8980\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 92, Train NLL: 14.1421\n",
      "Epoch: 92, Val NLL: 27.4158, Val Acc: 0.7143\n",
      "LR = 0.0001\n",
      "Epoch: 93, Train NLL: 18.0540\n",
      "Epoch: 93, Val NLL: 19.4861, Val Acc: 0.7959\n",
      "LR = 0.0001\n",
      "Epoch: 94, Train NLL: 14.2041\n",
      "Epoch: 94, Val NLL: 11.1944, Val Acc: 0.9592\n",
      "LR = 0.0001\n",
      "Epoch: 95, Train NLL: 12.2540\n",
      "Epoch: 95, Val NLL: 10.4253, Val Acc: 0.9184\n",
      "LR = 0.0001\n",
      "Epoch: 96, Train NLL: 13.3577\n",
      "Epoch: 96, Val NLL: 12.2173, Val Acc: 0.9184\n",
      "LR = 0.0001\n",
      "Epoch: 97, Train NLL: 11.7640\n",
      "Epoch: 97, Val NLL: 10.9356, Val Acc: 0.9388\n",
      "LR = 0.0001\n",
      "Epoch: 98, Train NLL: 10.4431\n",
      "Epoch: 98, Val NLL: 10.3714, Val Acc: 0.8776\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n",
      "Epoch: 99, Train NLL: 14.6352\n",
      "Epoch: 99, Val NLL: 9.7411, Val Acc: 0.9184\n",
      "LR = 0.0001\n",
      "WROTE MODEL\n"
     ]
    }
   ],
   "source": [
    "best_loss = 1e8\n",
    "for e in range(epochs):\n",
    "    train_utils.embedding_training_loop(e, train_loader, net, criterion, optimizer,pool_fn)\n",
    "    loss = train_utils.embedding_validation_loop(e, valid_loader, net, criterion,pool_fn)\n",
    "    #scheduler.step(loss)\n",
    "    print('LR = {}'.format(optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "    if loss < best_loss:\n",
    "        torch.save(net.state_dict(),'best_convnet.pt')\n",
    "        best_loss = loss\n",
    "        print('WROTE MODEL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (m): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (n): Dropout(p=0)\n",
       "  (relu): ReLU()\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(3, 36, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(36, 48, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=1200, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0)\n",
       "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0)\n",
       "  )\n",
       "  (classification_layer): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

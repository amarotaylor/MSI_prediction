{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "import data_utils\n",
    "import train_utils\n",
    "import models\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = data_utils.COAD_dataset(data_utils.COAD_DEV)\n",
    "dev_loader = torch.utils.data.DataLoader(dev, batch_size=1, shuffle=True, pin_memory=True)\n",
    "train = data_utils.COAD_dataset(data_utils.COAD_TRAIN)\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=1, shuffle=True, pin_memory=True)\n",
    "valid = data_utils.COAD_dataset(data_utils.COAD_VALID)\n",
    "valid_loader = torch.utils.data.DataLoader(valid, batch_size=1, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (m): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu): ReLU()\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(3, 36, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(36, 48, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (lstm): LSTM(1200, 512, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (classification_layer): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_conv_layers = 2\n",
    "kernel_size = [4,3]\n",
    "n_conv_filters = [36,48]\n",
    "hidden_size = 512\n",
    "n_rnn_layers = 2\n",
    "dropout=0.0\n",
    "gen = models.Generator(n_conv_layers, kernel_size, n_conv_filters, hidden_size, n_rnn_layers, dropout=dropout)\n",
    "gen.cuda()\n",
    "\n",
    "n_conv_layers = 2\n",
    "n_fc_layers = 2\n",
    "kernel_size = [4,3]\n",
    "n_conv_filters = [36,48]\n",
    "hidden_size = [512,512]\n",
    "dropout=0.0\n",
    "enc = models.ConvNet(n_conv_layers, n_fc_layers, kernel_size, n_conv_filters, hidden_size, dropout=dropout)\n",
    "enc.cuda()\n",
    "\n",
    "\n",
    "num_samples = 10\n",
    "lamb1 = 0.0\n",
    "lamb2 = 0.0\n",
    "xent = nn.CrossEntropyLoss()\n",
    "learning_rate = 1e-4\n",
    "\n",
    "\n",
    "params = list(enc.parameters()) + list(gen.parameters())\n",
    "optimizer = torch.optim.Adam(params, lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_fn(x):\n",
    "    #v,a = torch.max(x,0)\n",
    "    v = torch.mean(x,0)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 7594282.3017\n",
      "Epoch: 0, Val Loss: 141.4314, Val Acc: 0.4082\n",
      "Epoch: 1, Train Loss: 1362.6312\n",
      "Epoch: 1, Val Loss: 138.9712, Val Acc: 0.4082\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuDNN error: CUDNN_STATUS_EXECUTION_FAILED",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b01b54ed07e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     train_utils.rationales_training_loop(e, train_loader, gen, enc, pool_fn, num_samples, \n\u001b[0;32m----> 4\u001b[0;31m                                          lamb1, lamb2, xent, learning_rate, optimizer)\n\u001b[0m\u001b[1;32m      5\u001b[0m     loss = train_utils.rationales_validation_loop(e, valid_loader, gen, enc, pool_fn, num_samples, \n\u001b[1;32m      6\u001b[0m                                                   lamb1, lamb2, xent)\n",
      "\u001b[0;32m~/MSI_prediction/labeled_nuclei_project/train_utils.py\u001b[0m in \u001b[0;36mrationales_training_loop\u001b[0;34m(e, train_loader, gen, enc, pool_fn, num_samples, lamb1, lamb2, xent, learning_rate, optimizer)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mslide\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mslide\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslide\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mzis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0mzis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MSI_prediction/labeled_nuclei_project/train_utils.py\u001b[0m in \u001b[0;36msampler\u001b[0;34m(slide, gen, num_samples)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mlogprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mlogprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_EXECUTION_FAILED"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for e in range(epochs):\n",
    "    train_utils.rationales_training_loop(e, train_loader, gen, enc, pool_fn, num_samples, \n",
    "                                         lamb1, lamb2, xent, learning_rate, optimizer)\n",
    "    loss = train_utils.rationales_validation_loop(e, valid_loader, gen, enc, pool_fn, num_samples, \n",
    "                                                  lamb1, lamb2, xent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS MAY NOT WORK ON EPOCH 1!!! BECAUSE OF CUDA ERROR!!!\n",
    "torch.backends.cudnn.version()\n",
    "lsm = torch.nn.LogSoftmax(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "    gen.train()\n",
    "    enc.train()\n",
    "    \n",
    "    total_loss = 0\n",
    "    \n",
    "    for slide,label in train_loader:\n",
    "        slide,label = slide.squeeze(0).cuda(),label.cuda()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_gumbel(shape, eps=1e-20): \n",
    "    \"\"\"Sample from Gumbel(0, 1)\"\"\"\n",
    "    U = torch.rand(shape,dtype=torch.float32,device='cuda')\n",
    "    return -torch.log(-torch.log(U + eps) + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gumbel_softmax_sample(logits, temperature): \n",
    "    \"\"\" Draw a sample from the Gumbel-Softmax distribution\"\"\"\n",
    "    y = logits + sample_gumbel(logits.shape)\n",
    "    return F.softmax( y / temperature,dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gumbel_softmax(logits, temperature, hard=False):\n",
    "    \"\"\"Sample from the Gumbel-Softmax distribution and optionally discretize.\n",
    "  Args:\n",
    "    logits: [batch_size, n_class] unnormalized log-probs\n",
    "    temperature: non-negative scalar\n",
    "    hard: if True, take argmax, but differentiate w.r.t. soft sample y\n",
    "  Returns:\n",
    "    [batch_size, n_class] sample from the Gumbel-Softmax distribution.\n",
    "    If hard=True, then the returned sample will be one-hot, otherwise it will\n",
    "    be a probabilitiy distribution that sums to 1 across classes\n",
    "  \"\"\"\n",
    "    y = gumbel_softmax_sample(logits, temperature)\n",
    "    if hard:\n",
    "        y = torch.argmax(logits,dim=1)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = gen(slide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = lsm(preds).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = gumbel_softmax(logits, 10.0)\n",
    "#sample = torch.zeros_like(sample)+0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6809, device='cuda:0', grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rationale = slide.view(3,27,27,-1) * sample[:,1]\n",
    "rationale = rationale.view(-1,slide.shape[1],slide.shape[2],slide.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = enc(rationale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = pool_fn(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = enc.classification_layer(pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = xent(y_hat.unsqueeze(0),label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.4824e-03, -1.2373e-03, -1.7632e-03, -1.5996e-03],\n",
      "          [-1.4752e-03, -1.2300e-03, -1.8194e-03, -1.4933e-03],\n",
      "          [-1.3611e-03, -1.1104e-03, -1.6497e-03, -1.4167e-03],\n",
      "          [-1.4463e-03, -1.1894e-03, -1.7332e-03, -1.5124e-03]],\n",
      "\n",
      "         [[-1.4502e-03, -1.0757e-03, -1.6620e-03, -1.4019e-03],\n",
      "          [-1.4859e-03, -1.2389e-03, -1.7924e-03, -1.4363e-03],\n",
      "          [-6.6304e-04, -3.0163e-04, -1.0648e-03, -6.5863e-04],\n",
      "          [-1.4278e-03, -1.1135e-03, -1.6939e-03, -1.3613e-03]],\n",
      "\n",
      "         [[-1.5774e-03, -1.2512e-03, -1.8185e-03, -1.5035e-03],\n",
      "          [-1.4575e-03, -1.1201e-03, -1.7016e-03, -1.5092e-03],\n",
      "          [-1.4513e-03, -1.1805e-03, -1.7375e-03, -1.4512e-03],\n",
      "          [-1.4889e-03, -1.3291e-03, -1.8473e-03, -1.5752e-03]]],\n",
      "\n",
      "\n",
      "        [[[-3.2772e-03, -3.1356e-03, -3.3610e-03, -3.2743e-03],\n",
      "          [-3.0988e-03, -2.9308e-03, -3.1134e-03, -3.1775e-03],\n",
      "          [-2.9359e-03, -2.5880e-03, -3.0656e-03, -2.8390e-03],\n",
      "          [-3.2758e-03, -3.0272e-03, -3.4450e-03, -3.2166e-03]],\n",
      "\n",
      "         [[-3.0170e-03, -2.8450e-03, -3.0966e-03, -3.0700e-03],\n",
      "          [-3.0941e-03, -2.8171e-03, -3.2791e-03, -2.9654e-03],\n",
      "          [-2.2648e-03, -2.0328e-03, -2.4942e-03, -2.3580e-03],\n",
      "          [-2.9978e-03, -2.8571e-03, -3.0415e-03, -3.1085e-03]],\n",
      "\n",
      "         [[-3.0364e-03, -2.8101e-03, -3.1726e-03, -3.1428e-03],\n",
      "          [-2.8266e-03, -2.7079e-03, -2.9768e-03, -2.8830e-03],\n",
      "          [-3.1834e-03, -3.0493e-03, -3.2018e-03, -3.2791e-03],\n",
      "          [-3.2257e-03, -2.8674e-03, -3.2303e-03, -3.1073e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.5559e-04,  1.3818e-04,  1.5139e-04,  1.4934e-04],\n",
      "          [ 1.4692e-04,  1.4714e-04,  1.4784e-04,  1.6816e-04],\n",
      "          [ 1.4420e-04,  1.2486e-04,  1.5532e-04,  1.3143e-04],\n",
      "          [ 1.4395e-04,  1.3676e-04,  1.4323e-04,  1.3557e-04]],\n",
      "\n",
      "         [[ 1.1962e-04,  1.0610e-04,  1.3560e-04,  1.3625e-04],\n",
      "          [ 1.2523e-04,  1.1421e-04,  1.3045e-04,  1.2369e-04],\n",
      "          [ 9.6411e-05,  1.0764e-04,  1.1279e-04,  9.0068e-05],\n",
      "          [ 1.1462e-04,  1.0796e-04,  1.2446e-04,  1.2938e-04]],\n",
      "\n",
      "         [[ 1.4590e-04,  1.2767e-04,  1.4052e-04,  1.3503e-04],\n",
      "          [ 1.3245e-04,  1.1240e-04,  1.3268e-04,  1.3029e-04],\n",
      "          [ 6.4178e-05,  5.1496e-05,  6.4158e-05,  8.1593e-05],\n",
      "          [ 1.4333e-04,  1.1884e-04,  1.3622e-04,  1.1564e-04]]],\n",
      "\n",
      "\n",
      "        [[[-1.0821e-03, -1.1860e-03, -1.3616e-03, -9.9901e-04],\n",
      "          [-1.4235e-03, -1.4699e-03, -1.5979e-03, -1.4062e-03],\n",
      "          [-1.2935e-03, -1.3462e-03, -1.5393e-03, -1.1370e-03],\n",
      "          [-9.6961e-04, -1.0890e-03, -1.2316e-03, -9.5664e-04]],\n",
      "\n",
      "         [[-1.1224e-03, -1.3502e-03, -1.3968e-03, -1.2015e-03],\n",
      "          [-1.2990e-03, -1.3633e-03, -1.6300e-03, -1.3605e-03],\n",
      "          [-4.6996e-04, -7.7320e-04, -7.7711e-04, -5.7904e-04],\n",
      "          [-1.1447e-03, -1.3408e-03, -1.3612e-03, -1.2114e-03]],\n",
      "\n",
      "         [[-1.0970e-03, -1.1468e-03, -1.2945e-03, -1.0507e-03],\n",
      "          [-1.2577e-03, -1.2815e-03, -1.4854e-03, -1.1832e-03],\n",
      "          [-1.4654e-03, -1.4638e-03, -1.6113e-03, -1.3795e-03],\n",
      "          [-1.1758e-03, -1.2343e-03, -1.4407e-03, -1.0283e-03]]],\n",
      "\n",
      "\n",
      "        [[[-4.8495e-03, -5.5168e-03, -4.7528e-03, -5.0103e-03],\n",
      "          [-4.8715e-03, -5.2682e-03, -4.7752e-03, -4.7832e-03],\n",
      "          [-5.4608e-03, -5.5031e-03, -5.4446e-03, -5.1304e-03],\n",
      "          [-4.9294e-03, -5.5263e-03, -5.0646e-03, -4.8194e-03]],\n",
      "\n",
      "         [[-5.4216e-03, -5.5322e-03, -5.3175e-03, -5.3270e-03],\n",
      "          [-3.9994e-03, -4.3954e-03, -4.1151e-03, -3.9864e-03],\n",
      "          [-4.6100e-03, -5.0830e-03, -4.7715e-03, -4.8995e-03],\n",
      "          [-5.2297e-03, -5.5480e-03, -5.2616e-03, -5.5604e-03]],\n",
      "\n",
      "         [[-5.1224e-03, -5.3276e-03, -5.1779e-03, -4.9580e-03],\n",
      "          [-5.0671e-03, -5.6309e-03, -4.9048e-03, -5.2698e-03],\n",
      "          [-5.2829e-03, -5.5629e-03, -5.1871e-03, -5.2510e-03],\n",
      "          [-5.3577e-03, -5.3852e-03, -5.3741e-03, -4.9585e-03]]]],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.0000e+00, -3.6236e-03, -7.5611e-03, -5.5068e-03,  4.6535e-03,\n",
      "         0.0000e+00,  1.3949e-05, -1.5443e-02, -3.8679e-04, -1.3027e-04,\n",
      "         5.1475e-05, -8.7611e-04,  0.0000e+00,  2.9270e-04,  0.0000e+00,\n",
      "         4.1362e-05,  6.0883e-03, -1.2833e-03,  3.3566e-03, -2.4892e-02,\n",
      "        -2.1471e-04, -1.0196e-02, -6.6101e-03,  0.0000e+00,  5.2323e-03,\n",
      "         1.3821e-03, -7.2090e-05, -1.4717e-02,  1.5225e-03, -4.1105e-03,\n",
      "        -1.0702e-02, -6.4995e-04,  1.1246e-02,  3.3421e-04, -3.6538e-03,\n",
      "        -1.2883e-02], device='cuda:0')\n",
      "tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 5.5300e-04,  7.6913e-04,  1.0134e-03],\n",
      "          [ 4.8573e-04,  7.6171e-04,  8.6676e-04],\n",
      "          [ 6.1923e-04,  8.5425e-04,  9.1576e-04]],\n",
      "\n",
      "         [[ 1.3662e-03,  1.3620e-03,  1.4928e-03],\n",
      "          [ 9.9044e-04,  1.0828e-03,  1.2885e-03],\n",
      "          [ 1.2086e-03,  1.3256e-03,  1.4364e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.8893e-07, -6.0727e-06, -5.4162e-06],\n",
      "          [ 1.2485e-05,  1.0530e-05,  1.0340e-06],\n",
      "          [ 9.9983e-06, -6.0617e-06, -7.1277e-06]],\n",
      "\n",
      "         [[ 4.8959e-04,  6.0648e-04,  3.6819e-04],\n",
      "          [ 2.4875e-04,  4.1930e-04,  1.5763e-04],\n",
      "          [ 7.0256e-04,  7.8724e-04,  5.0113e-04]],\n",
      "\n",
      "         [[ 8.6984e-04,  8.2906e-04,  7.4367e-04],\n",
      "          [ 1.0439e-03,  1.0102e-03,  1.0286e-03],\n",
      "          [ 1.1764e-03,  1.2351e-03,  1.2059e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 2.8065e-03,  2.9974e-03,  2.7940e-03],\n",
      "          [ 2.8914e-03,  2.9348e-03,  2.8387e-03],\n",
      "          [ 2.7177e-03,  2.8710e-03,  2.8687e-03]],\n",
      "\n",
      "         [[ 4.6719e-03,  4.8995e-03,  4.6715e-03],\n",
      "          [ 4.8486e-03,  5.0674e-03,  4.9024e-03],\n",
      "          [ 4.8445e-03,  4.9474e-03,  4.8678e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0375e-05,  3.0800e-06,  1.7202e-05],\n",
      "          [ 1.3679e-06,  2.1498e-06,  3.0150e-06],\n",
      "          [ 2.6186e-05,  1.1109e-05,  1.6622e-06]],\n",
      "\n",
      "         [[ 1.2854e-03,  1.1740e-03,  1.0596e-03],\n",
      "          [ 1.2672e-03,  1.1532e-03,  1.1698e-03],\n",
      "          [ 1.0327e-03,  9.8366e-04,  1.0084e-03]],\n",
      "\n",
      "         [[ 3.9364e-03,  3.9701e-03,  4.0102e-03],\n",
      "          [ 3.8547e-03,  3.7813e-03,  3.8491e-03],\n",
      "          [ 3.7302e-03,  3.6528e-03,  3.6373e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 5.8639e-04,  6.7475e-04,  7.4812e-04],\n",
      "          [ 6.7319e-04,  6.8226e-04,  7.4905e-04],\n",
      "          [ 8.9310e-04,  9.4590e-04,  9.7358e-04]],\n",
      "\n",
      "         [[ 1.0192e-03,  9.9802e-04,  1.0739e-03],\n",
      "          [ 1.2561e-03,  1.2417e-03,  1.2029e-03],\n",
      "          [ 1.4432e-03,  1.5695e-03,  1.5168e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.2748e-05, -9.6205e-07,  2.1311e-05],\n",
      "          [-4.9560e-06, -1.3843e-05, -9.4892e-06],\n",
      "          [-7.5563e-06,  1.1304e-07, -6.0601e-06]],\n",
      "\n",
      "         [[ 1.4774e-04,  9.4970e-05,  5.4626e-05],\n",
      "          [ 1.5944e-04,  1.4394e-04,  1.1076e-04],\n",
      "          [ 1.8573e-04,  2.3140e-04,  3.7564e-05]],\n",
      "\n",
      "         [[ 8.4937e-04,  9.0496e-04,  7.9798e-04],\n",
      "          [ 1.3266e-03,  1.2969e-03,  1.2732e-03],\n",
      "          [ 6.2135e-04,  6.7384e-04,  6.3344e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]]], device='cuda:0')\n",
      "tensor([ 3.7600e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00, -4.9627e-03,\n",
      "        -2.3092e-02,  9.7255e-03,  3.2791e-02, -4.4500e-02,  1.1001e-03,\n",
      "         0.0000e+00,  2.4569e-05,  0.0000e+00, -2.9323e-02,  0.0000e+00,\n",
      "         3.5942e-04, -1.5117e-02,  0.0000e+00,  9.3327e-03,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -5.6890e-03, -4.2714e-02,  2.3963e-02,\n",
      "        -1.3255e-02,  3.6281e-02,  2.4566e-03, -8.6682e-03, -1.0380e-02,\n",
      "        -8.1373e-03,  0.0000e+00, -7.9026e-04, -2.2286e-02, -3.4882e-03,\n",
      "         4.9364e-03, -4.5054e-03, -1.2691e-04,  2.9023e-05,  0.0000e+00,\n",
      "         7.8234e-04,  0.0000e+00,  9.4673e-06,  1.4921e-04, -5.0403e-03,\n",
      "         1.2690e-02,  2.8550e-03,  0.0000e+00], device='cuda:0')\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0002,  0.0003,  0.0002,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0002, -0.0002, -0.0002,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [-0.0004, -0.0005, -0.0005,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0002, -0.0002, -0.0002,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0004,  0.0005,  0.0005,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.0000e+00,  3.6398e-03, -2.3073e-03, -8.4034e-05,  0.0000e+00,\n",
      "         4.4844e-03,  6.5895e-03,  0.0000e+00,  1.0291e-02,  0.0000e+00,\n",
      "        -8.7191e-03,  0.0000e+00,  7.2928e-03,  7.7239e-03,  0.0000e+00,\n",
      "        -6.1761e-03,  0.0000e+00, -5.2848e-03,  3.4417e-04,  0.0000e+00,\n",
      "         0.0000e+00,  5.9782e-03, -9.8008e-03,  0.0000e+00, -1.0254e-03,\n",
      "         0.0000e+00,  2.7830e-03,  3.6104e-03,  0.0000e+00,  0.0000e+00,\n",
      "         1.4350e-03,  1.1875e-02,  0.0000e+00, -9.6473e-03,  1.3955e-03,\n",
      "         0.0000e+00,  0.0000e+00,  4.2665e-03,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  2.0802e-03,  0.0000e+00, -9.8760e-03,  9.7646e-03,\n",
      "         0.0000e+00,  3.6546e-03,  0.0000e+00, -9.4751e-03, -8.9207e-03,\n",
      "         6.8358e-04, -2.1436e-02,  0.0000e+00,  0.0000e+00,  1.1069e-02,\n",
      "         4.7331e-03,  0.0000e+00, -9.8949e-03, -5.4090e-03,  6.0731e-03,\n",
      "         0.0000e+00,  1.9387e-03,  0.0000e+00,  1.4230e-02,  0.0000e+00,\n",
      "         0.0000e+00,  8.8115e-03, -3.6406e-03, -2.1313e-03,  0.0000e+00,\n",
      "         0.0000e+00, -5.5926e-03,  7.1479e-03, -1.0733e-02,  2.0352e-03,\n",
      "         5.4777e-03, -1.2022e-02, -1.1154e-02,  0.0000e+00,  8.3753e-03,\n",
      "        -1.0955e-03,  0.0000e+00,  5.4877e-03, -4.1022e-04,  0.0000e+00,\n",
      "         7.1143e-03,  0.0000e+00,  0.0000e+00,  1.0935e-04, -1.3979e-03,\n",
      "        -3.9927e-03,  2.4096e-03,  0.0000e+00,  0.0000e+00, -6.3946e-03,\n",
      "        -6.3808e-03,  9.9056e-04,  0.0000e+00, -9.2712e-03,  1.7821e-03,\n",
      "         4.0279e-03,  0.0000e+00,  2.4249e-03,  0.0000e+00,  2.7172e-03,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -1.1082e-02,  1.0116e-02,\n",
      "         0.0000e+00,  7.2502e-03,  2.0560e-04, -2.7520e-03,  0.0000e+00,\n",
      "        -9.5204e-03, -1.2604e-02, -6.8243e-03,  0.0000e+00, -1.3405e-02,\n",
      "         0.0000e+00, -5.8723e-03,  4.9622e-03,  1.8265e-03, -3.8261e-03,\n",
      "        -3.6322e-03, -9.9064e-03, -1.0227e-03,  0.0000e+00, -1.0407e-03,\n",
      "        -3.8657e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.1478e-02,\n",
      "        -1.9473e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "        -7.0689e-03, -7.7823e-03, -2.8491e-03,  1.3009e-03,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  3.5747e-03, -6.4107e-03,\n",
      "         2.8881e-04,  3.9141e-03,  0.0000e+00, -1.4877e-04, -3.6254e-03,\n",
      "        -5.3391e-03,  1.4345e-02,  5.5683e-03,  0.0000e+00, -4.9739e-03,\n",
      "        -7.3697e-03,  0.0000e+00,  0.0000e+00, -2.8798e-03,  0.0000e+00,\n",
      "        -5.9899e-03,  4.9958e-03,  5.1960e-03, -1.8046e-03,  2.6213e-03,\n",
      "        -1.2550e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.2248e-03,\n",
      "        -8.2835e-03,  0.0000e+00,  0.0000e+00,  3.5952e-03,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -1.4138e-04,  0.0000e+00,\n",
      "         0.0000e+00,  4.7723e-03,  3.3360e-03,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  1.0654e-02,  5.0860e-03,  8.7719e-03,\n",
      "         5.3377e-03,  2.5362e-03,  0.0000e+00, -1.2366e-03,  1.1436e-02,\n",
      "        -2.9873e-03,  0.0000e+00,  4.6698e-03,  0.0000e+00,  0.0000e+00,\n",
      "        -8.8983e-03,  0.0000e+00, -2.2046e-02,  5.7462e-03,  0.0000e+00,\n",
      "         0.0000e+00, -2.4707e-05,  0.0000e+00,  0.0000e+00,  1.2781e-02,\n",
      "        -3.1750e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  1.9463e-03,  2.3738e-03, -3.6713e-04,  0.0000e+00,\n",
      "         8.1425e-04,  0.0000e+00,  3.4962e-03,  1.0243e-02,  2.0727e-04,\n",
      "         0.0000e+00, -6.6665e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "        -2.7973e-05, -5.0541e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -6.1361e-03, -6.8641e-03,\n",
      "         0.0000e+00,  3.2922e-03, -6.3306e-03, -2.4640e-03,  0.0000e+00,\n",
      "         0.0000e+00,  5.1328e-04,  8.0680e-03, -3.8075e-03,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -1.1719e-02,  7.7366e-03,  6.6382e-03,\n",
      "        -2.3718e-03, -2.1179e-03,  0.0000e+00,  1.2342e-03,  0.0000e+00,\n",
      "        -6.2326e-03,  0.0000e+00,  9.6739e-03, -4.0243e-04,  0.0000e+00,\n",
      "         0.0000e+00,  2.4062e-03,  1.4888e-02,  0.0000e+00,  0.0000e+00,\n",
      "         4.1165e-03,  0.0000e+00, -4.4845e-05,  0.0000e+00, -1.6602e-03,\n",
      "        -3.0132e-03,  0.0000e+00, -3.4324e-03,  0.0000e+00, -2.3086e-03,\n",
      "        -4.9552e-03, -6.0373e-03, -1.2407e-02,  1.5859e-03,  8.7035e-03,\n",
      "         0.0000e+00, -8.8063e-03,  3.9120e-03,  0.0000e+00,  4.6997e-03,\n",
      "        -2.6588e-03, -6.5750e-03, -2.8128e-03, -6.7000e-03,  6.7203e-03,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         4.9501e-03,  6.2166e-03, -7.7230e-03,  5.2435e-03, -2.0037e-03,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -5.2978e-03,  0.0000e+00,\n",
      "         9.0123e-03, -1.1684e-03,  1.9061e-03,  0.0000e+00,  2.9626e-03,\n",
      "        -5.0000e-04,  6.6664e-03, -3.5207e-04,  0.0000e+00,  4.5467e-03,\n",
      "         1.8178e-03,  2.7172e-03,  6.5087e-03, -6.8038e-03,  5.4964e-03,\n",
      "         1.1073e-02, -5.3908e-03,  9.5624e-04,  0.0000e+00,  8.0151e-03,\n",
      "         0.0000e+00,  1.0496e-03,  2.1716e-03,  0.0000e+00, -1.7939e-03,\n",
      "        -4.7442e-03,  8.1769e-03,  3.8976e-03,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -1.1003e-02, -4.7983e-03, -3.2872e-05,\n",
      "         0.0000e+00, -5.9562e-04,  0.0000e+00, -1.1155e-02,  1.1058e-02,\n",
      "        -2.0794e-04, -8.6025e-03,  0.0000e+00,  7.1347e-03, -2.0526e-03,\n",
      "        -3.1600e-03,  1.0997e-02, -1.5142e-02,  0.0000e+00, -1.1650e-02,\n",
      "        -3.3210e-03,  0.0000e+00,  0.0000e+00,  8.6135e-03, -1.2217e-02,\n",
      "         0.0000e+00, -3.6396e-03,  5.7879e-05,  1.0103e-02,  5.0579e-03,\n",
      "         0.0000e+00,  0.0000e+00,  2.2609e-02, -7.2793e-03,  0.0000e+00,\n",
      "         0.0000e+00, -3.1818e-03,  0.0000e+00,  1.0710e-03, -5.7481e-03,\n",
      "         0.0000e+00, -5.0890e-03, -8.7404e-04,  1.6570e-03,  0.0000e+00,\n",
      "         0.0000e+00, -6.5229e-03,  4.0578e-03,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  5.1267e-04, -6.7016e-03,  0.0000e+00, -1.3895e-02,\n",
      "        -1.0107e-02,  3.2604e-03,  1.7924e-02, -4.7311e-03,  0.0000e+00,\n",
      "        -8.9609e-03,  9.9430e-04, -7.6122e-04,  0.0000e+00,  4.7478e-04,\n",
      "         0.0000e+00, -5.5951e-03,  2.2097e-03,  0.0000e+00,  5.9547e-03,\n",
      "         4.4373e-03,  2.2139e-04,  0.0000e+00,  1.2256e-03, -2.3323e-02,\n",
      "         4.2918e-04,  0.0000e+00,  3.2601e-05, -1.5613e-03,  0.0000e+00,\n",
      "         5.9720e-03,  1.1820e-02,  0.0000e+00, -1.9196e-04, -9.8367e-03,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         9.9216e-03, -5.0876e-04,  0.0000e+00,  1.1384e-03,  0.0000e+00,\n",
      "         0.0000e+00, -1.5551e-02, -6.0103e-03,  8.1990e-04,  9.0122e-04,\n",
      "         0.0000e+00,  0.0000e+00,  1.5665e-02,  5.8070e-03, -1.6502e-02,\n",
      "         0.0000e+00,  8.4131e-03,  1.3667e-03,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -1.5378e-02,  2.5086e-03,  1.3439e-03,\n",
      "         7.9818e-04,  4.7198e-04, -1.6360e-03,  7.0144e-04, -9.3456e-03,\n",
      "        -6.5825e-03,  2.2217e-03, -9.9543e-04,  3.1774e-03,  0.0000e+00,\n",
      "        -1.9398e-03,  8.7354e-04,  0.0000e+00, -8.5968e-03, -7.8217e-05,\n",
      "         0.0000e+00,  1.9005e-03,  4.4818e-03, -3.4375e-03,  0.0000e+00,\n",
      "         7.2512e-03, -1.2995e-02,  9.1267e-03,  0.0000e+00, -8.2592e-04,\n",
      "         0.0000e+00,  0.0000e+00, -6.8452e-03,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -4.1248e-03,  0.0000e+00,  1.1561e-03,\n",
      "        -7.5307e-03, -1.7702e-02,  1.9469e-02,  1.6875e-03,  0.0000e+00,\n",
      "         6.9067e-04,  0.0000e+00,  1.3849e-02, -1.0887e-03, -8.0721e-03,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  6.0778e-04, -6.6878e-03,\n",
      "        -3.1682e-03,  6.8560e-03], device='cuda:0')\n",
      "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  1.9940e-04,  5.6701e-04,  ...,  3.6275e-04,\n",
      "          8.3281e-04,  1.1944e-03],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -6.1094e-05, -1.7373e-04,  ..., -1.1114e-04,\n",
      "         -2.5517e-04, -3.6596e-04]], device='cuda:0')\n",
      "tensor([ 0.0000e+00,  3.6525e-02,  0.0000e+00, -3.3932e-02,  0.0000e+00,\n",
      "        -3.7026e-02,  0.0000e+00, -1.4142e-02,  1.4780e-02,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -3.4269e-03,  0.0000e+00, -1.9369e-02, -4.3206e-03,\n",
      "        -1.8919e-02,  0.0000e+00, -2.1806e-02,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -1.8136e-03,  0.0000e+00, -2.1293e-02,\n",
      "        -1.4998e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0862e-03, -1.8242e-03,\n",
      "         1.5371e-02, -2.7001e-02,  2.9463e-02,  2.0779e-02,  0.0000e+00,\n",
      "        -2.7551e-02,  0.0000e+00,  8.6826e-03,  0.0000e+00,  0.0000e+00,\n",
      "         2.1819e-02, -1.3488e-02,  1.9254e-02,  2.0344e-02,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -9.8651e-04,  2.2104e-02, -1.5565e-02,\n",
      "        -1.7928e-02,  7.8660e-03, -1.2883e-02,  1.2853e-02,  5.5831e-03,\n",
      "         0.0000e+00, -2.3516e-03, -2.0010e-02, -1.2324e-02,  0.0000e+00,\n",
      "         0.0000e+00,  2.2675e-02,  0.0000e+00, -3.4321e-02,  0.0000e+00,\n",
      "        -6.3898e-03,  1.3582e-02,  1.5411e-02,  2.8963e-02,  0.0000e+00,\n",
      "         1.0667e-02,  0.0000e+00,  0.0000e+00, -3.4462e-02, -2.4955e-02,\n",
      "         0.0000e+00,  0.0000e+00, -2.2952e-02,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -1.5878e-02,  1.7332e-02,  0.0000e+00, -1.8204e-02,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -1.8352e-02,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "        -9.5235e-03,  1.0854e-02,  3.5406e-05,  9.5267e-03,  0.0000e+00,\n",
      "         0.0000e+00, -1.5049e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  4.5302e-04,  0.0000e+00,\n",
      "         0.0000e+00, -2.7768e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         3.3796e-03,  1.0094e-02,  0.0000e+00,  9.0414e-03, -8.0738e-03,\n",
      "         0.0000e+00,  0.0000e+00,  1.6387e-02,  8.2606e-03,  0.0000e+00,\n",
      "        -1.6840e-02,  0.0000e+00, -3.6366e-04,  0.0000e+00, -1.0563e-02,\n",
      "         0.0000e+00,  0.0000e+00, -6.1079e-03, -7.3051e-03,  1.6119e-02,\n",
      "         4.3666e-04, -3.5177e-03, -5.8431e-03,  0.0000e+00,  2.5214e-03,\n",
      "        -2.0577e-02,  0.0000e+00,  0.0000e+00, -1.7142e-02,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -1.9145e-02,  3.5245e-02,  2.1556e-02,\n",
      "         1.7389e-02, -2.1548e-02,  0.0000e+00,  0.0000e+00, -2.1773e-02,\n",
      "         1.2795e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0393e-02,\n",
      "         0.0000e+00, -1.6198e-02,  0.0000e+00,  8.1829e-05,  0.0000e+00,\n",
      "         1.1237e-02,  1.5562e-02,  1.3503e-02,  0.0000e+00, -2.4375e-02,\n",
      "         0.0000e+00,  4.7941e-03,  0.0000e+00,  0.0000e+00,  2.9408e-02,\n",
      "         0.0000e+00,  0.0000e+00, -2.5341e-02,  0.0000e+00, -1.2687e-03,\n",
      "         1.0686e-02, -7.1112e-03, -2.3190e-02, -3.8032e-02, -3.4107e-02,\n",
      "        -4.0256e-03, -1.3145e-02,  1.9792e-02, -2.0746e-02,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  1.3734e-02,  0.0000e+00,  7.1739e-03,\n",
      "         6.8251e-03,  9.4583e-03,  8.7093e-03,  0.0000e+00,  0.0000e+00,\n",
      "         2.1107e-02, -3.7680e-02,  1.5097e-02, -2.8872e-02,  0.0000e+00,\n",
      "        -1.7753e-02,  4.7600e-03,  0.0000e+00,  0.0000e+00, -1.4066e-02,\n",
      "        -1.3682e-02, -1.4298e-02,  0.0000e+00, -1.8158e-02, -1.2309e-03,\n",
      "        -3.3608e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  1.1115e-02, -1.4403e-02, -1.6538e-02,\n",
      "         9.2415e-03, -1.4933e-02,  0.0000e+00, -2.1047e-02, -7.1636e-03,\n",
      "         0.0000e+00,  1.9993e-02,  0.0000e+00,  0.0000e+00, -7.7246e-03,\n",
      "        -7.4215e-03,  2.8569e-02,  0.0000e+00,  0.0000e+00,  2.7885e-02,\n",
      "         0.0000e+00, -1.0358e-02,  2.7637e-02,  5.4454e-03,  2.1944e-02,\n",
      "         3.0374e-03, -5.6708e-03,  5.5288e-03, -2.5536e-02, -2.4155e-03,\n",
      "         4.9763e-03, -3.1815e-02,  0.0000e+00, -6.8250e-03,  0.0000e+00,\n",
      "         0.0000e+00,  6.7092e-03, -6.8872e-04, -9.6728e-03,  7.5442e-04,\n",
      "         0.0000e+00,  1.4980e-02, -9.6301e-03,  4.0078e-02,  0.0000e+00,\n",
      "        -4.2381e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00, -2.2881e-02,\n",
      "         0.0000e+00,  1.4253e-03, -6.3852e-03,  1.4948e-02,  8.8178e-03,\n",
      "        -2.2146e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.5133e-02,\n",
      "         1.7507e-02, -7.1528e-03,  0.0000e+00, -2.5312e-02, -1.3132e-02,\n",
      "         0.0000e+00,  0.0000e+00, -1.8498e-02, -1.7717e-02,  1.2503e-02,\n",
      "         0.0000e+00, -1.2243e-02,  0.0000e+00,  2.0997e-02, -1.2595e-02,\n",
      "        -1.1159e-02, -1.5486e-02,  0.0000e+00,  0.0000e+00, -1.8259e-02,\n",
      "         2.6509e-03,  0.0000e+00,  2.3740e-02,  1.1317e-02,  2.7152e-02,\n",
      "        -1.2249e-02, -2.6185e-02,  1.8128e-02,  0.0000e+00, -2.4428e-02,\n",
      "         0.0000e+00,  1.3853e-03,  1.2109e-02,  2.3007e-02,  8.3868e-03,\n",
      "         4.1049e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.8339e-02,\n",
      "        -3.8670e-03,  0.0000e+00,  0.0000e+00, -1.7444e-02,  4.5610e-04,\n",
      "         3.4411e-04, -3.5341e-03,  1.7694e-02,  0.0000e+00,  0.0000e+00,\n",
      "        -1.2213e-03,  0.0000e+00,  0.0000e+00,  3.2772e-02,  3.0235e-03,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.4217e-02,\n",
      "         3.3233e-02,  2.5288e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  3.1330e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -1.0889e-02,  0.0000e+00,  1.0074e-02,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -2.6637e-02, -1.7032e-02,\n",
      "         0.0000e+00,  0.0000e+00, -4.5852e-03, -2.8116e-03,  1.9907e-02,\n",
      "         2.9644e-02,  0.0000e+00,  1.6383e-02, -1.9666e-02,  0.0000e+00,\n",
      "        -8.5202e-03,  0.0000e+00,  0.0000e+00,  4.4895e-03,  0.0000e+00,\n",
      "         0.0000e+00, -1.7778e-02,  3.5862e-02,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -1.8064e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "        -2.4800e-03,  0.0000e+00,  0.0000e+00,  1.8912e-02,  0.0000e+00,\n",
      "         2.2352e-03, -1.8778e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         6.6935e-04,  1.9920e-02,  0.0000e+00,  0.0000e+00, -3.1956e-03,\n",
      "         4.8088e-03, -3.2653e-02,  6.2922e-04,  0.0000e+00, -1.1302e-02,\n",
      "         0.0000e+00,  1.9252e-02,  0.0000e+00, -1.3817e-02,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -3.4390e-03, -9.2454e-04,\n",
      "         0.0000e+00,  0.0000e+00,  1.3936e-02,  0.0000e+00,  6.0916e-03,\n",
      "         2.0576e-02,  0.0000e+00, -5.0785e-03, -8.2343e-04,  2.2016e-03,\n",
      "         3.4391e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.7557e-02,\n",
      "         1.8491e-03,  9.9207e-03,  0.0000e+00,  4.7817e-03, -2.5556e-03,\n",
      "         6.7775e-03,  0.0000e+00, -1.0770e-02,  1.2743e-03,  0.0000e+00,\n",
      "         0.0000e+00,  2.8467e-02,  0.0000e+00,  2.7027e-02,  1.6509e-02,\n",
      "        -2.8564e-02, -8.1721e-04,  7.3548e-03,  0.0000e+00,  0.0000e+00,\n",
      "         1.0870e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  4.9357e-03,\n",
      "        -1.3246e-02,  2.2198e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         1.0630e-02,  1.0727e-02,  3.2140e-04,  0.0000e+00, -2.4370e-02,\n",
      "        -8.0910e-03, -1.3288e-02, -1.4355e-03,  1.0847e-02,  9.1644e-04,\n",
      "        -9.2680e-03,  3.2894e-02,  0.0000e+00, -9.2434e-03, -6.0171e-03,\n",
      "         0.0000e+00,  0.0000e+00, -2.3226e-02,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  8.6986e-03,  0.0000e+00, -8.4713e-04,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  2.1990e-02,  0.0000e+00,  0.0000e+00,\n",
      "         1.2760e-03,  0.0000e+00, -2.4746e-02, -1.7028e-02,  0.0000e+00,\n",
      "         0.0000e+00, -1.1191e-02], device='cuda:0')\n",
      "tensor([[ 0.0000e+00, -3.3729e-03,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00, -1.5906e-02],\n",
      "        [ 0.0000e+00,  3.3729e-03,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  1.5906e-02]], device='cuda:0')\n",
      "tensor([-0.4939,  0.4939], device='cuda:0')\n",
      "tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 9.7423e-06,  7.7780e-06,  9.3416e-06,  9.6664e-06],\n",
      "          [ 9.2518e-06,  7.0008e-06,  8.5895e-06,  8.7710e-06],\n",
      "          [ 9.1187e-06,  6.8836e-06,  9.0578e-06,  8.7987e-06],\n",
      "          [ 1.0001e-05,  7.8897e-06,  9.8238e-06,  1.0184e-05]],\n",
      "\n",
      "         [[ 9.0931e-06,  7.1543e-06,  8.9450e-06,  9.2076e-06],\n",
      "          [ 4.3883e-06,  2.9136e-06,  5.4525e-06,  4.5377e-06],\n",
      "          [ 7.9283e-06,  6.0839e-06,  8.3885e-06,  8.0564e-06],\n",
      "          [ 9.4637e-06,  7.4670e-06,  9.2578e-06,  9.7079e-06]],\n",
      "\n",
      "         [[ 8.1854e-06,  6.8206e-06,  8.1440e-06,  8.1306e-06],\n",
      "          [ 9.2585e-06,  7.2346e-06,  9.2077e-06,  9.1527e-06],\n",
      "          [ 8.3360e-06,  6.7878e-06,  8.6418e-06,  8.6947e-06],\n",
      "          [ 8.0265e-06,  6.6897e-06,  7.8834e-06,  7.8661e-06]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.7748e-05,  2.1527e-05,  2.0965e-05,  1.7296e-05],\n",
      "          [ 1.7027e-05,  2.0884e-05,  2.0885e-05,  1.7483e-05],\n",
      "          [ 1.9534e-05,  2.2457e-05,  2.2746e-05,  1.9514e-05],\n",
      "          [ 1.7196e-05,  2.1109e-05,  2.0288e-05,  1.6601e-05]],\n",
      "\n",
      "         [[ 1.3328e-05,  1.9450e-05,  1.7655e-05,  1.3336e-05],\n",
      "          [ 1.4638e-05,  2.0629e-05,  2.0057e-05,  1.5460e-05],\n",
      "          [ 1.9739e-05,  2.4021e-05,  2.3800e-05,  1.9429e-05],\n",
      "          [ 1.4129e-05,  2.0340e-05,  1.8604e-05,  1.4247e-05]],\n",
      "\n",
      "         [[ 1.7478e-05,  2.1827e-05,  2.1887e-05,  1.7476e-05],\n",
      "          [ 1.7452e-05,  2.1594e-05,  2.1276e-05,  1.7306e-05],\n",
      "          [ 1.9310e-05,  2.2955e-05,  2.3404e-05,  1.9346e-05],\n",
      "          [ 1.7856e-05,  2.1990e-05,  2.2076e-05,  1.7729e-05]]],\n",
      "\n",
      "\n",
      "        [[[-2.9013e-05, -2.8868e-05, -2.7954e-05, -2.8770e-05],\n",
      "          [-2.7676e-05, -2.7850e-05, -2.5877e-05, -2.7690e-05],\n",
      "          [-2.8936e-05, -2.8994e-05, -2.7451e-05, -2.8724e-05],\n",
      "          [-2.8789e-05, -2.8724e-05, -2.7973e-05, -2.8792e-05]],\n",
      "\n",
      "         [[-3.0530e-05, -3.0313e-05, -2.9106e-05, -3.0101e-05],\n",
      "          [-2.3261e-05, -2.3133e-05, -2.1448e-05, -2.3652e-05],\n",
      "          [-2.5623e-05, -2.6317e-05, -2.4371e-05, -2.5772e-05],\n",
      "          [-3.0378e-05, -3.0068e-05, -2.8970e-05, -3.0118e-05]],\n",
      "\n",
      "         [[-2.8973e-05, -2.8665e-05, -2.7961e-05, -2.9044e-05],\n",
      "          [-2.9229e-05, -2.9583e-05, -2.8347e-05, -2.9370e-05],\n",
      "          [-2.7808e-05, -2.8483e-05, -2.7068e-05, -2.7634e-05],\n",
      "          [-2.8963e-05, -2.8664e-05, -2.7980e-05, -2.9060e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]]],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.0000e+00,  1.0521e-05,  0.0000e+00, -4.3140e-06, -4.1702e-05,\n",
      "         5.9006e-05,  0.0000e+00,  2.2288e-06,  2.9111e-06, -2.9398e-05,\n",
      "         0.0000e+00,  1.9114e-07,  8.5560e-06, -2.8336e-05, -6.5473e-06,\n",
      "         5.7007e-05,  3.0291e-07,  5.1584e-05,  3.8972e-05, -1.9300e-05,\n",
      "         3.8761e-05, -1.0835e-06,  1.1188e-05,  1.8644e-05,  0.0000e+00,\n",
      "         2.3426e-05,  0.0000e+00,  9.1828e-07,  1.5999e-07,  0.0000e+00,\n",
      "         6.4700e-07,  4.2980e-05,  4.2160e-05,  2.6280e-05, -3.6078e-05,\n",
      "         0.0000e+00], device='cuda:0')\n",
      "tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 2.7079e-05,  3.1298e-05,  3.1700e-05],\n",
      "          [ 2.6774e-05,  3.0680e-05,  3.1243e-05],\n",
      "          [ 2.5823e-05,  2.9791e-05,  3.0447e-05]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.3280e-05,  2.3665e-05,  2.1415e-05],\n",
      "          [ 2.3397e-05,  2.3703e-05,  2.1511e-05],\n",
      "          [ 2.3008e-05,  2.3320e-05,  2.1144e-05]],\n",
      "\n",
      "         [[ 5.3643e-05,  5.4056e-05,  5.2736e-05],\n",
      "          [ 5.3479e-05,  5.3781e-05,  5.2233e-05],\n",
      "          [ 5.2132e-05,  5.2691e-05,  5.1662e-05]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-1.7717e-05, -1.8487e-05, -1.9340e-05],\n",
      "          [-1.7550e-05, -1.8534e-05, -1.9381e-05],\n",
      "          [-1.7397e-05, -1.7855e-05, -1.8389e-05]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2870e-05, -1.3578e-05, -1.2895e-05],\n",
      "          [-1.2163e-05, -1.3186e-05, -1.2286e-05],\n",
      "          [-1.2522e-05, -1.3228e-05, -1.2598e-05]],\n",
      "\n",
      "         [[-3.2654e-05, -3.3226e-05, -3.3193e-05],\n",
      "          [-3.2915e-05, -3.3158e-05, -3.3195e-05],\n",
      "          [-3.1982e-05, -3.2241e-05, -3.1984e-05]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-6.3474e-06, -5.9662e-06, -5.3113e-06],\n",
      "          [-4.7520e-06, -4.7440e-06, -4.4617e-06],\n",
      "          [-6.4010e-06, -6.2598e-06, -5.6585e-06]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.3331e-06, -3.0726e-06, -3.7247e-06],\n",
      "          [-3.5827e-06, -3.1841e-06, -3.7698e-06],\n",
      "          [-3.3964e-06, -3.0659e-06, -3.5987e-06]],\n",
      "\n",
      "         [[-1.0145e-05, -9.8346e-06, -1.0134e-05],\n",
      "          [-8.7301e-06, -8.5018e-06, -8.9291e-06],\n",
      "          [-9.6148e-06, -9.4564e-06, -1.0232e-05]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 2.1277e-05,  2.1337e-05,  2.0237e-05],\n",
      "          [ 2.1985e-05,  2.1932e-05,  2.0989e-05],\n",
      "          [ 2.1420e-05,  2.1276e-05,  1.9970e-05]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.5953e-05,  1.6022e-05,  1.5880e-05],\n",
      "          [ 1.6030e-05,  1.6188e-05,  1.5937e-05],\n",
      "          [ 1.6040e-05,  1.6574e-05,  1.6398e-05]],\n",
      "\n",
      "         [[ 3.8214e-05,  3.7986e-05,  3.7879e-05],\n",
      "          [ 3.8228e-05,  3.8769e-05,  3.8912e-05],\n",
      "          [ 3.7577e-05,  3.6978e-05,  3.6606e-05]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-8.7212e-06, -8.5663e-06, -8.9281e-06],\n",
      "          [-9.5543e-06, -8.9616e-06, -9.1822e-06],\n",
      "          [-6.7208e-06, -6.4004e-06, -7.2832e-06]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.6903e-06, -5.9252e-06, -5.9645e-06],\n",
      "          [-4.4591e-06, -4.8805e-06, -5.3639e-06],\n",
      "          [-5.1882e-06, -5.6558e-06, -5.6578e-06]],\n",
      "\n",
      "         [[-1.4883e-05, -1.5283e-05, -1.5298e-05],\n",
      "          [-1.5287e-05, -1.5431e-05, -1.5341e-05],\n",
      "          [-1.3173e-05, -1.3338e-05, -1.3624e-05]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]]], device='cuda:0')\n",
      "tensor([ 4.7684e-05, -2.9979e-05, -8.5191e-06, -8.4546e-05,  0.0000e+00,\n",
      "         0.0000e+00,  1.7031e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  7.2937e-05,  1.2148e-04,  0.0000e+00, -6.8727e-08,\n",
      "         0.0000e+00,  1.8678e-04, -5.2227e-07,  0.0000e+00,  0.0000e+00,\n",
      "        -5.0884e-06,  0.0000e+00,  0.0000e+00,  1.0505e-04,  0.0000e+00,\n",
      "         0.0000e+00,  5.2273e-05,  8.5252e-05, -1.0190e-06, -1.6311e-05,\n",
      "        -9.7127e-05,  0.0000e+00,  1.7692e-04,  0.0000e+00, -7.8370e-06,\n",
      "        -1.6565e-06, -2.6870e-06,  0.0000e+00,  0.0000e+00, -1.8663e-05,\n",
      "         0.0000e+00,  0.0000e+00,  2.0259e-05, -7.5787e-05,  2.4267e-08,\n",
      "         0.0000e+00,  3.4533e-05, -1.2847e-05], device='cuda:0')\n",
      "tensor([[ 2.3751e-08,  2.2141e-08,  2.4609e-08,  ...,  1.1906e-08,\n",
      "          1.1206e-08,  1.1601e-08],\n",
      "        [-1.1045e-07, -1.0289e-07, -1.1309e-07,  ..., -4.9965e-08,\n",
      "         -4.9027e-08, -4.9654e-08],\n",
      "        [ 1.5166e-07,  1.4096e-07,  1.5606e-07,  ...,  6.8671e-08,\n",
      "          6.7418e-08,  6.7707e-08],\n",
      "        ...,\n",
      "        [-1.7436e-08, -1.6229e-08, -1.7751e-08,  ..., -7.9768e-09,\n",
      "         -7.7127e-09, -7.8316e-09],\n",
      "        [ 4.7559e-08,  4.4182e-08,  4.8835e-08,  ...,  2.1752e-08,\n",
      "          2.1265e-08,  2.1341e-08],\n",
      "        [-1.1090e-10, -1.0214e-10, -1.0880e-10,  ..., -6.8669e-11,\n",
      "         -6.4398e-11, -6.4908e-11]], device='cuda:0')\n",
      "tensor([[-3.6597e-10, -6.1424e-09,  2.7606e-09,  ..., -1.1524e-09,\n",
      "          3.0540e-09,  1.5845e-10],\n",
      "        [ 1.4785e-09,  2.5841e-08, -1.1735e-08,  ...,  4.2834e-09,\n",
      "         -1.3388e-08, -7.9060e-11],\n",
      "        [-2.2670e-09, -3.6957e-08,  1.7112e-08,  ..., -5.8654e-09,\n",
      "          1.9335e-08,  4.1254e-11],\n",
      "        ...,\n",
      "        [ 2.6123e-10,  4.1623e-09, -1.9067e-09,  ...,  7.1829e-10,\n",
      "         -2.1459e-09, -1.3196e-11],\n",
      "        [-6.6443e-10, -1.1474e-08,  5.2479e-09,  ..., -1.8602e-09,\n",
      "          5.9748e-09,  6.2915e-12],\n",
      "        [ 5.2950e-12,  2.6459e-11, -1.2366e-11,  ...,  6.2120e-12,\n",
      "         -1.2725e-11, -1.0407e-12]], device='cuda:0')\n",
      "tensor([ 8.8399e-08, -4.0982e-07,  5.6336e-07,  ..., -6.4165e-08,\n",
      "         1.7611e-07, -4.1130e-10], device='cuda:0')\n",
      "tensor([ 8.8399e-08, -4.0982e-07,  5.6336e-07,  ..., -6.4165e-08,\n",
      "         1.7611e-07, -4.1130e-10], device='cuda:0')\n",
      "tensor([[ 3.9875e-08,  3.6968e-08,  4.1184e-08,  ...,  1.8318e-08,\n",
      "          1.8349e-08,  1.8466e-08],\n",
      "        [-6.8822e-09, -6.4031e-09, -6.9927e-09,  ..., -3.1114e-09,\n",
      "         -3.0437e-09, -3.1011e-09],\n",
      "        [ 9.8863e-08,  9.2015e-08,  1.0201e-07,  ...,  4.4849e-08,\n",
      "          4.3859e-08,  4.4756e-08],\n",
      "        ...,\n",
      "        [ 3.5364e-08,  3.2491e-08,  3.6115e-08,  ...,  1.6238e-08,\n",
      "          1.5725e-08,  1.6145e-08],\n",
      "        [ 1.3141e-08,  1.2374e-08,  1.3773e-08,  ...,  5.8466e-09,\n",
      "          5.9349e-09,  6.2345e-09],\n",
      "        [ 2.1748e-07,  2.0153e-07,  2.2318e-07,  ...,  9.8687e-08,\n",
      "          9.6653e-08,  9.7662e-08]], device='cuda:0')\n",
      "tensor([[-4.2463e-09,  5.9664e-09, -1.2531e-08,  ..., -2.4953e-09,\n",
      "          4.2881e-09,  9.0446e-09],\n",
      "        [ 7.3558e-10, -1.0519e-09,  2.1656e-09,  ...,  4.1434e-10,\n",
      "         -7.7141e-10, -1.5769e-09],\n",
      "        [-1.0238e-08,  1.4503e-08, -2.9939e-08,  ..., -5.9295e-09,\n",
      "          1.0107e-08,  2.1543e-08],\n",
      "        ...,\n",
      "        [-3.8110e-09,  5.3698e-09, -1.1148e-08,  ..., -2.2680e-09,\n",
      "          3.8488e-09,  8.0263e-09],\n",
      "        [-1.5378e-09,  2.0912e-09, -4.2451e-09,  ..., -9.0182e-10,\n",
      "          1.4857e-09,  3.0681e-09],\n",
      "        [-2.3412e-08,  3.3330e-08, -6.8787e-08,  ..., -1.3381e-08,\n",
      "          2.3703e-08,  4.9835e-08]], device='cuda:0')\n",
      "tensor([ 1.4895e-07, -2.5544e-08,  3.6875e-07,  ...,  1.3386e-07,\n",
      "         4.9608e-08,  8.1149e-07], device='cuda:0')\n",
      "tensor([ 1.4895e-07, -2.5544e-08,  3.6875e-07,  ...,  1.3386e-07,\n",
      "         4.9608e-08,  8.1149e-07], device='cuda:0')\n",
      "tensor([[-2.5394e-09, -4.4767e-08,  2.0536e-08,  ..., -1.1179e-08,\n",
      "          2.1244e-08,  4.3430e-08],\n",
      "        [ 3.4356e-11,  4.7137e-10, -1.8495e-10,  ...,  1.3123e-10,\n",
      "         -2.5588e-10, -4.9629e-10],\n",
      "        [-3.6164e-10, -5.1311e-09,  2.3768e-09,  ..., -1.2611e-09,\n",
      "          2.2240e-09,  4.8112e-09],\n",
      "        ...,\n",
      "        [-1.0781e-09, -1.4439e-08,  6.8077e-09,  ..., -3.5856e-09,\n",
      "          6.2676e-09,  1.3425e-08],\n",
      "        [ 6.5697e-11,  3.0329e-11, -1.8008e-11,  ...,  7.9051e-12,\n",
      "          4.3565e-11,  1.7381e-11],\n",
      "        [-4.6198e-10, -6.0001e-09,  2.7876e-09,  ..., -1.4615e-09,\n",
      "          2.6046e-09,  5.5323e-09]], device='cuda:0')\n",
      "tensor([[ 3.6241e-08,  1.4799e-09,  1.1584e-08,  ..., -1.7408e-08,\n",
      "          1.4612e-08, -6.9675e-09],\n",
      "        [-3.4428e-10, -3.6121e-11, -1.4007e-10,  ...,  1.4829e-10,\n",
      "         -1.5070e-10,  7.4614e-11],\n",
      "        [ 4.2371e-09,  1.5662e-10,  1.3514e-09,  ..., -2.0392e-09,\n",
      "          1.7037e-09, -7.8085e-10],\n",
      "        ...,\n",
      "        [ 1.2123e-08,  3.9628e-10,  3.7478e-09,  ..., -5.9191e-09,\n",
      "          4.8579e-09, -2.2408e-09],\n",
      "        [-7.8071e-11, -1.6212e-12, -1.5007e-11,  ...,  4.8436e-11,\n",
      "         -3.6858e-11, -9.0126e-13],\n",
      "        [ 4.9480e-09,  1.9278e-10,  1.5710e-09,  ..., -2.3884e-09,\n",
      "          2.0119e-09, -9.4597e-10]], device='cuda:0')\n",
      "tensor([ 6.8237e-07, -7.6370e-09,  7.8399e-08,  ...,  2.1938e-07,\n",
      "        -1.2635e-09,  9.1747e-08], device='cuda:0')\n",
      "tensor([ 6.8237e-07, -7.6370e-09,  7.8399e-08,  ...,  2.1938e-07,\n",
      "        -1.2635e-09,  9.1747e-08], device='cuda:0')\n",
      "tensor([[-7.3463e-10, -9.0593e-09,  4.3477e-09,  ..., -2.1763e-09,\n",
      "          3.6657e-09,  8.0187e-09],\n",
      "        [-9.3187e-11, -1.1490e-09,  5.4820e-10,  ..., -2.7114e-10,\n",
      "          4.6319e-10,  1.0101e-09],\n",
      "        [ 2.2986e-10,  3.1083e-09, -1.4726e-09,  ...,  7.5583e-10,\n",
      "         -1.3092e-09, -2.8313e-09],\n",
      "        ...,\n",
      "        [ 8.8399e-10,  1.2262e-08, -5.6042e-09,  ...,  3.0406e-09,\n",
      "         -5.3967e-09, -1.1750e-08],\n",
      "        [-1.0161e-09, -1.3758e-08,  6.4914e-09,  ..., -3.4596e-09,\n",
      "          6.0695e-09,  1.2864e-08],\n",
      "        [ 1.0399e-09,  1.3808e-08, -6.3119e-09,  ...,  3.4243e-09,\n",
      "         -6.0664e-09, -1.3134e-08]], device='cuda:0')\n",
      "tensor([[ 1.5032e-09,  9.1778e-10, -1.0292e-09,  ...,  4.8351e-09,\n",
      "          2.3290e-09, -4.5795e-09],\n",
      "        [ 1.9048e-10,  1.1795e-10, -1.3012e-10,  ...,  6.0661e-10,\n",
      "          2.9155e-10, -5.7752e-10],\n",
      "        [-5.3489e-10, -3.2938e-10,  3.7126e-10,  ..., -1.7350e-09,\n",
      "         -8.3735e-10,  1.6474e-09],\n",
      "        ...,\n",
      "        [-2.1183e-09, -1.3325e-09,  1.5572e-09,  ..., -7.2489e-09,\n",
      "         -3.4546e-09,  6.8300e-09],\n",
      "        [ 2.3864e-09,  1.4424e-09, -1.6728e-09,  ...,  7.9560e-09,\n",
      "          3.8315e-09, -7.5119e-09],\n",
      "        [-2.3775e-09, -1.4970e-09,  1.7382e-09,  ..., -8.1059e-09,\n",
      "         -3.8604e-09,  7.6636e-09]], device='cuda:0')\n",
      "tensor([ 1.3642e-07,  1.7395e-08, -4.7040e-08,  ..., -1.9036e-07,\n",
      "         2.0818e-07, -2.1418e-07], device='cuda:0')\n",
      "tensor([ 1.3642e-07,  1.7395e-08, -4.7040e-08,  ..., -1.9036e-07,\n",
      "         2.0818e-07, -2.1418e-07], device='cuda:0')\n",
      "tensor([[ 6.6721e-05,  2.0589e-06,  2.0269e-05,  ...,  4.6417e-05,\n",
      "          2.2315e-05, -4.3991e-05],\n",
      "        [-6.6721e-05, -2.0589e-06, -2.0269e-05,  ..., -4.6417e-05,\n",
      "         -2.2315e-05,  4.3991e-05]], device='cuda:0')\n",
      "tensor([ 0.0012, -0.0012], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for p in params:\n",
    "    print(p.grad)\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rationales_training_loop_GS(e, train_loader, gen, enc, pool_fn, lamb1, lamb2, xent, learning_rate, optimizer, parameters):\n",
    "    gen.train()\n",
    "    enc.train()\n",
    "    \n",
    "    total_loss = 0\n",
    "    \n",
    "    for slide,label in train_loader:\n",
    "        slide,label = slide.squeeze(0).cuda(),label.cuda()\n",
    "        \n",
    "        # generate tile rationales\n",
    "        preds = gen(slide)\n",
    "        logits = lsm(preds).squeeze(0)\n",
    "        sample = gumbel_softmax(logits, temperature=10.0)\n",
    "        rationale = slide.view(slide.shape[1],slide.shape[2],slide.shape[3],-1) * sample[:,1]\n",
    "        rationale = rationale.view(-1,slide.shape[1],slide.shape[2],slide.shape[3])\n",
    "        \n",
    "        # predict class based on rationales\n",
    "        output = enc(rationale)\n",
    "        pool = pool_fn(output)\n",
    "        y_hat = enc.classification_layer(pool)\n",
    "        \n",
    "        # compute loss and regularization term\n",
    "        znorm = torch.sum(sample[:,1])\n",
    "        zdist = torch.sum(torch.abs(sample[:-1,1] - sample[1:,1]))\n",
    "        omega = (lamb1 * znorm) + (lamb2 * zdist)\n",
    "        loss = xent(y_hat.unsqueeze(0), label)# + omega\n",
    "        loss.backward()\n",
    "        #print(y_hat,label,znorm)\n",
    "        optimizer.step()\n",
    "        \n",
    "        #for p in parameters:\n",
    "            #print(p.grad)\n",
    "        optimizer.zero_grad()\n",
    "        total_loss += loss.detach().cpu().numpy() \n",
    "\n",
    "    print('Epoch: {0}, Train Loss: {1:0.4f}, Number of tiles from last slide: {2:0.1f}'.format(e, total_loss,znorm))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 24.0918, Number of tiles from last slide: 18.5\n",
      "Epoch: 1, Train Loss: 20.9500, Number of tiles from last slide: 75.5\n",
      "Epoch: 2, Train Loss: 20.5768, Number of tiles from last slide: 644.3\n",
      "Epoch: 3, Train Loss: 19.1501, Number of tiles from last slide: 338.5\n",
      "Epoch: 4, Train Loss: 21.4056, Number of tiles from last slide: 93.8\n",
      "Epoch: 5, Train Loss: 20.9973, Number of tiles from last slide: 338.6\n",
      "Epoch: 6, Train Loss: 20.5546, Number of tiles from last slide: 93.8\n",
      "Epoch: 7, Train Loss: 19.9358, Number of tiles from last slide: 75.7\n",
      "Epoch: 8, Train Loss: 18.9516, Number of tiles from last slide: 167.8\n",
      "Epoch: 9, Train Loss: 20.3999, Number of tiles from last slide: 162.6\n",
      "Epoch: 10, Train Loss: 19.0639, Number of tiles from last slide: 299.6\n",
      "Epoch: 11, Train Loss: 18.1739, Number of tiles from last slide: 197.7\n",
      "Epoch: 12, Train Loss: 18.4311, Number of tiles from last slide: 93.8\n",
      "Epoch: 13, Train Loss: 17.4477, Number of tiles from last slide: 13.8\n",
      "Epoch: 14, Train Loss: 19.5423, Number of tiles from last slide: 324.7\n",
      "Epoch: 15, Train Loss: 17.4561, Number of tiles from last slide: 569.6\n",
      "Epoch: 16, Train Loss: 16.7883, Number of tiles from last slide: 133.7\n",
      "Epoch: 17, Train Loss: 15.9372, Number of tiles from last slide: 690.3\n",
      "Epoch: 18, Train Loss: 15.1046, Number of tiles from last slide: 9.1\n",
      "Epoch: 19, Train Loss: 18.6497, Number of tiles from last slide: 91.0\n",
      "Epoch: 20, Train Loss: 16.6384, Number of tiles from last slide: 133.7\n",
      "Epoch: 21, Train Loss: 17.8139, Number of tiles from last slide: 347.5\n",
      "Epoch: 22, Train Loss: 14.6650, Number of tiles from last slide: 5.3\n",
      "Epoch: 23, Train Loss: 17.5038, Number of tiles from last slide: 133.9\n",
      "Epoch: 24, Train Loss: 15.1588, Number of tiles from last slide: 347.8\n",
      "Epoch: 25, Train Loss: 18.6277, Number of tiles from last slide: 147.9\n",
      "Epoch: 26, Train Loss: 19.6587, Number of tiles from last slide: 13.8\n",
      "Epoch: 27, Train Loss: 15.6521, Number of tiles from last slide: 288.8\n",
      "Epoch: 28, Train Loss: 16.0409, Number of tiles from last slide: 324.8\n",
      "Epoch: 29, Train Loss: 16.0398, Number of tiles from last slide: 249.0\n",
      "Epoch: 30, Train Loss: 16.1918, Number of tiles from last slide: 358.7\n",
      "Epoch: 31, Train Loss: 15.4125, Number of tiles from last slide: 19.0\n",
      "Epoch: 32, Train Loss: 15.8356, Number of tiles from last slide: 123.9\n",
      "Epoch: 33, Train Loss: 16.2613, Number of tiles from last slide: 569.6\n",
      "Epoch: 34, Train Loss: 15.6201, Number of tiles from last slide: 287.7\n",
      "Epoch: 35, Train Loss: 14.0339, Number of tiles from last slide: 29.9\n",
      "Epoch: 36, Train Loss: 16.5715, Number of tiles from last slide: 643.8\n",
      "Epoch: 37, Train Loss: 12.7384, Number of tiles from last slide: 12.1\n",
      "Epoch: 38, Train Loss: 12.5739, Number of tiles from last slide: 160.8\n",
      "Epoch: 39, Train Loss: 13.2923, Number of tiles from last slide: 222.2\n",
      "Epoch: 40, Train Loss: 11.7406, Number of tiles from last slide: 569.5\n",
      "Epoch: 41, Train Loss: 12.3685, Number of tiles from last slide: 6.0\n",
      "Epoch: 42, Train Loss: 11.6617, Number of tiles from last slide: 5.6\n",
      "Epoch: 43, Train Loss: 12.8904, Number of tiles from last slide: 135.9\n",
      "Epoch: 44, Train Loss: 9.4610, Number of tiles from last slide: 262.8\n",
      "Epoch: 45, Train Loss: 12.9514, Number of tiles from last slide: 77.0\n",
      "Epoch: 46, Train Loss: 11.9726, Number of tiles from last slide: 74.5\n",
      "Epoch: 47, Train Loss: 9.1737, Number of tiles from last slide: 208.9\n",
      "Epoch: 48, Train Loss: 9.3573, Number of tiles from last slide: 9.0\n",
      "Epoch: 49, Train Loss: 6.7655, Number of tiles from last slide: 0.9\n",
      "Epoch: 50, Train Loss: 35.6297, Number of tiles from last slide: 2.6\n",
      "Epoch: 51, Train Loss: 13.9939, Number of tiles from last slide: 86.2\n",
      "Epoch: 52, Train Loss: 13.5881, Number of tiles from last slide: 2.6\n",
      "Epoch: 53, Train Loss: 12.0187, Number of tiles from last slide: 15.6\n",
      "Epoch: 54, Train Loss: 12.4829, Number of tiles from last slide: 7.4\n",
      "Epoch: 55, Train Loss: 10.8266, Number of tiles from last slide: 296.5\n",
      "Epoch: 56, Train Loss: 9.8154, Number of tiles from last slide: 17.9\n",
      "Epoch: 57, Train Loss: 11.4283, Number of tiles from last slide: 18.5\n",
      "Epoch: 58, Train Loss: 7.9347, Number of tiles from last slide: 105.2\n",
      "Epoch: 59, Train Loss: 10.7896, Number of tiles from last slide: 254.7\n",
      "Epoch: 60, Train Loss: 8.6476, Number of tiles from last slide: 54.9\n",
      "Epoch: 61, Train Loss: 9.5135, Number of tiles from last slide: 18.6\n",
      "Epoch: 62, Train Loss: 7.6340, Number of tiles from last slide: 3.7\n",
      "Epoch: 63, Train Loss: 8.2136, Number of tiles from last slide: 178.7\n",
      "Epoch: 64, Train Loss: 8.2849, Number of tiles from last slide: 431.0\n",
      "Epoch: 65, Train Loss: 8.3811, Number of tiles from last slide: 156.8\n",
      "Epoch: 66, Train Loss: 7.9250, Number of tiles from last slide: 158.0\n",
      "Epoch: 67, Train Loss: 5.9767, Number of tiles from last slide: 260.6\n",
      "Epoch: 68, Train Loss: 6.9560, Number of tiles from last slide: 104.7\n",
      "Epoch: 69, Train Loss: 7.1191, Number of tiles from last slide: 58.9\n",
      "Epoch: 70, Train Loss: 6.6350, Number of tiles from last slide: 19.1\n",
      "Epoch: 71, Train Loss: 6.1820, Number of tiles from last slide: 161.0\n",
      "Epoch: 72, Train Loss: 7.3486, Number of tiles from last slide: 99.5\n",
      "Epoch: 73, Train Loss: 7.3544, Number of tiles from last slide: 231.5\n",
      "Epoch: 74, Train Loss: 6.7608, Number of tiles from last slide: 218.9\n",
      "Epoch: 75, Train Loss: 8.8529, Number of tiles from last slide: 105.5\n",
      "Epoch: 76, Train Loss: 5.4080, Number of tiles from last slide: 113.9\n",
      "Epoch: 77, Train Loss: 4.9309, Number of tiles from last slide: 136.0\n",
      "Epoch: 78, Train Loss: 5.6973, Number of tiles from last slide: 145.6\n",
      "Epoch: 79, Train Loss: 4.3659, Number of tiles from last slide: 192.4\n",
      "Epoch: 80, Train Loss: 4.2809, Number of tiles from last slide: 452.5\n",
      "Epoch: 81, Train Loss: 4.5890, Number of tiles from last slide: 194.5\n",
      "Epoch: 82, Train Loss: 4.9149, Number of tiles from last slide: 227.1\n",
      "Epoch: 83, Train Loss: 4.6978, Number of tiles from last slide: 49.9\n",
      "Epoch: 84, Train Loss: 2.6131, Number of tiles from last slide: 12.3\n",
      "Epoch: 85, Train Loss: 29.2831, Number of tiles from last slide: 107.0\n",
      "Epoch: 86, Train Loss: 8.7392, Number of tiles from last slide: 377.9\n",
      "Epoch: 87, Train Loss: 5.3152, Number of tiles from last slide: 1.1\n",
      "Epoch: 88, Train Loss: 4.5651, Number of tiles from last slide: 189.3\n",
      "Epoch: 89, Train Loss: 3.8673, Number of tiles from last slide: 5.2\n",
      "Epoch: 90, Train Loss: 3.1941, Number of tiles from last slide: 236.3\n",
      "Epoch: 91, Train Loss: 3.3853, Number of tiles from last slide: 231.8\n",
      "Epoch: 92, Train Loss: 2.3445, Number of tiles from last slide: 223.3\n",
      "Epoch: 93, Train Loss: 2.0524, Number of tiles from last slide: 47.9\n",
      "Epoch: 94, Train Loss: 3.1055, Number of tiles from last slide: 56.7\n",
      "Epoch: 95, Train Loss: 1.9541, Number of tiles from last slide: 191.9\n",
      "Epoch: 96, Train Loss: 1.5825, Number of tiles from last slide: 45.1\n",
      "Epoch: 97, Train Loss: 1.0429, Number of tiles from last slide: 137.5\n",
      "Epoch: 98, Train Loss: 0.9398, Number of tiles from last slide: 10.1\n",
      "Epoch: 99, Train Loss: 1.5585, Number of tiles from last slide: 18.1\n"
     ]
    }
   ],
   "source": [
    "for e in range(100):\n",
    "    rationales_training_loop_GS(e, train_loader, gen, enc, pool_fn, lamb1, lamb2, xent, learning_rate, optimizer,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

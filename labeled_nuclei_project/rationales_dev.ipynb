{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "import data_utils\n",
    "import train_utils\n",
    "import models\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = data_utils.COAD_dataset(data_utils.COAD_DEV)\n",
    "dev_loader = torch.utils.data.DataLoader(dev, batch_size=1, shuffle=True , pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, n_conv_layers, kernel_size, n_conv_filters, hidden_size, n_rnn_layers, dropout=0.5):\n",
    "        super(Generator, self).__init__()\n",
    "        self.n_conv_layers = n_conv_layers\n",
    "        self.kernel_size = kernel_size\n",
    "        self.n_conv_filters = n_conv_filters\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_rnn_layers = n_rnn_layers\n",
    "        self.conv_layers = []\n",
    "        self.m = nn.MaxPool2d(2, stride=2)\n",
    "        self.relu = nn.ReLU()\n",
    "         \n",
    "        in_channels = 3        \n",
    "        for layer in range(self.n_conv_layers):\n",
    "            self.conv_layers.append(nn.Conv2d(in_channels, self.n_conv_filters[layer], self.kernel_size[layer]))\n",
    "            self.conv_layers.append(self.relu)\n",
    "            self.conv_layers.append(self.m)\n",
    "            in_channels = self.n_conv_filters[layer]\n",
    "        self.conv = nn.Sequential(*self.conv_layers)\n",
    "        in_channels = in_channels * 25\n",
    "\n",
    "        self.lstm = nn.LSTM(in_channels, self.hidden_size, self.n_rnn_layers, batch_first=True, \n",
    "                            dropout=dropout, bidirectional=True) \n",
    "        in_channels = hidden_size * 2\n",
    "        self.classification_layer = nn.Linear(in_channels, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embed = self.conv(x)\n",
    "        embed = embed.view(1,x.shape[0],-1)\n",
    "        output, hidden = self.lstm(embed)\n",
    "        y = self.classification_layer(output)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for slide,label in dev_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.5216, 0.3098, 0.5961,  ..., 0.5294, 0.3098, 0.6157],\n",
       "          [0.5647, 0.3451, 0.6471,  ..., 0.6706, 0.4392, 0.6902],\n",
       "          [0.6510, 0.4157, 0.6706,  ..., 0.6510, 0.4078, 0.7137],\n",
       "          ...,\n",
       "          [0.6118, 0.3843, 0.7255,  ..., 0.5765, 0.3490, 0.6667],\n",
       "          [0.5412, 0.3098, 0.6353,  ..., 0.6118, 0.3882, 0.6588],\n",
       "          [0.6863, 0.4588, 0.7176,  ..., 0.8706, 0.6078, 0.8353]],\n",
       "\n",
       "         [[0.5843, 0.3608, 0.7059,  ..., 0.7451, 0.5098, 0.8275],\n",
       "          [0.6235, 0.3961, 0.7098,  ..., 0.6745, 0.4588, 0.7216],\n",
       "          [0.6431, 0.4235, 0.6941,  ..., 0.8118, 0.5490, 0.7804],\n",
       "          ...,\n",
       "          [0.8314, 0.6392, 0.8510,  ..., 0.8196, 0.5804, 0.8353],\n",
       "          [0.7961, 0.5608, 0.8157,  ..., 0.8196, 0.5725, 0.8196],\n",
       "          [0.7843, 0.5412, 0.7882,  ..., 0.7490, 0.5098, 0.7373]],\n",
       "\n",
       "         [[0.5804, 0.3765, 0.6392,  ..., 0.8000, 0.5569, 0.8196],\n",
       "          [0.7843, 0.5451, 0.8078,  ..., 0.9725, 0.7333, 0.9294],\n",
       "          [0.9490, 0.7059, 0.9059,  ..., 0.7804, 0.5529, 0.7843],\n",
       "          ...,\n",
       "          [0.7725, 0.5725, 0.8275,  ..., 0.7765, 0.5373, 0.8118],\n",
       "          [0.7529, 0.5098, 0.7765,  ..., 0.6784, 0.4431, 0.7490],\n",
       "          [0.6353, 0.4000, 0.7020,  ..., 0.7373, 0.4980, 0.7490]]],\n",
       "\n",
       "\n",
       "        [[[0.9843, 0.7804, 0.9294,  ..., 0.6745, 0.4353, 0.6745],\n",
       "          [0.7569, 0.5137, 0.7373,  ..., 0.5608, 0.3176, 0.6275],\n",
       "          [0.5490, 0.3176, 0.6118,  ..., 0.4588, 0.2392, 0.5647],\n",
       "          ...,\n",
       "          [0.6902, 0.4431, 0.7608,  ..., 0.5765, 0.3176, 0.6157],\n",
       "          [0.6196, 0.3647, 0.6667,  ..., 0.4706, 0.2706, 0.5725],\n",
       "          [0.5333, 0.3294, 0.6314,  ..., 0.6275, 0.4118, 0.7176]],\n",
       "\n",
       "         [[0.6784, 0.4275, 0.7608,  ..., 0.6235, 0.3725, 0.6667],\n",
       "          [0.6471, 0.3961, 0.6863,  ..., 0.4745, 0.2667, 0.5765],\n",
       "          [0.5373, 0.3255, 0.6392,  ..., 0.6078, 0.3922, 0.6824],\n",
       "          ...,\n",
       "          [0.5137, 0.3059, 0.6000,  ..., 0.5137, 0.2941, 0.6039],\n",
       "          [0.4863, 0.2706, 0.5882,  ..., 0.6549, 0.4471, 0.7176],\n",
       "          [0.6980, 0.4941, 0.7686,  ..., 0.7765, 0.5176, 0.7765]],\n",
       "\n",
       "         [[0.5216, 0.3098, 0.6196,  ..., 0.5412, 0.3216, 0.6353],\n",
       "          [0.4980, 0.2863, 0.6118,  ..., 0.7608, 0.5490, 0.8314],\n",
       "          [0.7765, 0.5725, 0.8431,  ..., 0.7922, 0.5333, 0.7922],\n",
       "          ...,\n",
       "          [0.7294, 0.5608, 0.7176,  ..., 0.7373, 0.5373, 0.7961],\n",
       "          [0.7294, 0.5294, 0.7882,  ..., 0.6314, 0.4000, 0.6902],\n",
       "          [0.6118, 0.3922, 0.6627,  ..., 0.6314, 0.3961, 0.6392]]],\n",
       "\n",
       "\n",
       "        [[[0.8314, 0.6000, 0.8039,  ..., 0.6000, 0.3608, 0.6510],\n",
       "          [0.6471, 0.4157, 0.6784,  ..., 0.7647, 0.5294, 0.8078],\n",
       "          [0.8157, 0.5843, 0.8706,  ..., 0.6118, 0.3843, 0.7255],\n",
       "          ...,\n",
       "          [0.8902, 0.6353, 0.8471,  ..., 0.5216, 0.3137, 0.6118],\n",
       "          [0.5098, 0.2980, 0.5882,  ..., 0.4824, 0.2706, 0.5725],\n",
       "          [0.4392, 0.2314, 0.5176,  ..., 0.8392, 0.6431, 0.8784]],\n",
       "\n",
       "         [[0.8902, 0.6353, 0.8510,  ..., 0.5569, 0.3333, 0.6353],\n",
       "          [0.4706, 0.2471, 0.5451,  ..., 0.4902, 0.2745, 0.6078],\n",
       "          [0.4706, 0.2549, 0.5882,  ..., 0.8314, 0.6392, 0.8510],\n",
       "          ...,\n",
       "          [0.8745, 0.6275, 0.8784,  ..., 0.8314, 0.6471, 0.8118],\n",
       "          [0.9686, 0.8157, 0.8941,  ..., 0.5725, 0.3725, 0.6627],\n",
       "          [0.5176, 0.3255, 0.5961,  ..., 0.6471, 0.4431, 0.7020]],\n",
       "\n",
       "         [[0.9059, 0.6667, 0.9059,  ..., 0.6431, 0.4314, 0.6627],\n",
       "          [0.6196, 0.4275, 0.6078,  ..., 0.4549, 0.2627, 0.5647],\n",
       "          [0.4706, 0.2784, 0.5765,  ..., 0.7725, 0.5725, 0.8275],\n",
       "          ...,\n",
       "          [0.6902, 0.4627, 0.7176,  ..., 0.5333, 0.3176, 0.6392],\n",
       "          [0.4941, 0.2784, 0.5961,  ..., 0.7020, 0.4784, 0.7255],\n",
       "          [0.6314, 0.4118, 0.6431,  ..., 0.8941, 0.7608, 0.9098]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.8627, 0.6235, 0.8314,  ..., 0.7255, 0.4431, 0.6902],\n",
       "          [0.9059, 0.6353, 0.8510,  ..., 0.7098, 0.4863, 0.7216],\n",
       "          [0.7294, 0.5059, 0.7490,  ..., 0.7529, 0.5647, 0.8118],\n",
       "          ...,\n",
       "          [0.8745, 0.6667, 0.8275,  ..., 0.9882, 0.7529, 0.9490],\n",
       "          [0.9373, 0.7059, 0.8784,  ..., 0.7529, 0.5725, 0.7412],\n",
       "          [0.8431, 0.6784, 0.8431,  ..., 0.8510, 0.5451, 0.7569]],\n",
       "\n",
       "         [[0.9490, 0.7569, 0.9059,  ..., 0.9922, 0.7725, 0.9333],\n",
       "          [0.9216, 0.6941, 0.8627,  ..., 0.9020, 0.7294, 0.9294],\n",
       "          [0.9961, 0.9098, 1.0000,  ..., 0.8627, 0.5569, 0.7647],\n",
       "          ...,\n",
       "          [1.0000, 0.8902, 0.9882,  ..., 0.9882, 0.7373, 0.9255],\n",
       "          [0.9765, 0.7529, 0.9373,  ..., 1.0000, 0.8745, 1.0000],\n",
       "          [0.9294, 0.7765, 0.9137,  ..., 0.6157, 0.3725, 0.6039]],\n",
       "\n",
       "         [[1.0000, 0.8431, 0.9569,  ..., 0.9843, 0.7451, 0.9373],\n",
       "          [0.8863, 0.6902, 0.8784,  ..., 0.9569, 0.8157, 0.9608],\n",
       "          [0.8000, 0.6392, 0.8118,  ..., 0.6784, 0.4392, 0.6745],\n",
       "          ...,\n",
       "          [0.8980, 0.6824, 0.8471,  ..., 0.4000, 0.2314, 0.5647],\n",
       "          [0.4824, 0.2941, 0.6078,  ..., 0.8353, 0.6353, 0.8431],\n",
       "          [0.9216, 0.7020, 0.9137,  ..., 0.9765, 0.7961, 0.9961]]],\n",
       "\n",
       "\n",
       "        [[[0.8980, 0.7020, 0.8706,  ..., 0.8157, 0.6039, 0.7686],\n",
       "          [0.9373, 0.7216, 0.8745,  ..., 0.5804, 0.3647, 0.6510],\n",
       "          [0.5020, 0.3059, 0.5608,  ..., 0.8588, 0.5608, 0.7804],\n",
       "          ...,\n",
       "          [1.0000, 0.9255, 1.0000,  ..., 0.9059, 0.6706, 0.8431],\n",
       "          [0.8863, 0.6235, 0.8078,  ..., 0.9333, 0.7176, 0.9137],\n",
       "          [1.0000, 0.8157, 0.9725,  ..., 0.6902, 0.4824, 0.7451]],\n",
       "\n",
       "         [[0.9922, 0.9020, 0.9843,  ..., 0.9020, 0.6549, 0.8235],\n",
       "          [0.9333, 0.6667, 0.8510,  ..., 1.0000, 0.7882, 0.9765],\n",
       "          [0.9608, 0.7765, 0.9098,  ..., 0.6863, 0.4824, 0.7686],\n",
       "          ...,\n",
       "          [0.6980, 0.4784, 0.6941,  ..., 0.9098, 0.6549, 0.8157],\n",
       "          [0.8471, 0.6431, 0.8902,  ..., 0.9176, 0.7294, 0.9059],\n",
       "          [0.9451, 0.7569, 0.9255,  ..., 0.5294, 0.3176, 0.6353]],\n",
       "\n",
       "         [[0.8000, 0.5608, 0.7647,  ..., 0.9294, 0.6745, 0.8471],\n",
       "          [0.9020, 0.6863, 0.9373,  ..., 0.7882, 0.6000, 0.7882],\n",
       "          [0.9137, 0.7176, 0.9020,  ..., 0.4863, 0.2784, 0.6000],\n",
       "          ...,\n",
       "          [0.9020, 0.6667, 0.8353,  ..., 0.7882, 0.5686, 0.7216],\n",
       "          [0.9255, 0.7569, 0.8784,  ..., 0.7098, 0.5020, 0.7137],\n",
       "          [0.8627, 0.6588, 0.8471,  ..., 0.7882, 0.6118, 0.8588]]],\n",
       "\n",
       "\n",
       "        [[[0.7098, 0.4745, 0.7765,  ..., 0.7569, 0.5059, 0.7490],\n",
       "          [0.7255, 0.4784, 0.7020,  ..., 0.7373, 0.4941, 0.7294],\n",
       "          [0.7412, 0.4863, 0.7333,  ..., 0.9137, 0.7020, 0.8902],\n",
       "          ...,\n",
       "          [0.8588, 0.6157, 0.8235,  ..., 0.6392, 0.4078, 0.6902],\n",
       "          [0.4196, 0.2196, 0.5490,  ..., 1.0000, 0.8588, 0.9686],\n",
       "          [1.0000, 0.8588, 1.0000,  ..., 0.9216, 0.7412, 0.9020]],\n",
       "\n",
       "         [[0.8039, 0.5529, 0.7647,  ..., 0.5569, 0.3451, 0.6157],\n",
       "          [0.4235, 0.2392, 0.5333,  ..., 0.9843, 0.8000, 0.9059],\n",
       "          [0.9529, 0.7647, 0.9098,  ..., 0.9765, 0.8118, 0.9569],\n",
       "          ...,\n",
       "          [0.6235, 0.3882, 0.6627,  ..., 0.7765, 0.5255, 0.8157],\n",
       "          [0.6275, 0.4039, 0.7529,  ..., 0.7882, 0.5529, 0.7922],\n",
       "          [0.7804, 0.5294, 0.8000,  ..., 0.8510, 0.6039, 0.8157]],\n",
       "\n",
       "         [[0.6235, 0.3843, 0.6902,  ..., 0.7961, 0.5529, 0.8118],\n",
       "          [0.7490, 0.5176, 0.8235,  ..., 0.8157, 0.5647, 0.8235],\n",
       "          [0.7020, 0.4549, 0.7608,  ..., 0.8118, 0.5765, 0.7961],\n",
       "          ...,\n",
       "          [0.7647, 0.5373, 0.7725,  ..., 0.8118, 0.5765, 0.7961],\n",
       "          [0.8275, 0.5922, 0.8039,  ..., 0.9961, 0.9059, 0.9882],\n",
       "          [0.8667, 0.6863, 0.8314,  ..., 0.7529, 0.5020, 0.7804]]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slide.squeeze_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 3, 27, 27])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slide.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (m): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu): ReLU()\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(3, 36, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(36, 48, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (lstm): LSTM(1200, 512, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (classification_layer): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_conv_layers = 2\n",
    "kernel_size = [4,3]\n",
    "n_conv_filters = [36,48]\n",
    "hidden_size = 512\n",
    "n_rnn_layers = 2\n",
    "dropout=0.5\n",
    "gen = Generator(n_conv_layers, kernel_size, n_conv_filters, hidden_size, n_rnn_layers, dropout=dropout)\n",
    "gen.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slide = slide.cuda()\n",
    "preds = gen(slide)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 3, 27, 27])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slide.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector = torch.argmax(preds, dim=2)\n",
    "selector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rationale = slide[selector.squeeze_(0)==1,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (m): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (n): Dropout(p=0.5)\n",
       "  (relu): ReLU()\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(3, 36, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(36, 48, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=1200, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.5)\n",
       "  )\n",
       "  (classification_layer): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_conv_layers = 2\n",
    "n_fc_layers = 2\n",
    "kernel_size = [4,3]\n",
    "n_conv_filters = [36,48]\n",
    "hidden_size = [512,512]\n",
    "dropout=0.5\n",
    "enc = models.ConvNet(n_conv_layers, n_fc_layers, kernel_size, n_conv_filters, hidden_size, dropout=dropout)\n",
    "enc.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([48, 512])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = enc(rationale)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

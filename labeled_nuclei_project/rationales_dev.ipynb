{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "import data_utils\n",
    "import train_utils\n",
    "import models\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = data_utils.COAD_dataset(data_utils.COAD_DEV)\n",
    "dev_loader = torch.utils.data.DataLoader(dev, batch_size=1, shuffle=True, pin_memory=True)\n",
    "train = data_utils.COAD_dataset(data_utils.COAD_TRAIN)\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=1, shuffle=True, pin_memory=True)\n",
    "valid = data_utils.COAD_dataset(data_utils.COAD_VALID)\n",
    "valid_loader = torch.utils.data.DataLoader(valid, batch_size=1, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_conv_layers = 2\n",
    "kernel_size = [4,3]\n",
    "n_conv_filters = [36,48]\n",
    "hidden_size = 512\n",
    "n_rnn_layers = 2\n",
    "dropout=0.5\n",
    "gen = models.Generator(n_conv_layers, kernel_size, n_conv_filters, hidden_size, n_rnn_layers, dropout=dropout)\n",
    "gen.cuda()\n",
    "\n",
    "n_conv_layers = 2\n",
    "n_fc_layers = 2\n",
    "kernel_size = [4,3]\n",
    "n_conv_filters = [36,48]\n",
    "hidden_size = [512,512]\n",
    "dropout=0.5\n",
    "enc = models.ConvNet(n_conv_layers, n_fc_layers, kernel_size, n_conv_filters, hidden_size, dropout=dropout)\n",
    "enc.cuda()\n",
    "\n",
    "lamb1 = 0\n",
    "lamb2 = 0\n",
    "xent = nn.CrossEntropyLoss()\n",
    "learning_rate = 1e-4\n",
    "temp = 10\n",
    "params = list(enc.parameters()) + list(gen.parameters())\n",
    "optimizer = torch.optim.Adam(params, lr = learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_fn(x):\n",
    "    #v,a = torch.max(x,0)\n",
    "    v = torch.mean(x,0)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 800, Train Loss: 13.519963, Train Omega: 19.3704, Fraction of Tiles: 0.9923\n",
      "Lambda: 0.40100, LR: 0.0000010, Temperature: 1.00\n",
      "Epoch: 800, Val Loss: 8.7677, Val Acc: 1.0000, Fraction of Tiles: 0.9918\n",
      "Epoch: 801, Train Loss: 13.527605, Train Omega: 19.3962, Fraction of Tiles: 0.9921\n",
      "Epoch: 801, Val Loss: 8.7641, Val Acc: 1.0000, Fraction of Tiles: 0.9918\n",
      "Epoch: 802, Train Loss: 13.464378, Train Omega: 19.4592, Fraction of Tiles: 0.9925\n",
      "Epoch: 802, Val Loss: 8.7693, Val Acc: 1.0000, Fraction of Tiles: 0.9918\n",
      "Epoch: 803, Train Loss: 12.891794, Train Omega: 19.5746, Fraction of Tiles: 0.9925\n",
      "Epoch: 803, Val Loss: 8.7464, Val Acc: 1.0000, Fraction of Tiles: 0.9918\n",
      "Epoch: 804, Train Loss: 13.644829, Train Omega: 19.5732, Fraction of Tiles: 0.9924\n",
      "Epoch: 804, Val Loss: 8.7415, Val Acc: 1.0000, Fraction of Tiles: 0.9918\n",
      "Epoch: 805, Train Loss: 13.619876, Train Omega: 19.6381, Fraction of Tiles: 0.9924\n",
      "Lambda: 0.40600, LR: 0.0000010, Temperature: 1.00\n",
      "Epoch: 805, Val Loss: 8.7656, Val Acc: 1.0000, Fraction of Tiles: 0.9918\n",
      "Epoch: 806, Train Loss: 13.628613, Train Omega: 19.6304, Fraction of Tiles: 0.9922\n",
      "Epoch: 806, Val Loss: 8.7175, Val Acc: 1.0000, Fraction of Tiles: 0.9918\n",
      "Epoch: 807, Train Loss: 13.715856, Train Omega: 19.7331, Fraction of Tiles: 0.9924\n",
      "Epoch: 807, Val Loss: 8.7526, Val Acc: 1.0000, Fraction of Tiles: 0.9918\n",
      "Epoch: 808, Train Loss: 13.307784, Train Omega: 19.7947, Fraction of Tiles: 0.9924\n",
      "Epoch: 808, Val Loss: 8.7326, Val Acc: 1.0000, Fraction of Tiles: 0.9918\n",
      "Epoch: 809, Train Loss: 13.376534, Train Omega: 19.8051, Fraction of Tiles: 0.9922\n",
      "Epoch: 809, Val Loss: 8.7290, Val Acc: 1.0000, Fraction of Tiles: 0.9918\n",
      "Epoch: 810, Train Loss: 13.781653, Train Omega: 19.8682, Fraction of Tiles: 0.9924\n",
      "Lambda: 0.41100, LR: 0.0000010, Temperature: 1.00\n",
      "Epoch: 810, Val Loss: 8.7271, Val Acc: 1.0000, Fraction of Tiles: 0.9920\n",
      "Epoch: 811, Train Loss: 13.509238, Train Omega: 19.8999, Fraction of Tiles: 0.9923\n",
      "Epoch: 811, Val Loss: 8.7535, Val Acc: 1.0000, Fraction of Tiles: 0.9922\n",
      "Epoch: 812, Train Loss: 13.050744, Train Omega: 19.9294, Fraction of Tiles: 0.9922\n",
      "Epoch: 812, Val Loss: 8.7482, Val Acc: 1.0000, Fraction of Tiles: 0.9920\n",
      "Epoch: 813, Train Loss: 13.431705, Train Omega: 19.9960, Fraction of Tiles: 0.9926\n",
      "Epoch: 813, Val Loss: 8.7279, Val Acc: 1.0000, Fraction of Tiles: 0.9921\n",
      "Epoch: 814, Train Loss: 13.297808, Train Omega: 20.1279, Fraction of Tiles: 0.9925\n",
      "Epoch: 814, Val Loss: 8.7034, Val Acc: 1.0000, Fraction of Tiles: 0.9919\n",
      "Epoch: 815, Train Loss: 13.840372, Train Omega: 20.0865, Fraction of Tiles: 0.9924\n",
      "Lambda: 0.41600, LR: 0.0000010, Temperature: 1.00\n",
      "Epoch: 815, Val Loss: 8.7347, Val Acc: 1.0000, Fraction of Tiles: 0.9918\n",
      "Epoch: 816, Train Loss: 13.538457, Train Omega: 20.1560, Fraction of Tiles: 0.9925\n",
      "Epoch: 816, Val Loss: 8.7613, Val Acc: 0.9796, Fraction of Tiles: 0.9919\n",
      "Epoch: 817, Train Loss: 13.508725, Train Omega: 20.1714, Fraction of Tiles: 0.9922\n",
      "Epoch: 817, Val Loss: 8.7566, Val Acc: 0.9796, Fraction of Tiles: 0.9918\n",
      "Epoch: 818, Train Loss: 13.604404, Train Omega: 20.1903, Fraction of Tiles: 0.9920\n",
      "Epoch: 818, Val Loss: 8.7333, Val Acc: 1.0000, Fraction of Tiles: 0.9918\n",
      "Epoch: 819, Train Loss: 13.483633, Train Omega: 20.3044, Fraction of Tiles: 0.9925\n",
      "Epoch: 819, Val Loss: 8.7583, Val Acc: 1.0000, Fraction of Tiles: 0.9918\n",
      "Epoch: 820, Train Loss: 13.708302, Train Omega: 20.3910, Fraction of Tiles: 0.9924\n",
      "Lambda: 0.42100, LR: 0.0000010, Temperature: 1.00\n",
      "Epoch: 820, Val Loss: 8.7880, Val Acc: 0.9592, Fraction of Tiles: 0.9918\n",
      "Epoch: 821, Train Loss: 13.514547, Train Omega: 20.3866, Fraction of Tiles: 0.9921\n",
      "Epoch: 821, Val Loss: 8.7558, Val Acc: 1.0000, Fraction of Tiles: 0.9917\n",
      "Epoch: 822, Train Loss: 13.520313, Train Omega: 20.5044, Fraction of Tiles: 0.9924\n",
      "Epoch: 822, Val Loss: 8.7559, Val Acc: 1.0000, Fraction of Tiles: 0.9916\n",
      "Epoch: 823, Train Loss: 12.728760, Train Omega: 20.5136, Fraction of Tiles: 0.9925\n",
      "Epoch: 823, Val Loss: 8.7521, Val Acc: 0.9796, Fraction of Tiles: 0.9915\n",
      "Epoch: 824, Train Loss: 13.287618, Train Omega: 20.5098, Fraction of Tiles: 0.9923\n",
      "Epoch: 824, Val Loss: 8.7210, Val Acc: 1.0000, Fraction of Tiles: 0.9914\n",
      "Epoch: 825, Train Loss: 13.436695, Train Omega: 20.5547, Fraction of Tiles: 0.9921\n",
      "Lambda: 0.42600, LR: 0.0000010, Temperature: 1.00\n",
      "Epoch: 825, Val Loss: 8.7205, Val Acc: 1.0000, Fraction of Tiles: 0.9914\n",
      "Epoch: 826, Train Loss: 13.323793, Train Omega: 20.6545, Fraction of Tiles: 0.9924\n",
      "Epoch: 826, Val Loss: 8.7431, Val Acc: 0.9796, Fraction of Tiles: 0.9914\n",
      "Epoch: 827, Train Loss: 13.615432, Train Omega: 20.7009, Fraction of Tiles: 0.9924\n",
      "Epoch: 827, Val Loss: 8.7226, Val Acc: 0.9796, Fraction of Tiles: 0.9914\n",
      "Epoch: 828, Train Loss: 13.191335, Train Omega: 20.7340, Fraction of Tiles: 0.9924\n",
      "Epoch: 828, Val Loss: 8.7764, Val Acc: 0.9592, Fraction of Tiles: 0.9916\n",
      "Epoch: 829, Train Loss: 13.284691, Train Omega: 20.7606, Fraction of Tiles: 0.9921\n"
     ]
    }
   ],
   "source": [
    "for e in range(800,1500):\n",
    "    train_utils.rationales_training_loop_GS(e, train_loader, gen, enc, pool_fn, lamb1, lamb2, xent, learning_rate, optimizer,temp)\n",
    "    if e > 30:\n",
    "        lamb1 += 0.001\n",
    "        temp -= 0.25\n",
    "    temp = np.max([temp,1])\n",
    "    lamb1 = np.min([lamb1,1.0])\n",
    "    if e % 5 == 0:\n",
    "        print('Lambda: {0:0.5f}, LR: {1:0.7f}, Temperature: {2:0.2f}'.format(lamb1, optimizer.state_dict()['param_groups'][0]['lr'],temp))\n",
    "    frac_tiles = train_utils.rationales_validation_loop_GS(e, valid_loader, gen, enc, pool_fn, xent, scheduler)\n",
    "    if frac_tiles < 0.9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 399, Val Loss: 16.3430, Val Acc: 0.8049, Fraction of Tiles: 0.0228\n"
     ]
    }
   ],
   "source": [
    "train_utils.rationales_validation_loop_GS(e, train_loader, gen, enc, pool_fn, xent, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gen.state_dict(),'generator.pt')\n",
    "torch.save(enc.state_dict(),'encoder.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
